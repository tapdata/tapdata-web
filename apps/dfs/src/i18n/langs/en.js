export default {
  data_see_more: 'See more',
  data_see_all: 'View all',
  data_no_data: 'No data',
  data_no: 'Not yet',
  data_no_find_result: 'No matching results were found ',
  form_all: 'whole',
  form_placeholder_input: 'Please Enter',
  form_placeholder_select: 'Please Select',
  form_can_not_be_empty: 'Cannot be empty',
  form_save_success: 'Save successfully',
  form_save_fail: 'Save failed',
  button_edit: 'Edit',
  button_copy: 'Copy',
  button_reset: 'Reset',
  button_stop: 'Stop',
  button_delete: 'Delete',
  button_all_delete: 'Delete all',
  button_cancel: 'Cancel',
  button_finish: 'Finish',
  button_submit: 'Submit',
  button_confirm: 'Confirm',
  button_close: 'Close',
  button_save: 'Save',
  button_upload: 'upload',
  button_export: 'export',
  button_details: 'details',
  button_test_connection: 'Connection test',
  button_bind: 'binding',
  button_unbind: 'unbind',
  button_retry: 'retry',
  button_shouQi: 'Close',
  button_zhanKai: 'Open',
  link_back_to_list: 'Back to list',
  lang_zh_cn: 'chinese',
  lang_en: 'english',
  lang_zh_tw: 'traditional Chinese character',
  confirm_error_tip: 'Error prompt',
  confirm_reload_label: 'Refresh page',
  list_operation: 'operation',
  start_time: 'Start time',
  end_time: 'End time',
  user_name: 'User name',
  user_nick_name: 'Nickname',
  user_name_id: 'User ID',
  user_password: 'Password',
  user_phone: 'mobile phone',
  user_phone_number: 'cell-phone number',
  user_email: 'mailbox',
  user_avatar: 'Avatart',
  user_wechat: 'WeChat',
  operate_delete_fail: 'Delete failed',
  operate_update_success: 'Modified successfully',
  symbol_colon: '：',
  gl_qr_code_wx_public_account: 'WeChat public account',
  gl_qr_code_tip: 'Code scanning consultation',
  gl_qr_code_wx_customer_service: 'WeChat customer service',
  gl_telephone_tip: 'Telephone consultation',
  workbench_manage: 'Workbench',
  workbench_quick_start: 'Quick start',
  workbench_notice: 'Announcement notice',
  workbench_overview: 'Overview',
  workbench_guide: "Beginner's guide",
  workbench_agent_desc:
    'Welcome to Tapdata Cloud, you are about to start your real-time data synchronization journey! Please install and deploy the Agent for the first use, otherwise the task cannot be run. ',
  workbench_agent_button_create: 'Create Agent',
  workbench_connection_desc:
    "Data connection is mainly used to establish the connection between the Agent and the user's source database and target database. Come and create a data connection, and test and manage the status of the existing data connection. ",
  workbench_connection_button_create: 'Create connection',
  workbench_task_desc:
    'Task management is mainly used to create and manage synchronization tasks. Come and create a data synchronization task, and view and manage the types and status of existing data synchronization tasks. ',
  workbench_task_button_create: 'Create task',
  workbench_overview_connection: 'Connect',
  workbench_overview_connection_ready: 'Active',
  workbench_overview_connection_invalid: 'Invalid',
  workbench_overview_task: 'Task',
  workbench_guide_novice: 'Novice Guide',
  workbench_guide_documentation: 'Product Documentation',
  workbench_guide_problem: 'Common problems',
  workbench_guide_data_safe: 'How does Tapdata cloud ensure data security? ',
  workbench_statistics_title: 'Task data volume statistics',
  workbench_statistics__sub_title: 'Input data volume',
  workbench_statistics__sub_title_label: 'cumulative',
  header_scan_code: 'Encountered problems during use? ',
  header_join_group: 'Scan the code to add a small assistant to get technical support',
  header_manual: 'User Manual',
  header_technical_support: 'Technical Support',
  header_upgrade: 'Access old version',
  header_official_website: 'Official website',
  header_sign_out: 'Sign out',
  header_welcome: 'Hi, welcome to use',
  header_tutorials_tip: 'We have prepared a detailed novice guide for you, so that you can get started faster~',
  header_more_reminders: 'No more reminders',
  header_log_out_title: 'Logout',
  header_log_out_tip: 'Are you sure you want to log out? ',
  header_notify: 'Notification',
  header_notification_content: 'Notification content',
  header_your: 'Your ',
  header_no_notice: 'No notice yet',
  header_setting: 'Settings',
  header_view_notifications: 'View all notifications',
  notify_setting: 'Notify settings',
  notify_agent_notification: 'agent notification',
  notify_sms_notification: 'SMS notification',
  notify_email_notification: 'email notification',
  notify_agent_status_offline: 'Agent status is offline',
  notify_agent_status_running: 'Agent status is running',
  notify_agent_status_error: 'Error in task operation',
  notify_task_running_notification: 'Task running notification',
  notify_sync_task: 'Sync task',
  notify_migration_task: 'Migration task',
  notify_task: 'task',
  notify_agent: 'Agent',
  notify_inspect: 'Verify task',
  notify_jobDDL: 'DDL processing',
  notify_task_longer_exists: 'Your task no longer exists',
  notify_list: 'Notification list',
  notify_mark_read: 'Mark as read',
  notify_all_read: 'all read',
  notify_notification_content: 'Notification content',
  notify_day: 'day',
  notify_notification_time: 'Notification time',
  notify_your: 'Your ',
  notify_no_notice: 'No notification yet',
  notify_delete_notification_tip: 'Are you sure to delete the notification?',
  notify_delete_notification_title: 'Delete notification',
  notify_delete_all_notification_message: 'Are you sure to delete all notifications?',
  notify_list_started: 'started',
  notify_list_paused: 'Paused',
  notify_list_edited: 'Edited',
  notify_list_deleted: 'deleted',
  notify_list_abnormally_stopped: 'abnormally stopped, please pay attention!',
  notify_list_stopped_by_error: 'stopped by error, please pay attention!',
  notify_list_startup_failed: 'startup failed',
  notify_list_stop_failed: 'stop failed',
  notify_list_encounter_error_skipped: 'skip an ERROR',
  notify_list_connection_interrupted: 'connection interrupted',
  notify_list_connected: 'has returned to normal!',
  notify_list_inspect_count: 'Verify job count difference',
  notify_list_inspect_value: 'Verify job field value difference',
  notify_list_inspect_delete: 'Verify job was deleted',
  notify_list_inspect_error: 'Verify job error',
  notify_list_approaching: 'Remaining',
  notify_list_agent_started: 'Agent started',
  notify_list_agent_stopped: 'Agent stopped',
  notify_list_agents_failed: 'Agent start failed',
  notify_list_agent_stop: 'Agent stop failed',
  notify_list_agent_created: 'Agent created',
  notify_list_agent_deleted: 'Agent deleted',
  notify_list_will_release_agent: 'will be released soon',
  notify_list_releases_agent: 'has been reclaimed',
  tap_home: 'Home',
  tap_workbench: 'Workbench',
  tap_announcement_notice: 'Announcement Notice',
  tap_system_notification: 'System notification',
  tap_agent_management: 'Agent Management',
  tap_instance_details: 'instance details',
  tap_connection_management: 'Connection Management',
  tap_create_connection: 'Create connection',
  tap_edit_connection: 'Edit connection',
  tap_task_management: 'Task Management',
  tap_create_task: 'Create task',
  tap_edit_task: 'Edit task',
  tap_monitor: 'Run monitoring',
  tap_task_details: 'Task details',
  tap_data_validation: 'Data validation',
  tap_difference_check_details: 'Difference check details',
  tap_check_result: 'Check result',
  tap_difference_check_history: 'Difference check history',
  tap_operation_log: 'Operation log',
  tap_agent_download: 'Agent download',
  tap_agent_download_now: 'Agent download now',
  tap_upgrade: 'Agent upgrade',
  tap_user_center: 'User center',
  agent_key: 'Agent',
  agent_manage: 'Agent',
  agent_name: 'Agent Name',
  agent_id: 'Agent ID',
  agent_task_number: 'Number tasks',
  agent_create_time: 'Creation time',
  agent_version: 'Version',
  agent_status: 'Status',
  agent_status_all: 'All status',
  agent_status_creating: 'Creating',
  agent_status_running: 'Running',
  agent_status_stopped: 'Stopped',
  agent_status_stopping: 'Stopping',
  agent_search: 'Search by ID/Agent name',
  agent_test_use: 'For testing use only',
  agent_button_create: 'Create Agent',
  agent_button_order1: 'Order Instance1',
  agent_button_order2: 'Order Instance2',
  agent_button_deploy: 'Deploy',
  agent_button_deploy_now: 'Deploy now',
  agent_button_deploy_later: 'Deploy later',
  agent_button_auto_upgrade: 'Auto update',
  agent_button_manual_upgrade: 'Manual upgrade',
  agent_tip_auto_upgrade: 'Unable to use "Auto upgrade" when Agent is offline',
  agent_dialog_upgrade_title:
    'The Agent version is updated. You can upgrade your Agent to the latest version in the following ways. Tasks cannot be run during the upgrade process.',
  agent_dialog_upgrade_fail: 'Auto upgrade failed, please try again or upgrade manually!',
  agent_button_create_msg_success: 'Agent created successfully',
  agent_button_create_msg_success_desc:
    'Please click [Deploy] to enter the deployment page and follow the instructions to complete the Agent deployment.',
  agent_button_stop_tip: 'Whether to stop',
  agent_button_stop_tip_running:
    'There is a task currently running on the Agent. Forcibly stopping the Agent may cause the task to be abnormal. Do you want to forcibly stop it?',
  agent_button_stop_tip_no_running:
    'After the Agent is stopped, the task can no longer be run. You need to go to the Agent installation directory to start the Agent again. Are you sure to stop?',
  agent_button_stop_msg_success: 'Agent is stopped',
  agent_button_stop_msg_fail: 'Agent failed to stop',
  agent_button_delete_confirm_title: 'The agent can no longer be used after it is deleted. Are you sure to delete it?',
  agent_button_delete_confirm_msg:
    'There are tasks currently running on the Agent. Please stop the tasks before deleting them.',
  agent_button_delete_success: 'Agent deleted successfully',
  agent_button_delete_fail: 'Agent deletion failed',
  agent_auto_upgrade_tip_running_task:
    'It has been detected that you have a task running, please stop all tasks under this agent before proceeding with the upgrade operation!',
  agent_auto_upgrade_tip_start: 'Start to upgrade',
  agent_auto_upgrade_tip_upgrading: 'Automatically upgrading',
  agent_auto_upgrade_tip_progress: 'Upgrade package download progress',
  agent_auto_upgrade_tip_fail: 'Automatic upgrade failed, please upgrade manually',
  agent_auto_upgrade_tip_have_new: 'Agent version is updated, click to upgrade',
  agent_button_create_tip: 'Create an Agent？',
  agent_detail_synchronization_task_number: 'Number of synchronization tasks',
  agent_detail_version: 'Agent version',
  agent_detail_create_time: 'Agent creation time',
  agent_detail_host_name: 'Host host name',
  agent_detail_host_ip: 'Host IP',
  agent_detail_host_cpu_number: 'Host CPU number',
  agent_detail_host_cpu_memory: 'Host CPU memory',
  agent_detail_host_memory_size: 'Host memory size',
  agent_detail_installation_manual: 'Installation directory',
  agent_detail_run_manual: 'Log directory',
  agent_list_empty_desc1: 'Come soon',
  agent_list_empty_desc2: 'Start real-time data synchronization~',
  agent_error_check: 'Agent current status is abnormal, please check',
  agent_deploy_title: 'Agent download and installation',
  agent_deploy_select_tip:
    'Tapdata DFS Cloud Edition needs to install the Agent locally to ensure the normal operation of the database connection and data transmission service. You can select the corresponding type below to download and install according to the type of server to be installed.',
  agent_deploy_before_prepare_title: 'Prepare before installation',
  agent_deploy_before_prepare_windows_first:
    '1. Before installation, please make sure that Java 1.8 is installed in your deployment environment and the environment variables are correctly configured. ',
  agent_deploy_before_prepare_windows_first_link: 'Click to see how to install and configure Java 1.8',
  agent_deploy_before_prepare_windows_second:
    '2. Click the download button below to download the Tapdata Agent installation package to the local environment. ',
  agent_deploy_before_prepare_windows_second_download: 'Click to download Tapdata Agent',
  agent_deploy_before_prepare_windows_third:
    '3. Please strictly follow the installation steps below to deploy, do not double-click the installation package directly! ',
  agent_deploy_before_prepare_windows_four:
    '4. If the installation path includes Chinese or special characters, the installation may fail.',
  agent_deploy_start_install: 'Start installation',
  agent_deploy_start_install_button_copy: 'Copy',
  agent_deploy_start_install_button_copied: 'Copied',
  agent_deploy_start_install_windows_first: '1. Click',
  agent_deploy_start_install_windows_first_download: 'Download Tapdata Agent',
  agent_deploy_start_install_windows_second:
    '2. Put tapdata.exe into the directory you want to install. The installation path cannot contain Chinese and special characters. ',
  agent_deploy_start_install_windows_third: '3. Double-click to execute tapdata.exe to start the installation. ',
  agent_deploy_start_install_windows_fourth:
    '4. When the installation process prompts you to enter the Token, copy the Token below and right-click in the command window to paste it',
  agent_deploy_start_install_windows_fifth:
    '5. Wait patiently to complete the installation and startup of Tapdata Agent. ',
  agent_deploy_link_agent_operation: '"Agent Installation Manual and Common QA"',
  agent_deploy_link_agent_operation_desc:
    'Or directly scan the QR code on the right to join the community for technical support. ',
  agent_deploy_before_prepare_linux_first:
    '1. Before installation, please make sure that Java 1.8 is installed in your deployment environment and the environment variables are correctly configured. ',
  agent_deploy_before_prepare_linux_first_link: 'Click to see how to install and configure Java 1.8',
  agent_deploy_before_prepare_linux_second:
    '2. We highly recommend deploying Tapdata Agent in a separate and clean folder.',
  agent_deploy_before_prepare_linux_third:
    '3. Download and deploy Tapdata Agent without root permission, only need to have read and write permissions on the deployment directory',
  agent_deploy_start_install_linux_first:
    '1. Please copy the following command and execute it in the local deployment environment, which includes the download, automatic deployment and startup of Tapdata Agent:',
  agent_deploy_start_install_linux_second:
    '2. After the above command is executed, the log as shown in the figure below appears, which means that the agent started successfully:',
  agent_deploy_start_install_linux_third:
    '3. If you encounter any problems during installation and use, please refer to',
  agent_deploy_before_prepare_docker_first:
    '1. We provide an image that contains the environment required for Tapdata Agent to run.',
  agent_deploy_before_prepare_docker_second:
    '2. First, your deployment environment must have Docker installed before you can use Docker to install, if not installed, please refer to',
  agent_deploy_before_prepare_docker_install_link: '《Docker Installation》',
  agent_deploy_before_prepare_docker_second_install: 'Proceed to install.',
  agent_deploy_start_install_docker_first:
    '1. Please copy the following command and execute it in the deployment environment, which includes the download and operation of the image, the download, automatic deployment and start of the Tapdata Agent:',
  agent_deploy_start_install_docker_second:
    '2. After the docker installation is successful, the container ID of the installed Agent will be automatically output. You can use the docker ps command to view the running docker:',
  agent_deploy_start_install_docker_third:
    "3. If you need to view the agent's log or start and stop the agent, please refer to",
  agent_upgrade_title: 'Agent version upgrade',
  agent_upgrade_select_tip:
    'The system has detected that your Agent is not the latest version, please follow the instructions to upgrade',
  agent_upgrade_before_title: 'Before upgrade',
  agent_upgrade_step_title: 'Upgrade step',
  agent_deploy_upgrade_button_copy: 'Copy',
  agent_deploy_upgrade_button_copied: 'copied',
  agent_upgrade_before_windows_first: '1. Backup the tapdata.exe of the existing program',
  agent_upgrade_before_windows_second:
    '2. Download the new version of tapdata.exe program and put it in the program directory',
  agent_upgrade_before_windows_second_download: 'Click to download',
  agent_upgrade_before_windows_third: '3. Follow the upgrade steps',
  agent_upgrade_step_windows_first: '1. Open the cmd window and enter the original Agent installation directory',
  agent_upgrade_step_windows_second:
    '2. Copy the upgrade command below and execute it in the directory. The upgrade command will automatically back up, upgrade and start. If the upgrade fails, it will automatically roll back the version.',
  agent_upgrade_step_windows_third:
    '3. If "Update finished." appears, it means the Agent has been successfully upgraded',
  agent_upgrade_step_linux_first: '1. Enter the original Agent installation directory',
  agent_upgrade_step_linux_second:
    '2. Copy the upgrade command below and execute it in the directory. The upgrade command will automatically back up, upgrade and start. If the upgrade fails, it will automatically roll back the version.',
  agent_upgrade_step_linux_third: '3. If "Update finished." appears, it means the Agent has been successfully upgraded',
  agent_upgrade_step_docker_first: '1. Enter the docker container of the original Agent',
  agent_upgrade_step_docker_first_one: "(1) Found the original agent's docker container CONTAINER ID",
  agent_upgrade_step_docker_first_two: '(2) Enter the container through the container ID',
  agent_upgrade_step_docker_first_three:
    '(3) If the container has stopped running, you can start the container first and then enter the container to upgrade',
  agent_upgrade_step_docker_first_four: 'Start the container',
  agent_upgrade_step_docker_first_five: 'Enter the container',
  agent_upgrade_step_docker_second:
    '2. Copy the upgrade command below to execute directly in the container, the upgrade command will automatically back up, upgrade and start, if the upgrade fails, it will automatically roll back the version',
  agent_upgrade_step_docker_third:
    '3. If "Update finished." appears, it means the Agent has been successfully upgraded',
  connection_manage: 'Connection',
  connection_list_column_schema_status: 'Schema loading status',
  connection_list_column_schema_status_tips: 'Connections after Schema loading can be created normally',
  connection_list_form_all_status: 'All status',
  connection_list_form_search: 'Search by connection name',
  connection_list_name: 'Connection name',
  connection_list_status: 'Status',
  connection_list_schema_load_progress: 'Schema loading progress',
  connection_list_type: 'Type',
  connection_list_source: 'Source',
  connection_list_target: 'Target',
  connection_list_source_and_target: 'Source and target',
  connection_list_change_time: 'Modify Time',
  connection_list_test: 'Connection Test',
  connection_list_edit: 'Edit',
  connection_list_copy: 'Copy',
  connection_list_delete: 'Delete',
  connection_list_test_failed: 'Test connection failed',
  connection_list_task_occupied: 'This connection is occupied by a task and cannot be deleted',
  connection_list_delete_failed: 'Deletion failed',
  connection_list_delete_success: 'Delete successfully',
  connection_list_copy_success: 'Copy successful',
  connection_list_copy_failed:
    'Copying failed because of the reason: "Connection Settings-Allow the creation of duplicate data sources" in the system settings is set to "false"',
  connection_list_delete_connection: 'Delete connection',
  connection_list_delete_connection_tip: 'After this, this connection will not be restored',
  connection_list_delete_connection_title: 'Do you want to delete this connection? ',
  connection_list_efficient: 'effective',
  connection_list_invalidation: 'Invalid',
  connection_list_testing: 'Testing',
  connection_form_creat_connection: 'Create connection',
  connection_form_edit_connection: 'Edit connection',
  connection_form_data_source: 'Data source',
  connection_form_data_source_type: 'Data source type',
  connection_form_connection_name: 'Connection name',
  connection_form_database_address: 'Database address',
  connection_form_port: 'Port',
  connection_form_database_name: 'Database name',
  connection_form_database_username: 'Account',
  connection_form_database_password: 'Password',
  connection_form_additional_string: 'Other connection string parameters',
  connection_form_timezone: 'Time zone of time type',
  connection_form_virtual_host: 'Virtual Host',
  connection_form_route_key_field: 'Message routing',
  connection_form_mq_topic_set: 'topic name',
  connection_form_mq_queue_set: 'Queue name set',
  connection_form_broker_url: 'MQ connection string',
  connection_form_mq_type: 'MQ Type',
  connection_form_kafka_ignore_push: 'Ignore push message exception',
  connection_form_kafka_compression_type: 'Message compression type',
  connection_form_kafka_ack: 'ACK confirmation mechanism',
  connection_form_kafka_ignore_invalid: 'Ignore non-JSON Object format messages',
  connection_form_kafka_pattern_topic: 'topic expression',
  connection_form_connection_name_placeholder: 'Please enter the connection name',
  connection_form_coming_soon: 'Coming soon',
  connection_form_impact_type: 'Type of impact: DATE',
  connection_form_database_host_placeholder: 'Please enter the database address',
  connection_form_database_host_tips:
    'Database address (127.0.0.1/Domain: (port), please use multiple addresses, separate)',
  connection_form_name_rules:
    'Begin with Chinese and English, 1-100 characters, including Chinese and English, numbers, underscores, underscores, spaces',
  connection_form_no_name: 'The connection name cannot be empty',
  connection_form_name_exists: 'Name already exists',
  connection_form_kafka_host_tip: 'Enter IP/host:port, multiple addresses are separated by commas',
  connection_form_kafka_lonore_format_tip:
    'If it is turned on, it will ignore the message if it encounters a parsing exception, otherwise it will stop pulling the message',
  connection_form_kafka_ignore_push_error_tip:
    'If it is enabled, ignore the push message (there is a message loss), otherwise stop pushing the message',
  connection_form_dameng_database_owner_tip:
    'Comma-separated expression list, use * to represent any character of any length',
  connection_form_mq_queue_tip: 'Multiple queues are separated by commas',
  connection_form_mq_topic_tip: 'Multiple topics are separated by commas',
  connection_form_mq_broker_url: 'MQ connection string',
  connection_form_mq_broker_url_tip: 'Example tcp://127.0.0.1:61616, supports tcp, nio, udp, ssl, http(s)',
  connection_form_change: 'Change',
  connection_form_rename: 'Rename',
  connection_form_give_up: 'Give up',
  connection_form_database_owner_tip:
    'Comma separated expression list, using * to represent any character of any length',
  connection_form_confirm_edit: 'This operation will lose the current edit content',
  connection_form_confirm_create: 'This operation will lose the connection currently being created',
  connection_form_confirm_create_content: 'Do you want to abandon the creation of the connection ?',
  connection_form_confirm_edit_content: 'Do you want to abandon the modification of the content ?',
  connection_form_vika_plain_password: 'Interface Authentication Token',
  connection_form_vika_space_id: 'Space station name',
  connection_form_qingflow_tag_name: 'Application package name',
  connection_form_hazecast_name_exists: 'Name already exists',
  connection_form_hazecast_give_up: 'Give up',
  connection_form_hazecast_confirm_edit: 'This operation will lose the current edit content',
  connection_form_hazecast_confirm_create: 'This operation will lose the connection currently being created',
  connection_form_hazecast_confirm_create_content: 'Do you want to abandon the creation of the connection ?',
  connection_form_hazecast_confirm_edit_content: 'Do you want to abandon the modification of the content ?',
  connection_form_hazecast_database_name: 'Cluster Name',
  connection_form_hazecast_database_name_placeholder: 'Please enter the cluster name',
  connection_form_hazecast_database_name_empty: 'The cluster name cannot be empty',
  connection_form_hazecast_plain_password: 'Token',
  connection_form_hazecast_plain_password_placeholder: 'Please enter the token',
  connection_form_hazecast_plain_password_empty: 'Token cannot be empty',
  connection_form_hazecast_ssl: 'Enable SSL',
  connection_form_hazecast_sslKey: 'Key Store File',
  connection_form_hazecast_sslCA: 'Trust Key Store File',
  connection_form_hazecast_sslPass: 'Key File Password',
  connection_form_hazecast_sslPass_placeholder: 'Please enter the key file Password',
  connection_form_hazecast_none_sslKey: 'The key store file cannot be empty',
  connection_form_hazecast_none_sslCA: 'The trust key store file cannot be empty',
  connection_form_tidb_server: 'PDServer address',
  connection_form_tidb_none_server: 'PDServer address cannot be empty',
  connection_form_mongo_standard_mode_tip:
    'This mode connects to a separate server in the network that provides a TSL / SSL channel to the database. If your database is on an inaccessible subnet, you can try this method',
  connection_form_doris_http: 'http interface address',
  connection_form_doris_http_tip: 'http interface address cannot be empty',
  connection_test_schema_tips:
    'Possible reason: There is a problem with the Schema case setting, you can try to modify the case and try again',
  connection_preview_load_schema: 'Load Schema',
  connection_preview_edit: 'Edit',
  connection_preview_test: 'Test',
  connection_preview_no_sure: 'Do not confirm',
  connection_preview_master_partition: 'Write to master partition only',
  connection_preview_isr_partition: 'Write all ISR partitions',
  connection_preview_operation_success: 'Operation successful',
  task_manage: 'Task',
  task_manage_etl: 'Data development',
  task_manage_migrate: 'Data copy',
  task_name: 'Task name',
  task_status: 'Status',
  task_sync_type: 'Synchronization type',
  task_name_or_node_name_or_library_name: 'Name',
  task_status_running: 'Running',
  task_status_paused: 'Paused',
  task_status_error: 'Error',
  task_status_draft: 'Draft',
  task_status_scheduled: 'Scheduled',
  task_status_stopping: 'Stopping',
  task_status_force_stopping: 'Force stopping',
  task_status_finished: 'Finished',
  task_milestone_waiting: 'Waiting',
  task_milestone_running: 'Running',
  task_milestone_error: 'Error',
  task_milestone_finish: 'Finish',
  task_milestone_paused: 'Paused',
  task_sync_type_cdc: 'CDC',
  task_create_task: 'Create task',
  task_agent: 'belonging to agent',
  task_type: 'Task type',
  task_start_time: 'Start time',
  task_next_run_time: 'Next run time',
  task_config_not_completed: 'Task configuration is not completed and cannot be started',
  task_start_task: 'Start task',
  task_stop_task: 'Stop task',
  task_forced_stop: 'Forced stop',
  task_operation_monitor: 'Operation monitoring',
  task_initial_sync: 'initial_sync',
  task_cdc: 'cdc',
  task_initial_sync_cdc: 'initial_sync + cdc',
  task_reset_tsk: 'Do you want to reset this task? ',
  task_reset: 'Reset',
  task_reset_success: 'Reset success',
  task_reset_failed: 'Reset failed',
  task_operation_successful: 'Operation successful',
  task_start_failed: 'Task failed to start, please edit the task to complete the mapping configuration',
  task_not_exist: 'This task does not exist',
  task_not_allow_operation: 'Task status does not allow this operation',
  task_operation_failed: 'The operation failed, please try again',
  task_delete_confirm_title: 'Do you want to delete this task? ',
  task_delete_confirm_message: 'After deleting task xxx, this task cannot be restored',
  task_stop_confirm_title: 'Do you want to suspend this task? ',
  task_stop_confirm_message:
    'After suspending task xxx, when the table in the task that has not been fully synchronized is started again, full synchronization will be performed again',
  task_force_stop_confirm_title: 'Do you want to force stop this task? ',
  task_force_stop_confirm_message:
    'Forcibly stop task xxx will immediately interrupt the data transmission to force the task to stop quickly and reset the task',
  task_initialize_confirm_title: 'Do you want to reset this task? ',
  task_initialize_confirm_message:
    'Resetting task xxx will clear the task synchronization progress and the task will be executed again',
  task_pause_tip:
    'If a task of initialization type is paused and started again, the task will be synchronized from the beginning. Are you sure to pause?',
  task_important_reminder: 'Important reminder',
  task_stop_tip:
    'Task XXX contains aggregation processing nodes. After the task is stopped and restarted, the task will be reset first. Are you sure to stop? ',
  task_copy_success: 'Copy successful',
  task_copy_failed: 'Copy failed',
  task_delete_success: 'Delete successfully',
  task_delete_failed: 'Delete failed',
  task_list_edit_tip: 'If the task settings are modified',
  task_list_edit_tip1: ' Node typesetting process',
  task_list_node_attr: 'Node attribute',
  task_list_matching_releation: 'Matching relationship',
  task_list_edit_submit: 'Must be submitted after submission',
  task_list_edit_reset: ' Reset ',
  task_list_edit_tip3:
    'It can run normally, otherwise it may cause an abnormal error. Do you want to continue editing?',
  task_list_continue_edit: 'Continue editing',
  task_form_select_connection: 'Select connection',
  task_form_set_task_properties: 'Set task properties',
  task_form_select_table: 'Select table',
  task_form_table_field: 'Table field mapping',
  task_form_connection_tip:
    "If you haven't added a data source yet, please go to the connection management to add it first. ",
  task_form_go_to_connection_tip: 'Go to connection management to create a connection',
  task_form_task_setting: 'Task Settings',
  task_form_task_setting_tip:
    'Users can set the task name, synchronization type, error handling, etc. in the task setting step. Please check the help file for specific configuration instructions.',
  task_form_sync_tip:
    'Users can click the arrow button to the right in the middle to check the tables to be synchronized at the source and move these tables to the queue of tables to be synchronized (after the task is executed, these tables will be synchronized and transmitted)',
  task_form_task_cannot_empty: 'Task name cannot be empty',
  task_form_task_name_limit: 'Task name exceeds character limit',
  task_form_already_exists: 'Task name already exists',
  task_form_mapping_setting: 'Mapping settings',
  task_form_source_target_connection: 'Select the source and target connection',
  task_form_table_setting: 'Table Settings',
  task_form_table_name_cannot_consistent:
    'Reminder: You have selected the same data source as the source and target. In order to ensure that your task can be executed smoothly, please modify the target table name to be inconsistent with the original table. ',
  task_form_validation_failed: 'Form validation failed',
  task_form_no_bable_tip:
    'Please select the table to be synchronized first, if the selected data source does not have a table, please create a table in the database first',
  task_form_update_write_mode: 'Update write mode',
  task_form_update_write_mode_tip:
    'The update write mode will determine whether each piece of data at the source end exists on the target end, if it exists, it will be updated, and if it does not exist, it will be added. ',
  task_form_full_sync: 'Full sync',
  task_form_full_sync_tip:
    'Full synchronization is also called initial synchronization, that is, the source data snapshot is read at the start of the task and synchronized to the target; this synchronization has two modes: update write, delete rewrite. ',
  task_form_all: 'All',
  task_form_database_clone: 'Database clone',
  task_form_no_fields_not_save:
    'All fields in the current table have been deleted, and the save operation is not allowed',
  task_form_lost_task: 'This operation will lose the task currently being created/edited',
  task_form_give_up: 'Whether to give up creating/editing this task',
  task_form_model_deduction_failed: 'Model deduction failed',
  task_form_no_table_available: 'No table available? ',
  task_form_reload: 'Reload',
  task_form_field_mapping: 'Field mapping',
  task_form_regular:
    'Start with an English letter, only support English, numbers, underscores, dots, and underscores, with a limit of 0~50 characters',
  task_form_regular_not_system: 'The prefix is ​​not allowed to start with system',
  task_form_regular_header:
    'Start with English letters and underscores, only support English, numbers, underscores, dots, and underscores, limited to 0~50 characters',
  task_form_following_rules: 'Please enter according to the following rules:',
  task_form_field_mapped: 'Field to be mapped',
  task_form_mapped_fields: 'Mapped fields',
  task_form_field_limit:
    'Start with English letters and underscores, only support English, numbers, and underscores, with a limit of 1~50 characters',
  task_form_right_field_duplicate: 'Duplicate name with the field on the right, no further movement allowed',
  task_form_mapping_field_cannot_empty: 'The mapping field cannot be empty',
  task_form_table_reset:
    'Modifying the table name at this time will reset the existing table settings, are you sure to modify?',
  task_form_restore_table:
    'At this time, restoring the table name will reset the existing table settings. Are you sure to restore?',
  task_form_reloadFail: 'Schema loading failed',
  task_form_source_type: 'Source type',
  task_form_source_connection: 'Source connection',
  task_form_target_type: 'Target type',
  task_form_target_connection: 'Target connection',
  task_form_setting_sync_points_tip:
    'For the time point setting of incremental collection, only mysql, SQL server, Oracle and mongodb sources are supported temporarily.',
  task_monitor_progress: 'Task progress',
  task_monitor_full_sync: 'Full synchronization overview',
  task_monitor_full_completion_time: 'It is estimated that full completion will take time',
  task_monitor_cdc_overview: 'Incremental synchronization overview',
  task_monitor_delay: 'Delay',
  task_monitor_progress_details: 'Progress details',
  task_monitor_cdc_details: 'Incremental details',
  task_monitor_source_library: 'Source library',
  task_monitor_time: 'Time',
  task_monitor_target_library: 'Target library',
  task_monitor_status_statistice: 'Status Statistics',
  task_monitor_migrate_table_number: 'Number of tables planned to be migrated',
  task_monitor_migrate_table_rows: 'Planned migration data volume (rows)',
  task_monitor_migrate_table_number_completed: 'Number of completed migration tables',
  task_monitor_migrate_table_rows_completed: 'Completed migration data volume (rows)',
  task_monitor_migrate_tip:
    '*Current task progress view only supports: MySQL, Oracle, SQL Server, PostgreSQL and MongoDB',
  task_monitor_unit_row: 'Unit:/rows',
  task_monitor_unit_second: 'Unit:/sec',
  task_monitor_not_start: 'Not started',
  task_monitor_founder: 'creator',
  task_monitor_start: 'Start',
  task_monitor_stop: 'Stop',
  task_monitor_reset: 'Reset',
  task_monitor_forced_stop: 'Forced stop',
  task_monitor_total_output: 'Total output',
  task_monitor_total_input: 'Total input',
  task_monitor_total_insert: 'Total Insert',
  task_monitor_total_update: 'Total update',
  task_monitor_total_delete: 'Total delete',
  task_monitor_execution_time: 'This execution time',
  task_monitor_end_time: 'End time of this time',
  task_monitor_cdc_time: 'The time point of the increment',
  task_monitor_run_log: 'Run log',
  task_monitor_run_connection: 'Connect',
  task_monitor_history_run_record: 'History run record',
  task_monitor_mission_milestone: 'Mission Milestone',
  task_monitor_no_milestone_data:
    'This task has not been started or has been reset. There is no running milestone data yet',
  task_monitor_task_details: 'Task details',
  task_monitor_status: 'Status',
  task_monitor_sync_content: 'Sync content',
  task_monitor_source_info: 'Source information',
  task_monitor_node_name: 'Node name',
  task_monitor_owned_library: 'owned library',
  task_monitor_database_addr: 'Database address',
  task_monitor_database_type: 'Database Type',
  task_monitor_target_info: 'Target information',
  task_monitor_topic_name: 'topic name',
  task_monitor_topic_expressionL: 'topic expression',
  task_monitor_migration_task: 'Migration task',
  task_monitor_sync_task: 'Synchronous task',
  task_info_start: 'Start',
  task_info_stopt: 'Stop',
  task_info_data_screening: 'Event Statistics',
  task_info_input_output: 'Input and output statistics',
  task_info_throughputpop:
    'Input and output statistics: average source data collection speed and target write speed per second, the larger the value, the better',
  task_info_overview: 'Overview',
  task_info_plan: 'Plan',
  task_info_table_number: 'Number of tables',
  task_info_completed: 'Completed',
  task_info_expected: 'Expected',
  task_info_completed_time: 'Completed time',
  task_info_info: 'Details',
  task_info_synced: 'Synced',
  task_info_sync_running: 'Synchronizing',
  task_info_sync_waiting: 'To be synchronized',
  task_info_sync_pause: 'Paused',
  task_info_task_stopped: 'Task has been stopped',
  task_info_progress: 'in progress',
  task_info_stopped: 'Stopped',
  task_info_s: 'seconds',
  task_info_m: 'minutes',
  task_info_h: 'Hour',
  task_info_d: 'day',
  task_info_fully_completed: 'Fully completed',
  task_info_task_init: 'Task Initialization',
  task_info_task_structure: 'Structure migration',
  task_info_task_cdc: 'Incremental synchronization',
  task_info_input: 'input',
  task_info_output: 'Output',
  task_info_log_placeholder: 'Please enter the log content',
  task_info_no_more: 'No more',
  task_info_source_database: 'Source database',
  task_info_target_database: 'Target database',
  task_info_cdc_time: 'The time point of the increment',
  task_info_source_table: 'Source data table',
  task_info_data_row: 'Data volume (row)',
  task_info_target_table: 'Target data table',
  task_info_amount_sync_data: 'Completed synchronization data amount (rows)',
  task_info_completed_schedule: 'Fully completed progress',
  task_info_schedule: 'Progress',
  task_info_table_name: 'table name',
  task_info_milestone: 'Milestone',
  task_info_error: 'Error',
  task_info_forced_stop_task: 'Force stop task',
  task_info_running_time: 'running start time',
  task_info_running_end_time: 'Running end time',
  task_info_operator: 'Operator',
  task_info_operator_content: 'Operation content',
  task_info_connection_test: 'Test',
  task_info_lag_time: 'lag time',
  task_info_history_start_type: 'Operation mode',
  task_info_history_running_status: 'running state ',
  task_info_history_start_type_manual: 'Manual operation',
  task_info_history_start_type_auto: 'Regular scheduling',
  task_setting_sync_type: 'Sync type',
  task_setting_initial_sync: 'INITIAL SYNC',
  task_setting_cdc: 'CDC',
  task_setting_initial_sync_cdc: 'INITIAL SYNC + CDC',
  task_setting_initial_sync_tip:
    'INITIAL SYNC is also called initial synchronization, that is, the source data snapshot is read at the start of the task and synchronized to the target; this synchronization has two modes: update write, delete rewrite. ',
  task_setting_cdc_tip:
    'Incremental synchronization refers to the collection and analysis of the stored source-end change log from the start of the task, the orderly synchronization of data changes to the target end, and support for addition, deletion, and modification operations. ',
  task_setting_initial_sync_cdc_tip:
    'Select the INITIAL SYNC + CDC mode, the task will automatically enter the incremental synchronization state after the full synchronization is completed. ',
  task_setting_full_write_mode: 'Full write mode',
  task_setting_update_write_mode: 'Update write mode',
  task_setting_remoive_rewrite_mode: 'Remove rewrite mode',
  task_setting_update_write_mode_tip:
    'The update write mode will determine whether each piece of data at the source end exists on the target end, if it exists, it will be updated, and if it does not exist, it will be added. ',
  task_setting_remoive_rewrite_mode_tip:
    'Delete overwrite mode will first empty the data in the target table, and then synchronize all the source data to the target, ensuring that the data on the source and target are completely consistent. ',
  task_setting_append_rewrite_mode: 'Append write mode',
  task_setting_append_rewrite_mode_tip:
    'The append write mode will only append the newly added data from the source to the target, and will not update or delete the data on the target. ',
  task_setting_read_number: 'Number of reads per time',
  task_setting_read_number_cannot_empty: 'The number of reads per time cannot be empty, the default is 1000',
  task_setting_read_number_ranges: 'The number of reads per time ranges from 1 to 999999',
  task_setting_read_number_only_number: 'The number of each read can only be a number',
  task_setting_stop_on_error: 'Encountered an error to stop',
  task_setting_incremental_concurrency_switch: 'Whether to enable incremental concurrency',
  task_setting_incremental_concurrency: 'Incremental Concurrency',
  task_setting_incremental_concurrency_cannot_empty: 'Incremental concurrency cannot be empty, the default is 8',
  task_setting_incremental_concurrency_only_number: 'Incremental concurrent number can only be a number',
  task_setting_no_primary_sync_switch: 'Whether there is no primary key synchronization',
  task_setting_two_way_switch: 'Whether it is two-way',
  task_setting_automatic_ddl: 'Automatic DDL',
  task_setting_automatic_ddl_tip:
    'Automatic DDL operations support the renaming of fields and indexes, as well as operations such as adding, deleting, and updating',
  task_setting_automatic_index: 'Automatically create index',
  task_setting_sync_points: 'Start time of incremental acquisition',
  task_setting_cron_expression: 'Scheduled tasks',
  task_setting_schedule_time: 'Scheduled run time',
  task_setting_task_name_already_exists: 'Task name already exists',
  task_setting_cron_expression_valid_false: 'Scheduling expression error',
  task_instance_select_area: 'Select area',
  task_instance_choose_area: 'Select Availability Zone',
  task_mapping_table_setting: 'Table Settings',
  task_mapping_table_setting_tip:
    'Users can set the fields to be synchronized for each table in the source database on this page, as well as the corresponding field names and field types when the target database is automatically created.',
  task_mapping_table_setting_tip1: 'Unsupported synchronized field type',
  task_mapping_table_field_type_change: 'Type modification',
  task_mapping_table_rename: 'Table rename',
  task_mapping_table_field_rename: 'Field rename',
  task_mapping_table_restore_default: 'Restore default',
  task_mapping_table_search_table: 'Search table',
  task_mapping_table_selected: 'Selected',
  task_mapping_table_search_field: 'Search field',
  task_mapping_table_restore_default_fields: 'Restore default fields',
  task_mapping_table_source_table_field: 'Source table field name',
  task_mapping_table_source_table_type: 'Source table type',
  task_mapping_table_source_table_length: 'Source table length',
  task_mapping_table_source_table_accuracy: 'Source table accuracy',
  task_mapping_table_target_table_field: 'Target table field name',
  task_mapping_table_target_type: 'Target table type',
  task_mapping_table_target_length: 'Target table length',
  task_mapping_table_target_accuracy: 'Target table accuracy',
  task_mapping_table_length_range: 'Length range',
  task_mapping_table_accuracy_range: 'Accuracy range',
  task_mapping_table_reduction: 'Restore',
  task_mapping_table_field_name_empty_edit_vika: 'Please edit the field name',
  task_mapping_table_field_name_empty_check:
    'The current table field has not been set. Please ensure that all source fields are associated with the target field. Please delete the source fields that do not need to be synchronized',
  task_mapping_table_no_data: 'No data temporarily',
  task_mapping_table_no_data_vika:
    'Please select the target wig table and wait for the table structure information to be loaded',
  task_mapping_table_no_data_qingflow:
    'Please select the target light flow application and wait for the field information to be loaded',
  task_mapping_batch_change_field_title: 'Batch change field name settings',
  task_mapping_dialog_field_name_case: 'Field name case',
  task_mapping_dialog_constant: 'Unchanged',
  task_mapping_dialog_to_uppercase: 'Turn to uppercase',
  task_mapping_dialog_lowercase: 'Turn to lowercase',
  task_mapping_dialog_modify_target_field_name: 'Modify target field name',
  task_mapping_dialog_modify_target_field_type: 'Modify the target table field type',
  task_mapping_dialog_modify_target_field_length: 'Modify the target field length',
  task_mapping_dialog_modify_target_field_accuracy: 'Modify target table accuracy',
  task_mapping_batch_change_table_title: 'Batch change table name setting',
  task_mapping_dialog_table_name_case: 'Table name case',
  task_mapping_dialog_rule_note: 'Note: The prefix and suffix of the setting also follow the capitalization rule',
  task_mapping_dialog_enter_prefix: 'Please enter the prefix',
  task_mapping_dialog_english_letter:
    'Starting with an English letter, only supports English, numbers, underscores, dots, and underscores, limited to 0~50 characters',
  task_mapping_dialog_not_allow_system: 'Prefixes are not allowed to start with system',
  task_mapping_dialog_enter_suffix: 'Please enter the suffix',
  task_mapping_dialog_underscore_begin:
    'Start with English letters and underscores, only support English, numbers, underscores, dots, and underscores, limited to 0~50 characters',
  task_mapping_dialog_example: 'Example',
  task_mapping_dialog_original_table_name: 'Original table name',
  task_mapping_dialog_after_modify: 'After modification',
  task_mapping_dialog_rule_input: 'Please input according to the following rules:',
  task_mapping_dialog_all_restore_defaults: 'Are you sure you want to restore all defaults? ',
  task_mapping_dialog_hint: 'Hint',
  task_mapping_dialog_delete_all_field_tip:
    'All fields in the current table have been deleted, and the save operation is not allowed',
  task_mapping_dialog_restore_defaults: 'Are you sure you want to restore the defaults? ',
  task_mapping_dialog_field_name_restrictions_tip:
    'Start with English letters and underscores, only support English, numbers, and underscores, limited to 1~50 characters',
  task_mapping_dialog_target_no_fields: 'Target model not found',
  task_mapping_dialog_field_range_check: 'The current value does not meet the field range',
  task_mapping_dialog_field_type_problem:
    'It has been detected that you have a problem with the field type settings of XXX tables. Please select the problematic table in the table area on the left for processing.',
  task_mapping_dialog_target_no_fields_problem:
    'It is detected that you have XXX tables with no fields, please go back to the previous step and remove the tables without fields. ',
  task_mapping_dialog_rename_a_single_table_title: 'Modify target table name',
  task_mapping_dialog_rename_a_single_table_input_desc:
    'Tables with user-defined names will not be applied: prefix, suffix and case conversion operations',
  task_mapping_dialog_batch_change_field_type_desc:
    'The actual available length depends on the definition of the target database type. Please set it as required',
  milestone_label_init_dataflow: '[Preliminary preparation] Analyze dag path creation subtask',
  milestone_label_connect_to_source: '[Preliminary preparation] Connect to the source data source',
  milestone_label_connect_to_target: '[Preliminary preparation] Connect the target data source',
  milestone_label_init_connector:
    '[Preliminary preparation] Scan the source information and initialize the source collector',
  milestone_label_init_transformer:
    '[Preliminary preparation] Scan the target information and initialize the target processor',
  milestone_label_read_source_ddl: '[Preliminary preparation] Read source ddl information',
  milestone_label_drop_target_schema: '[Preliminary preparation] Delete target model',
  milestone_label_clear_target_data: '[Preliminary preparation] Clear target table data',
  milestone_label_create_target_table: '[Preliminary preparation] Automatically create a target table',
  milestone_label_create_target_index: '[Preliminary preparation] Create target table index',
  milestone_label_create_target_view: '[Preliminary preparation] Automatically create a target view',
  milestone_label_create_target_function: '[Preliminary preparation] Automatically create target function',
  milestone_label_create_target_procedure:
    '[Preliminary preparation] Automatically create a target-side stored procedure',
  milestone_label_read_snapshot: '[Data Transmission] Read all source data snapshot',
  milestone_label_write_snapshot: '[Data Transmission] The target end writes a snapshot of the data',
  milestone_label_read_cdc_event: '[Data Transmission] The source collector enters incremental reading mode',
  milestone_label_write_cdc_event: '[Data Transmission] Target processor enters incremental write mode',
  operation_log_manage: 'Operation log',
  operation_log_type: 'Operation Type',
  operation_log_Object: 'Operation object',
  operation_log_user_name: 'User name',
  operation_log_time: 'Operation time',
  operation_log_describe: 'Operation description',
  operation_log_connection_create: 'Create connection',
  operation_log_connection_create_tip: 'Created a connection [@{parameter1}]',
  operation_log_connection_update: 'Edit connection',
  operation_log_connection_update_tip: 'Edited the configuration information of the connection [@{parameter1}]',
  operation_log_connection_copy: 'Copy connection',
  operation_log_connection_copy_tip: 'Copy connection [${parameter1}] as [@{parameter2}]',
  operation_log_connection_delete: 'Delete connection',
  operation_log_connection_delete_tip: 'Connection deleted [${parameter1}]',
  operation_log_migration_create: 'Create task',
  operation_log_migration_create_tip: 'A task was created [@{parameter1}]',
  operation_log_migration_start: 'Start task',
  operation_log_migration_start_tip: 'Task started [@{parameter1}]',
  operation_log_migration_update: 'Edit task',
  operation_log_migration_update_tip: 'Edited the configuration information of task [@{parameter1}]',
  operation_log_migration_copy: 'Copy task',
  operation_log_migration_copy_tip: 'The task [${parameter1}] was copied as [@{parameter2}]',
  operation_log_migration_reset: 'Reset task',
  operation_log_migration_reset_tip: 'The task was reset [@{parameter1}]',
  operation_log_migration_delete: 'Delete task',
  operation_log_migration_delete_tip: 'Deleted task [${parameter1}]',
  operation_log_migration_stop: 'Stop task',
  operation_log_migration_stop_tip: 'The task has been stopped [@{parameter1}]',
  operation_log_migration_forceStop: 'Force stop task',
  operation_log_migration_forceStop_tip: 'The task was forcibly stopped [@{parameter1}]',
  operation_log_agent_create: 'Create agent',
  operation_log_agent_create_tip: 'Create a agent [@{parameter1}]',
  operation_log_agent_stop: 'Stop agent',
  operation_log_agent_stop_tip: 'The agent【 has been stopped【@{parameter1}】',
  operation_log_agent_delete: 'Delete agent',
  operation_log_agent_delete_tip: 'Delete a Agent [${parameter1}]',
  operation_log_agent_rename: 'Modify Agent name',
  operation_log_agent_rename_tip: 'Modify the Agent name [${parameter2}] to [@{parameter1}]',
  operation_log_agent_update: 'Agent upgrade',
  operation_log_agent_update_tip: 'Agent upgrade has been carried out',
  operation_log_inspect_create: 'New data verification',
  operation_log_inspect_create_tip: 'Create a new data verification task [@{parameter1}]',
  operation_log_inspect_start: 'Perform data verification',
  operation_log_inspect_start_tip: 'Perform data verification task [@{parameter1}]',
  operation_log_inspect_update: 'Edit data verification',
  operation_log_inspect_update_tip: 'Data verification task edited [@{parameter1}]',
  operation_log_inspect_delete: 'Delete data verification',
  operation_log_inspect_delete_tip: 'Data verification task [${parameter1}] is deleted',
  operation_log_difference_inspect_start: 'Perform difference check',
  operation_log_difference_inspect_start_tip:
    'Difference check was performed on the data verification task [@{parameter1}]',
  operation_log_message_read_all: 'All notifications have been read',
  operation_log_message_read_all_tip: 'Set all notifications as read',
  operation_log_message_delete_all: 'Delete all notifications',
  operation_log_message_delete_all_tip: 'All notifications have been deleted',
  operation_log_message_read: 'Mark the notification as read',
  operation_log_message_read_tip: 'Mark all selected notifications as read',
  operation_log_message_delete: 'Delete notification',
  operation_log_message_delete_tip: 'Delete all selected notifications',
  operation_log_modify_notification_setting: 'Modify notification settings',
  operation_log_modify_notification_setting_tip: 'System notification settings have been modified',
  operation_log_modify_connection_name: 'Modify the connection name from [${parameter2}] to [@{parameter1}]',
  operation_log_modular_name_user_center: 'User center',
  guide_install_agent: 'Install Agent',
  guide_create_source_connection: 'Create source connection',
  guide_create_target_connection: 'Create target connection',
  guide_config_sync_task: 'Configure synchronization task',
  guide_install_agent_tip:
    'TapData Cloud needs to install Agent locally to ensure the normal operation of the database connection and data transmission service. In order to better experience the novice guide mode, we will provide you with an Agent test environment that can be used to directly test the data source. ',
  guide_click_agent_next_step: 'Click to enable agent to start the next step! ',
  guide_name: 'Name',
  guide_install_agent_test_tip:
    'The synchronization speed of the test agent is limited to a maximum of 200 lines/S. The agent you deploy and install is not subject to this restriction. ',
  guide_install_agent_test_tip1:
    'If you have not accessed the system for more than a week, the test agent will be automatically recycled, and you can create it again through the novice guide. ',
  guide_start_test_agent: 'Start Test Agent',
  guide_stop_test_agent: 'Stop Test Agent',
  guide_previous: 'Back',
  guide_next_step: 'Next',
  guide_test_agent_tip: 'It takes about 1 to 5 minutes to start the test agent, please be patient. ',
  guide_create_source_connection_tip:
    'Data source refers to the connection of database, file, GridFS, REST API, etc. that can be used as the source. The source connection must be created before the migration task can be created. ',
  guide_create_target_connection_tip:
    'Target connection refers to a connection of database, file, GridFS, REST API, etc. that can be used as a target. A target connection must be created to create a migration task. ',
  guide_database_type: 'Database Type',
  guide_init_database: 'Initialize the database',
  guide_connection_name: 'Connection name',
  guide_only_test: '(Only for testing, not editable)',
  guide_address_port: 'Address/Port',
  guide_database_name: 'Database name',
  guide_database_account: 'Database account',
  guide_database_password: 'Database password',
  guide_sync_task: 'Sync type',
  guide_mapping_setting: 'Mapping settings',
  guide_mapping_setting_tip:
    'Users can check the source table to be synchronized on this page, click the arrow button in the middle to move these tables to the queue of tables to be synchronized (after the task is executed, these tables will be synchronized), and click the Finish button to succeed Create a synchronization task. ',
  guide_selected: 'table to be selected',
  guide_table_selected: 'Selected table',
  guide_finish: 'Finish',
  guide_complete_novice_guide: 'Congratulations on completing the novice guide! ',
  guide_back_workbench: 'Return to workbench',
  guide_view_task_monitor: 'View task monitor',
  guide_agent_start_success: 'Agent starting',
  guide_agent_start_fail: 'Agent start failed',
  guide_creat_connection_fail: 'Failed to create connection',
  message_exists_name: 'Name already exists',
  dataForm_form_connectionType: 'line type',
  dataForm_form_options_source: 'source',
  dataForm_form_options_sourceTips: 'This data connection can only be used as a source in tapdata, not as a target',
  dataForm_form_options_target: 'target',
  dataForm_form_options_targetTips: 'This data connection can only be used as a target in tapdata, not as a source',
  dataForm_form_host: 'Database address',
  dataForm_error_noneHost: 'Database address cannot be empty',
  dataForm_form_port: 'port',
  dataForm_error_nonePort: 'Port cannot be empty',
  dataForm_error_portNumber: 'The port must be numeric',
  dataForm_error_portRange: 'The value range of port number is 1 ~ 65535',
  dataForm_form_databaseName: 'Database name',
  dataForm_form_userName: 'account number',
  dataForm_form_password: 'password',
  dataForm_form_additionalString: 'Other connection string parameters',
  dataForm_form_timeZone: 'Time zone of time type',
  dataForm_form_timeZoneTips: 'Impact type: Date',
  dataForm_form_options_sourceAndTarget: 'Source and target',
  dataForm_form_options_sourceAndTargetTips: 'This data connection can be used as both source and target in tapdata',
  dataForm_form_databaseOwner: 'Schema',
  dataForm_form_plugin_name: 'Log decoder',
  dataForm_form_options_connectionMode: 'Connection mode',
  dataForm_form_options_URIMode: 'Uri pattern',
  dataForm_form_options_URIModeTips: 'Configure mongodb database in URI mode and support batch input',
  dataForm_form_options_standardMode: 'Standard mode',
  dataForm_form_databaseUri: 'Database URI',
  dataForm_form_ssl: 'Use TLS / SSL connection',
  dataForm_form_options_sslTSL: 'TSL / SSL connection',
  dataForm_form_options_sslTSLTip:
    'Tapdata will connect to a separate server in the network, which provides a TSL / SSL channel to the database. If your database is on an inaccessible subnet, you can try this method',
  dataForm_form_options_sslTop: 'Direct connection',
  dataForm_form_options_sslTopTips:
    'Tapdata will connect directly to the database, and you can create a security rule to allow system access, which is a simple and direct method',
  dataForm_form_sslKey: 'Client private key',
  dataForm_error_noneSslKey: 'Client private key cannot be empty',
  dataForm_form_sslPass: 'Private key password',
  dataForm_form_sslValidate: 'Verify server certificate',
  dataForm_form_sslCA: 'Certification authority',
  dataForm_error_noneSslCA: 'Certification authority cannot be empty',
  dataForm_form_ReloadSchema: 'Load schema periodically',
  dataForm_form_tableFilter: 'Include table',
  dataForm_form_tableFilterTips: 'Comma separated expression list, using * to represent any character of any length',
  dataForm_form_initialReadSize: 'Initialize data size',
  dataForm_form_incrementalTps: 'Test rate (times / second)',
  dataForm_form_indexPrefix: 'Index prefix',
  dataForm_form_kafka_topicExpression: 'Topic expression',
  dataForm_form_kafka_kerberos_attest: 'kerberos authentication',
  dataForm_form_kafka_kerberos_config_keytab: 'Key representation file',
  dataForm_form_kafka_kerberos_config_conf: 'Configuration file',
  dataForm_form_kafka_kerberos_body_config: 'body configuration',
  dataForm_form_kafka_kerberos_service_name: 'Service name',
  dataForm_form_kafka_kerberos_tip:
    'The instance name mapping needs to be configured on the host where the Engine is located in /etc/hosts',
  dataForm_form_kafka_kerberos_none_keytab: 'The key means that the file cannot be empty',
  dataForm_form_kafka_kerberos_none_conf: 'The configuration file cannot be empty',
  dataForm_form_kafka_encryption: 'Encryption method',
  dataForm_form_kafka_lonoreFormat: 'Ignore non JSON object format messages',
  dataForm_form_kafka_kafkaAcks: 'ACK confirmation mechanism',
  dataForm_form_kafka_kafkaAcks0: 'Unconfirmed',
  dataForm_form_kafka_kafkaAcks1: 'Write master partition only',
  dataForm_form_kafka_kafkaAcks_1: 'Write to most ISR partitions',
  dataForm_form_kafka_kafkaAcksAll: 'Write all ISR partitions',
  dataForm_form_kafka_kafkaCompressionType: 'Message compression type',
  dataForm_form_kafka_kafkaIgnorePushError: 'Ignore push message exception',
  dataForm_form_mq_mqType: 'MQ type',
  dataForm_form_mq_mqQueueSet: 'Queue name',
  dataForm_form_mq_mqTopicSet: 'Subject name',
  dataForm_form_mq_routeKeyField: 'Message routing',
  dataForm_form_mq_virtualHost: 'Virtual host',
  dataForm_form_connectionMode: 'Connection mode',
  dataForm_form_serviceName: 'service name',
  dataForm_form_uriTips_content:
    '<b>Demonstration of mongodb database connection URI: < / b > < br > < b > the user name and password in the URI must be URL encoded and spliced into the connection string < / b > < br > < b > replica set:</b> mongodb://192.168.0.100:27017/mydb?replicaSet=xxx <br><b>Certified replica set enabled:</b> mongodb://admin:password @192.168.0.100:27017/mydb? Replicaset = XXX & authsource = admin < br > < b > multi node replica set:</b> mongodb://192.168.0.1:27017 ,192.168.0.2:27017,192.168.0.3:27017/mydb? Replicaset = XXX < br > < b > fragment set:</b> mongodb://192.168.0.100:27017/mydb <br><b>Multiple mongos:</b> mongodb://192.168.0.1:27017 ,192.168.0.2:27017,192.168.0.3:27017/mydb<br>',
  connection_rename: 'Rename',
  dataForm_form_connectionName: 'Connection name',
  formBuilder_noneText: 'Cannot be empty',
  connection_reloadTittle: 'Reload schema',
  connection_reloadMsg: 'It may take too long to refresh the schema data source',
  message_confirm: 'determine',
  message_cancel: 'Cancel',
  connection_reloadFail: 'Schema loading failed',
  milestone_btn_check_error: 'View the cause of the error',
  dataFlow_second: 'second',
  dataFlow_min: 'branch',
  dataFlow_hour: 'Time',
  dataFlow_day: 'day',
  dataFlow_input: 'input',
  dataFlow_output: 'output',
  dataFlow_current: 'current',
  dataFlow_dataScreening: 'Event statistics',
  dataFlow_inputOutput: 'Input / output statistics',
  dataFlow_throughputpop:
    'Input and output statistics: the average speed of data collection at the source and the speed of writing at the target per second. The higher the value, the better',
  dataFlow_transf: 'Transmission time',
  dataFlow_transtime_pop:
    'Transmission time: except for the source node, the time after the event is processed minus the occurrence time of the event. Inter node statistics: the time consumed by events from entering the node to output. Task flow statistics: the time consumed by all nodes is added up. The smaller the value, the better',
  dataFlow_replicate: 'Data synchronization gap',
  dataFlow_replicate_pop:
    'Data synchronization gap: the gap between the last update time of the source database and the target database. The smaller the value, the better',
  dataFlow_totalOutput: 'Total output',
  dataFlow_totalInput: 'Total input',
  dataFlow_totalInsert: 'Total insertion',
  dataFlow_totalUpdate: 'Total update',
  dataFlow_totalDelete: 'Total deletion',
  dataFlow_cronExpression: 'Please enter a scheduling expression',
  dialog_jobSchedule_explanation:
    'You can set a fixed time, date and interval to run periodic tasks through cron expression',
  dialog_jobSchedule_grammar: 'Syntax:',
  dialog_jobSchedule_example: 'example:',
  dialog_jobSchedule_runMinute: 'Run every minute',
  dialog_jobSchedule_runDay: "Run at 2 o'clock every day",
  guide_btn_back: 'Previous step',
  guide_btn_next: 'next step',
  dataFlow_SyncInfo_localTZType: 'User browser time zone',
  dataFlow_SyncInfo_connTZType: 'Database time zone',
  dataFlow_SyncInfo_currentType: 'this moment',
  taskProgress_all: 'whole',
  taskProgress_running: 'In operation',
  taskProgress_waiting: 'Waiting',
  editor_cell_link_searchContent: 'Search content',
  editor_cell_link_migrationObjece: 'Table to be copied',
  editor_cell_link_chosen: 'Selected',
  message_placeholderSelect: 'Please select',
  app_Home_checkSame: 'Check consistency',
  app_Home_countDifference: 'Inconsistent count',
  app_Home_contentDifference: 'Content difference',
  dataFlow_importantReminder: 'Important reminder',
  classification_deleteNode: 'delete',
  message_deleteOK: 'Delete succeeded',
  dataFlow_dataLoading: 'Data loading',
  RequestErrorMessage_error_title: 'There is an error currently. Please refresh the page',
  RequestErrorMessage_code_label: 'Error code:',
  RequestErrorMessage_req_id_label: 'Request ID:',
  RequestErrorMessage_error_detail_label: 'Error details',
  dataForm_form_response_body_CHECK_CONNECT: 'Check if the service connection is available',
  dataForm_form_response_body_CHECK_AUTH: 'Check whether the user name, password and database are correct',
  dataForm_form_response_body_CHECK_VERSION: 'Check whether the data source version information is available',
  dataForm_form_response_body_LOAD_SCHEMA: 'Loading model',
  dataForm_form_response_body_CHECK_CDC_PERMISSION:
    'Check whether the permissions required for CDC synchronization are authorized',
  dataForm_form_response_body_CHECK_ARCHIVE_LOG: 'Check whether the archive log is enabled',
  dataForm_form_response_body_CHECK_SUPPLEMENTAL_LOG: 'Check whether the supplementary log mode is correct',
  dataForm_form_response_body_CHECK_DDL_PERMISSION:
    'Check whether the permissions required to execute DDL statements are authorized',
  dataForm_form_response_body_CHECK_PERMISSION:
    'Check whether the permissions required for synchronization are authorized',
  dataForm_form_response_body_CHECK_BIN_LOG: 'Check whether binlog is enabled and at row level',
  dataForm_form_response_body_CHECK_BIN_ROW_IMAGE: 'Check whether binlog format is full',
  dataForm_form_response_body_CHECK_SCRIPT: 'Check if the script is available',
  dataForm_form_response_body_CHECK_PRIMARY_KEY: 'Check whether the primary key is available',
  dataForm_form_response_body_CHECK_CONFIG: 'Check whether the configuration is correct',
  dataForm_form_response_body_CHECK_READ_PERMISSION: 'Check whether the readable permission is authorized',
  dataForm_form_response_body_CHECK_ACCESS_TOKEN: 'Check whether the access token is available',
  dataForm_form_response_body_CHECK_API_AUTH: 'Check whether the API has access rights',
  dataForm_form_response_body_CHECK_LOCAL_PORT: 'Check whether the local port is available',
  dataForm_form_response_body_SCAN_FILE: 'Scan files in directory',
  dataForm_form_response_body_CHECK_BIN_LOG_SYNC: 'Check whether binlog log synchronization is enabled',
  dataForm_form_response_body_CHECK_GTID: 'Check whether the consistency between gtid mode and gtid is enabled',
  dataForm_form_response_body_CHECK_VIKA_API_TOKEN: 'Check whether the Vika key is correct',
  dataForm_form_response_body_CHECK_QINGFLOW_ACCESS_TOKEN: 'Check whether the access token is available',
  field_mapping_field_mapping_dialog_muLu: 'catalogue',
  field_mapping_field_mapping_dialog_muBiao: 'Objectives:',
  field_mapping_field_mapping_dialog_piLiangXiuGaiZi: 'Batch modify field type',
  field_mapping_field_mapping_dialog_: '：',
  field_mapping_field_mapping_dialog_yuanZiDuanLeiXing: 'Source field type',
  field_mapping_field_mapping_dialog_muBiaoZiDuanLei: 'Target field type',
  field_mapping_field_mapping_dialog_changDu: 'length',
  field_mapping_field_mapping_dialog_jingDu: 'accuracy',
  field_mapping_field_mapping_dialog_tianJia: 'add to',
  field_mapping_field_mapping_dialog_qingShuRuBiaoMing: 'Please enter the table name',
  field_mapping_main_jieKouQingQiuShi: 'Interface request failed',
  filter_bar_DatetimeRange_zhi: 'to',
  components_InlineInput_ziFuChangDuXian: 'The character length is limited to {val1} - {val2} characters',
  components_RequestErrorMessage_yiFuZhi: 'Copied',
  components_SelectList_meiYouGengDuoShu: 'No more data',
  components_TableFilter_quanBu: 'whole',
  the_header_Header_yongHuZhongXin: 'User center',
  the_header_Header_zhongWen: 'chinese',
  components_VerificationCode_faSongYanZhengMa: 'Send verification code',
  agent_download_AgentDownloadModal_zaiNinDeLI:
    '2. Create a new directory tapdata under your Linux server to install and deploy tapdata agent',
  agent_download_AgentDownloadModal_fuZhiXiaFangMing2:
    '3. Copy the following commands and execute them in the tapdata directory, which includes the download, automatic deployment and startup of tapdata agent.',
  agent_download_AgentDownloadModal_dengDaiMingLingZhi2:
    '4. Wait for the command execution to complete the installation and startup of tapdata agent.',
  agent_download_AgentDownloadModal_ninDeBuShuHuan:
    '1. Your deployment environment must have docker installed and started before it can be installed by using docker. If it is not installed, please refer to',
  agent_download_AgentDownloadModal_fuZhiXiaFangMing:
    '2. Copy the following commands and execute them in the tapdata directory, which includes the download and operation of images, and the download, automatic deployment and startup of tapdata agent',
  agent_download_AgentDownloadModal_dengDaiMingLingZhi:
    '3. Wait for the command execution to complete the installation and startup of tapdata agent.',
  agent_download_AgentDownloadModal_buShuZhuangTaiJian: 'Deployment status detection in progress',
  agent_download_AgentDownloadModal_gongXiNinWanCheng: 'Congratulations on completing the deployment!',
  agent_download_AgentDownloadModal_kaiShiChuangJianLian: 'Start creating connection',
  agent_download_AgentDownloadModal_jinRuGongZuoTai: 'Enter the workbench',
  agent_download_UpgradeVersion_dOCKE: 'Docker exec - it container ID Bash',
  agent_download_UpgradeVersion_dOCKE2: 'Docker start container ID',
  connection_Form_lianJieMingChengBu: 'Connection name cannot be empty',
  connection_Form_mingChengGuiZeZhong:
    'Name rules: it starts with Chinese and English, with 1 ~ 100 characters, and can contain Chinese and English, numbers, middle dashes, underscores and spaces',
  connection_Form_mingChengYiCunZai: 'Name already exists',
  connection_List_lianJieMing: 'Connection name',
  connection_List_quanBuZhuangTai: 'All Status',
  connection_List_shuJuKuLeiXing: 'Database Type',
  connection_List_anLianJieMingSou: 'Search by connection name',
  connection_List_fuZhiChengGong: 'Copy successful',
  connection_List_shanChuShiBai: 'Delete failed',
  connection_Preview_caoZuoChengGong: 'Operation successful',
  views_Error_fuWuQiNeiBu: 'Server internal error!',
  views_Error_fanHuiShouYe: 'Return to home page',
  views_Error_zhangHuZanWuQuan:
    'The account has no permission! Your account authority is insufficient to order products. Please contact the customer manager or customer service personnel: 4001100868',
  views_Error_zhangHuYiBeiDong: 'The account has been frozen',
  views_Error_ninDeZhangHuYi:
    'Your account has been suspended and cannot order products. Please recharge in time or contact the account manager.',
  views_Error_chanPinYiXiaJia: 'The product has been taken off the shelf',
  views_Error_feiChangBaoQianChan: "I'm very sorry, the product has been taken off the shelf",
  instance_Instance_anIDShiLi: 'Search by ID / instance name',
  instance_Instance_tHIST: '，{val1}：{val2}%',
  monitor_Dashboard_cuoWu: 'error',
  monitor_Log_qingShuRuRiZhi: 'Please enter the log content',
  monitor_Log_xiaZaiRenWuRi: 'Download task log',
  monitor_Log_meiYouGengDuoLe: 'No more',
  monitor_Log_zanWuRiZhi: 'No log',
  monitor_Log_xuanZeRiZhiFan: 'Select log range',
  monitor_Log_liJiXiaZai: 'Download now',
  monitor_Log_zuiJinGeXiaoShi: 'Last 6 hours',
  monitor_Log_zuiJinTian3: 'Last 1 day',
  monitor_Log_zuiJinTian2: 'Last 3 days',
  monitor_Log_zuiJinTian: 'Last 5 days',
  operation_log_List_yiDuQuanBuTong: 'Read all notifications',
  operation_log_List_sheZhiQuanBuTong: 'Set all notifications to read',
  operation_log_List_shanChuQuanBuTong: 'Delete all notifications',
  operation_log_List_shanChuLeQuanBu: 'All notifications deleted',
  operation_log_List_biaoJiTongZhiWei: 'Mark notification as read',
  operation_log_List_jiangXuanZhongDeTong2: 'Mark all selected notifications as read',
  operation_log_List_shanChuTongZhi: 'Delete notification',
  operation_log_List_jiangXuanZhongDeTong: 'Delete all selected notifications',
  operation_log_List_xiuGaiTongZhiShe: 'Modify notification settings',
  operation_log_List_xiuGaiLeXiTong: 'Modified system notification settings',
  operation_log_List_xiuGaiYongHuXin: 'Modify user information',
  operation_log_List_xiuGaiLeYongHu: 'User information modified',
  operation_log_List_bangDingShouJiHao: 'Bind mobile number',
  operation_log_List_bangDingLeShouJi: 'Bound mobile number',
  operation_log_List_xiuGaiShouJiHao: 'Modify mobile phone number',
  operation_log_List_xiuGaiLeShouJi: 'Modified the mobile phone number',
  operation_log_List_bangDingYouXiang: 'Bind mailbox',
  operation_log_List_bangDingLeYouXiang: 'Bound mailbox',
  operation_log_List_xiuGaiYouXiang: 'Modify mailbox',
  operation_log_List_xiuGaiLeYouXiang: 'Modified mailbox',
  operation_log_List_xiuGaiMiMa: 'Change Password',
  operation_log_List_xiuGaiLeMiMa: 'Changed password',
  operation_log_List_xiuGaiQiYeXin: 'Modify enterprise information',
  operation_log_List_xiuGaiLeQiYe: 'Modified enterprise information',
  operation_log_List_caoZuoShiJian: 'Operation time',
  operation_log_List_caoZuoDuiXiang: 'Operation object',
  operation_log_List_caoZuoLeiXing: 'Operation type',
  operation_log_List_caoZuoMiaoShu: 'pedagogical operation',
  operation_log_List_yongHuMingCheng: 'User name',
  copy_Info_pTHIS: '<p>{val1}<span style="color:#409EFF">{val2}</span>、',
  copy_Info_sPANS: '<span style="color:#409EFF">{val1}</span>、',
  task_Migration_renWuMingCheng: 'Task name',
  task_Migration_renWuLeiXing: 'Task type',
  task_Migration_suoShuAGE: 'Agent',
  task_Migration_xuanZeRenWuLei: 'Select task type',
  task_Migration_shuJuKuQianYi: 'Database migration',
  task_Migration_duiShuJuKuJin: 'Cross database replication',
  task_Migration_shuJuBiaoTongBu: 'Data table synchronization',
  task_Migration_chouQuYuanDuanShu: 'Extract the source data and calculate the conversion',
  task_Migration_renWuZhuangTai: 'Task status',
  task_Migration_tongBuLeiXing: 'Synchronization type',
  task_Migration_aGENT: 'Agent name',
  task_Migration_mingCheng: 'name',
  task_Migration_gaiRenWuYiShe:
    'The scheduled running time has been set for this task. Manual startup will invalidate the scheduled running time. Are you sure you want to continue startup?',
  task_Migration_shiFouQiDongGai: 'Start the task?',
  task_TaskProgress_renWuLiChengBei: 'Mission milestones',
  task_TaskProgress_liChengBei: 'milepost',
  task_TaskProgress_shiJian: 'time',
  task_TaskProgress_qingShuRuBiaoMing: 'Please enter a table name',
  task_TaskProgress_shuJuKu: 'database',
  task_TaskProgress_shuJuBiao: 'data sheet',
  task_TaskProgress_shuJuLiangHang: 'Data volume (row)',
  task_TaskProgress_jinDu: 'speed of progress',
  task_TaskProgress_jieGouQianYiGai: 'Overview of structure migration',
  task_TaskProgress_jiHuaQianYiBiao: 'Number of planned migration tables: 100',
  task_TaskProgress_yiWanChengQianYi: 'Migration scale 100 completed',
  task_TaskProgress_yuJiQuanLiangWan:
    'It is estimated that it will take 24 hours, 23 minutes and 1 second to complete the whole project',
  task_TaskProgress_yiQianYiZhangBiao: '100 tables migrated',
  task_TaskProgress_gongZhangBiao: '100 sheets in total',
  task_TaskProgress_qianYiXiangQing: 'Migration details',
  task_TaskProgress_zhuangTai: 'Status:',
  task_TaskProgress_renWuChuShiHua: 'Task initialization',
  task_TaskProgress_jieGouQianYi: 'Structural migration',
  task_TaskProgress_quanLiangTongBu: 'Full synchronization',
  task_TaskProgress_zengLiangTongBu: 'Incremental synchronization',
  user_Center_shangChuanTouXiang: 'Upload Avatar',
  user_Center_dangQianShouJi: 'Current phone:',
  user_Center_qingShuRuDangQian: 'Please enter the current mobile phone',
  user_Center_shouJiYanZhengMa: 'Mobile phone verification code:',
  user_Center_qingShuRuShouJi: 'Please enter the mobile phone verification code',
  user_Center_xinMiMa: 'New password:',
  user_Center_qingShuRuXinMi: 'Please enter a new password',
  user_Center_queRenMiMa: 'Confirm password:',
  user_Center_yanZhengMa: 'Verification Code:',
  user_Center_jiuShouJiYanZheng: 'Old mobile phone verification code:',
  user_Center_qingShuRuJiuShou: 'Please enter the old mobile phone verification code',
  user_Center_xinShouJi: 'New phone:',
  user_Center_qingShuRuXinShou2: 'Please enter a new phone',
  user_Center_xinShouJiYanZheng: 'New mobile phone verification code:',
  user_Center_qingShuRuXinShou: 'Please enter the new mobile phone verification code',
  user_Center_bangDingWeiXin: 'Binding wechat',
  user_Center_youXiang: 'Email:',
  user_Center_qingShuRuYouXiang: 'Please enter email address',
  user_Center_qingShuRuYanZheng: 'Please enter the verification code',
  user_Center_dangQianYouXiangYan: 'Current email verification code:',
  user_Center_xinYouXiang: 'New mailbox:',
  user_Center_qingShuRuXinYou: 'Please enter a new mailbox',
  user_Center_xinYouXiangYanZheng: 'New email verification code:',
  user_Center_weiBangDing: 'Unbound',
  user_Center_weiTianXie: 'Not filled in',
  user_Center_geRenXinXi: 'personal information',
  user_Center_yongHuNiCheng: 'User nickname:',
  user_Center_xiuGai: 'modify',
  user_Center_qiYeXinXi: 'Enterprise information',
  user_Center_gongSiMingCheng: 'corporate name:',
  user_Center_gongSiGuanWang: 'Official website of the company:',
  user_Center_suoShuHangYe: 'Industry:',
  user_Center_suoShuChengShi: 'City:',
  user_Center_qiYeXinXiXiu: 'Enterprise information modification',
  user_Center_zhiChiJPG: 'Support JPG, PNG and GIF formats, and the image size should be within 500kb',
  user_Center_qingShiYongWeiXin: 'Please use wechat scanning QR code to bind tapdata cloud',
  user_Center_xiuGaiNiChengCheng: 'Successfully modified nickname',
  user_Center_shangChuanTouXiangTu: 'Upload avatar image size can not exceed 500kb!',
  user_Center_xiuGaiTouXiangCheng: 'Successfully modified Avatar',
  user_Center_qingXianBangDingShou: 'Please bind your mobile number first',
  user_Center_bangDingShouJi: 'Binding mobile phone',
  user_Center_shuRuMiMaBu: 'The passwords entered are inconsistent',
  user_Center_xiuGaiMiMaCheng: 'Password modified successfully',
  user_Center_bangDingShouJiCheng: 'Mobile phone binding succeeded',
  user_Center_xiuGaiShouJiCheng: 'Mobile phone modified successfully',
  user_Center_jieChuHouJiangWu:
    'You will not be able to use wechat to log in and receive wechat notifications. Are you sure to unbind',
  user_Center_jieChuWeiXin: 'Cancel wechat',
  user_Center_jieBangWeiXinCheng: 'Successfully unbound wechat',
  user_Center_bangDingYouXiangCheng: 'Bind mailbox successfully',
  user_Center_xiuGaiYouXiangCheng: 'Mailbox modified successfully',
  user_Center_xiuGaiQiYeXin: 'Enterprise information modified successfully',
  components_BindPhone_qingBangDingShouJi: 'Please bind your mobile number',
  components_BindPhone_qingShuRuShouJi: 'Please enter your mobile phone',
  workbench_Notice_tAPDA12: 'Tapdata cloud version 1.0.9 has been released!',
  workbench_Notice_tAPDA11:
    'Tapdata cloud is the first heterogeneous database real-time synchronization cloud platform in China. At present, it supports Oracle, mysql, PG, SQL server, mongodb and es, Dameng, Kafka, GP, MQ, Clickhouse, hazelcast cloud, ADB mysql, ADBThe data synchronization among PostgreSQL, kundb, tidb and dummy will support DB2, Sybase ASE, redis, gbase and gaussdbAnd permanently free to users.',
  workbench_Notice_buDuanYouHuaTi: '2. Continuously optimize and provide better experience',
  workbench_Notice_zaiChuangJianLianJie: 'When creating a connection, the user can select the connection type',
  workbench_Notice_benCiXinZengRi: 'The new log filtering function enables users to filter through log filtering',
  workbench_Notice_zhiChiPiLiangCao: '3. Support batch operation and better experience',
  workbench_Notice_ziDuanYingSheBu:
    'In the field mapping part, the table name, field name and case settings support user batch adjustment, which is simple and fast, and greatly improves the processing efficiency.',
  workbench_Notice_duoWeiDuTongJi: '4. Multi dimensional statistics, more intuitive understanding of task progress',
  workbench_Notice_banBenDuiShuJu:
    'Version 1.0.9 optimizes the details of database synchronization tasks. Users can see the synchronization progress and the synchronization process at a glance.',
  workbench_Notice_shengJiGongGao: 'Upgrade announcement!',
  workbench_Notice_zunJingDeYongHu: 'Dear users',
  workbench_Notice_ninHaoWeiLeJin:
    'Hello! In order to further improve the service quality, the tapdata cloud will be upgraded from 19:00 to 22:00 on January 20, 2022 (Thursday)',
  workbench_Notice_shengJiQiJianKe:
    'During the upgrade, operations such as accessing the console and creating tasks may be affected, and tasks that are already running may not be affected. After the upgrade, they will be restored to normal use.',
  workbench_Notice_yiShangShengJiRu:
    'Please understand the inconvenience caused by the above upgrade and make preparations in advance. If you have any questions, please contact us.',
  workbench_Notice_nianYueRi: 'January 20, 2022',
  workbench_Notice_tAPDA9: 'Tapdata cloud team',
  workbench_Notice_tAPDA8:
    'New year version update of tapdata cloud: details control benefits! The data source is newly added, which supports the custom collection "start time" of incremental tasks',
  workbench_Notice_kaiNianYouFengGeng:
    'Update again at the beginning of the year and optimize all the time - the new version of tapdata cloud has been released!',
  workbench_Notice_ciCiFaBuDe2:
    '2.0.1 of this releaseVersion, in addition to the new data source, it is optimized for many details in the actual operation process, which further improves its ease of use and convenience of operation.',
  workbench_Notice_gengXinSuLan: 'Update quick view 👇',
  workbench_Notice_zhiChi: '1. Support',
  workbench_Notice_sheZhiZengLiangCai: 'Set incremental acquisition time point',
  workbench_Notice_zengLiangRenWuKe: ', the start time of acquisition can be customized for incremental tasks',
  workbench_Notice_zhiChiShuJuYuan: '2. Support data source updating and data connection',
  workbench_Notice_xinZengMAR: 'Added MariaDB support',
  workbench_Notice_xiJieGengXinYou:
    '3. Detail update: the pop-up prompt for editing "run tasks" is optimized to avoid misoperation',
  workbench_Notice_zhiChiSheZhiZeng: 'Support setting incremental acquisition time point',
  workbench_Notice_gongNengShengJiCao: 'More flexible function upgrade operation',
  workbench_Notice_zhenDuiLiShiBan:
    'In the historical version, the time cannot be specified when setting the incremental task, and the incremental data collection starts from the "current time" by default. Now it has been optimized - in the new version, the incremental task can customize the incremental collection time point. By opening the incremental task setting, you can manually add the "incremental acquisition start time", meet the operation requirements in the real business scenario, and focus on the continuous optimization of the use experience.',
  workbench_Notice_ruGuoNiDeQuan:
    'If your full + incremental task is abnormal after entering the incremental phase, resulting in the task stopping, you can edit the task, change the synchronization type of the task to incremental synchronization, and then set the incremental acquisition start time as the incremental time point when the task stops, and then continue to run the task. The seamless connection of data can be realized without running the full volume again to ensure the integrity of data.',
  workbench_Notice_muQianGaiYouHua:
    'At present, the optimization has covered mysql, SQL server, Oracle and mongodbMultiple databases including. For the support of other databases, the follow-up will also be opened one after another. Please look forward to it.',
  workbench_Notice_shuJuYuanZaiShang: 'New data source',
  workbench_Notice_mARIA: 'MariaDB has now joined the tapdata cloud',
  workbench_Notice_yiGouShuJuKu: 'Heterogeneous database real-time synchronization family',
  workbench_Notice_zuoWeiGuoNeiShou3:
    'As the first heterogeneous database real-time synchronization cloud platform in China, tapdata cloudBreak the system and data type restrictions, support diversified data sources and drag-and-drop "zero" code configuration operation, and truly realize cross system and cross type data synchronization and exchange with strong data processing ability, so that you can release the energy in the data preparation stage and focus more on the development and innovation of data business.',
  workbench_Notice_benCiGengXinZhong3:
    'In this update, MariaDB support is added to the data connection, and another piece of data source layout that can be supported is added. Look, these are all the rivers and mountains that tapdata cloud has "fought" for you:',
  workbench_Notice_xiJieYouHua: 'Detail optimization',
  workbench_Notice_weiXiaoDanTieXin2: 'Small but intimate use is more reassuring',
  workbench_Notice_yongHuDaoXiangXi2:
    'User oriented, detail oriented - this time, we optimized the pop-up prompt for editing running tasks. Ding Dong, there are running tasks ahead. If you modify the task settings, you must reset them after submitting them to run normally. Please operate with caution.',
  workbench_Notice_zhongShiChengZhangLu2:
    "Pay attention to every feedback gained on the road of growth, constantly improve and optimize. Tapdata has been on the road all the time. Let's focus on details and become a great beauty. We look forward to seeing you again in the next new version",
  workbench_Notice_: '。',
  workbench_Notice_tAPDA7:
    'Here comes tapdata cloud 2.1.0: the latest version supports Alibaba cloud database access. The Windows version has lighter operation and a comprehensive upgrade of the user experience!',
  workbench_Notice_ciCiFaBuDe:
    'The release of version 2.1.0 has another big move: officially start accessing cloud database and optimize windowsThe version operation process comprehensively upgrades the user experience along the practical demand points in the real use environment.',
  workbench_Notice_shuJuLianJieShang2: '1. New data connection,',
  workbench_Notice_kaiShiZhiChiYun: 'Start supporting cloud database access',
  workbench_Notice_benLunXinZengA:
    ', aliyun is added in this roundMariaDB, aliyun mongodb, aliyun RDS for sqlserver, aliyun RDS for PG, aliyun RDS for MySQL as the source and target;',
  workbench_Notice_youHuaWIN: 'Optimize Windows version packaging and installation process',
  workbench_Notice_liuChengGengQingXi: ', clearer process and simpler deployment operation;',
  workbench_Notice_xinZengYongHuZhong2: 'Add user center module',
  workbench_Notice_zhiChiXiuGaiZhu:
    ': support the modification of initial registration information, including the editing of nickname, avatar, password and enterprise information, as well as the new binding and switching of mobile phone number and email;',
  workbench_Notice_xinZengRenWuShu2: 'New task data visualization module',
  workbench_Notice_yongHuGongZuoTai:
    ': the "daily data volume trend chart of task" can be seen on the user workbench ➕ "Cumulative data volume chart"',
  workbench_Notice_shuJuLianJieYou2: 'The data connection is new again, and the "cloud" is coming',
  workbench_Notice_zuoWeiGuoNeiShou:
    'As the first heterogeneous database real-time synchronization cloud platform in China, tapdata cloudContinuously expand the data connection layout that can be supported, strive to meet the diversified data sources and target needs of users, and truly realize the "comprehensive breaking wall" of real-time data synchronization.',
  workbench_Notice_mianDuiDaLiangYong:
    'Facing the urgent needs of a large number of users to connect to the cloud database, tapdata cloud gives priority to response. In this update, aliyun MariaDB and aliyun are supportedMongodb, aliyun RDS for sqlserver, aliyun RDS for PG and aliyun RDS for MySQL are the source and target. Zoom in and see tapdataLatest achievements of cloud "wall breaking operation" 👇：',
  workbench_Notice_wINDO: 'Windows version process optimization',
  workbench_Notice_shaGuaMoShiZai: '"Fool mode" is upgraded, installed and deployed more efficiently',
  workbench_Notice_tAPDA6: 'Is the installation and deployment of tapdata cloud easy to use? We can be simpler 👉',
  workbench_Notice_benCiGengXinZhong2:
    'This update focuses on the re optimization of Windows version operation process:',
  workbench_Notice_zaiAGEN:
    'In the aspect of agent deployment mode: after the user downloads the agent installation package, double-click execute to complete the installation and deployment',
  workbench_Notice_zaiAnZhuangGuoCheng:
    "During installation: the new version will automatically detect the user's Java environment. If the user's Java environment does not meet the running needs, it will automatically download JREWith, there is no need to configure the Java environment in advance. (* manual emphasis: the downloaded JRE is harmful to the customer environment",
  workbench_Notice_wuRenHeQinRu: 'No intrusion',
  workbench_Notice_3: '）',
  workbench_Notice_xinZengYongHuZhong: 'Add "user center" page',
  workbench_Notice_niDeGeXingHua: 'Your new personalization feature is online',
  workbench_Notice_xiangYaoZiZhuXiu:
    'If you want to modify the initial registration information, set the avatar / nickname / password, or bind a new mobile phone number and email, the entrance is coming! Hover over the personal account in the upper right corner, select the [user center] tab in the drop-down menu, and click to enter the personal and enterprise information editing interface.',
  workbench_Notice_xinZengRenWuShu: 'Statistical chart display of new task data volume',
  workbench_Notice_yinWeiKeShiSuo: "It's clearer because it's visible",
  workbench_Notice_zheYiCiWoMen:
    'This time, we also added "daily data volume trend chart" and "cumulative quantity chart" at the bottom of the [user workbench]. You can click to enter the workbench and slide down to view your task data statistics - a direct view of a table to make your task clearer.',
  workbench_Notice_zhongShiChengZhangLu:
    'Pay attention to every feedback gained on the road of growth, constantly improve and optimize. Tapdata has been on the road all the time. Start with details and become great beauty. I look forward to seeing you again in the next new version',
  workbench_Notice_xinZengTengXunYun:
    'Tencent cloud database connection is added, tasks can be published regularly, and forms can be specified for re verification - tapdata with user experience firstCloud, start on the functional details again',
  workbench_Notice_xuQiuChiXuGeng3:
    'The requirements are continuously updated and optimized all the time - the March version of tapdata cloud is updated again!',
  workbench_Notice_zuiXinFaBuDe3:
    'Newly released 2.1.1In the version, Tencent\'s cloud database connection is new. While expanding the access area of cloud database again, it adheres to the iterative guidance of giving priority to user experience and focuses on removing three "small nails" that are easy to kick in the past use.',
  workbench_Notice_shuJuLianJieShang: 'New data connection and new cloud database access',
  workbench_Notice_ciFanZengJiaLe:
    ': tencentdb for is added this timeMysql, tencentdb for MariaDB, tencentdb for PG, tencentdb for sqlserver, and tencentdb mongodbAs source and target;',
  workbench_Notice_kaiShiZhiChiRen: 'Start supporting task "scheduled release"',
  workbench_Notice_quanLiangRenWuKe2:
    '1. The "execution cycle" can be specified for the "full quantity" task, and the "planned running time" can also be set for the "full quantity + increment" & "increment" taskSecond, liberate migrant workers, non working hours are not hard;',
  workbench_Notice_kaiShiZhiChiZhi: 'Start to support "revalidation" of specified single table or multiple tables',
  workbench_Notice_shuJuJiaoYanHuan:
    ": in the data verification phase, you can independently initiate re verification for tables with inconsistent verification. You don't have to start from scratch, and you're not afraid of a large amount of data and multiple tables;",
  workbench_Notice_ziDuanYingSheGuo2: 'Single table name modification is supported during field mapping',
  workbench_Notice_zaiYuanYouDePi:
    ': on the basis of the original batch table name change, the modification for a single table name is added to realize the freedom of table name change and easier operation.',
  workbench_Notice_yunShuJuKuJie: 'New cloud database access',
  workbench_Notice_banTuYouJianXin: 'The territory has seen a new look, and Tencent cloud database has now settled in',
  workbench_Notice_zuoWeiGuoNeiShou2:
    'As the first heterogeneous database real-time synchronization cloud platform in China, tapdata cloudContinuously expand the data connection layout that can be supported, strive to meet the diversified data sources and target needs of users, and truly realize the "comprehensive breaking wall" of real-time data synchronization',
  workbench_Notice_jiBanBenShouCi:
    'Following the first cloud database access in version 2.1.0, tapdata cloud continues to make efforts. In this update, China Cloud database will go to five cities and support tencentdb forMysql, tencentdb for MariaDB, tencentdb for PG, tencentdb for sqlserver, tencentdb mongodb as the source and target,',
  workbench_Notice_shuJuYuanJuDian: 'Number of data source sites expanded to',
  workbench_Notice_fangDaJiuKanT:
    '。 Zoom in to see the latest achievements of tapdata cloud\'s "wall breaking operation" 👇：',
  workbench_Notice_hINiDeRen: 'Hi, your task has been released regularly',
  workbench_Notice_buBeiDongJiaBan:
    'Do not work overtime passively. Start by setting the "execution cycle" and "running" time independently',
  workbench_Notice_haiZaiWeiXuYao2: 'Are you still depressed about the need to start tasks during non working hours?',
  workbench_Notice_haiZaiWeiXuYao:
    'Are you still having a headache about the need to manually start periodic full-scale tasks over and over again?',
  workbench_Notice_niXiangYaoDeRen: '——The "scheduled release of tasks" function you want is online.',
  workbench_Notice_quanLiangZengLiangJi:
    'For [full amount + increment] and [increment] tasks, "start time" can be specified',
  workbench_Notice_zhenDuiQuanLiangZeng:
    'For [full quantity + increment] and [increment] tasks, the [planned running time] setting is added in the task attribute setting. This setting is closed by default, and you can choose whether to enable it according to the actual needs.',
  workbench_Notice_juTiLiuChengDa2:
    'Specific process: open the setting and display the time selection control → select the planned running time as needed, and the optional time is: [current time, + ∞) → complete other settings and save the task → the task is triggered to start and run at the specified time',
  workbench_Notice_shouDongHuaZhongDian:
    '(* manually highlight: if [task save time] ≥ [planned run time], the task will start when the settings are saved successfully,',
  workbench_Notice_baoCunQianQingWu: 'Please carefully check whether the time setting is correct before saving',
  workbench_Notice_daKaiSheZhi: 'Open Settings',
  workbench_Notice_xuanZeYunXingShi: 'Select run time',
  workbench_Notice_sheZhiShiJianQian: 'The task was not started before the time was set',
  workbench_Notice_sheZhiShiJianDao: 'When the set time is up, the task starts',
  workbench_Notice_quanLiangRenWuKe: '[full quantity] task can specify "operation cycle"',
  workbench_Notice_zhenDuiQuanLiangRen:
    'For the [full volume] task, the [scheduled task] setting is added in the task attribute setting. This setting is also closed by default and can be selected on demand.',
  workbench_Notice_juTiLiuChengDa:
    'Specific process: open the setting and display the [scheduling expression] input box → hover the help icon to display the input help and sample of cron expression → fill in the task cycle according to the instructions and actual needs → complete other settings and save the task → the task runs stably according to the set fixed time, date and interval',
  workbench_Notice_zhiLuShuRuKuang:
    'After the direction input box, you can see the instructions for filling in the dispatching expression',
  workbench_Notice_shiLiSheZhiTiao: 'Example: set the scheduling cycle to run every five minutes',
  workbench_Notice_renWuWeiQiDong: 'Task not started',
  workbench_Notice_renWuDiYiCi: 'The task starts for the first time',
  workbench_Notice_renWuZaiCiQi: 'The task starts again',
  workbench_Notice_zhiChiDuiZhiDing: 'Supports re verification of the specified table',
  workbench_Notice_zhiYouGeBieBiao:
    'Only individual table verification is inconsistent? Now you can delimit a small area and recheck it!',
  workbench_Notice_congZheYiBanKai2:
    '📣 From this version, when there is a problem of inconsistent data verification, there is no need to re perform the whole verification task!',
  workbench_Notice_xinBanBenZhiChi2:
    'The new version supports selecting one or more tables from the current execution results on the data verification results page to start the data verification task again. The task execution status and results will directly update the current verification results. Come back byeBye, efficiency high~',
  workbench_Notice_ziDuanYingSheShi: 'Field mapping supports modifying a single table name',
  workbench_Notice_daPoJuXianGeng: 'Break the limitations and be more convenient',
  workbench_Notice_tAPDA5:
    'Tapdata Cloud 2.1.1In view of the limitations of the function of "only supporting batch change of table name" in the historical version in the actual operation environment, starting from the actual needs of users, the ability of "single table name modification" is added on the basis of the original function of "batch change of table name".',
  workbench_Notice_xinGongNengXiaYong: 'Under the new function, users can:',
  workbench_Notice_zaiQianYiGuoCheng:
    'In the migration process, you can freely modify the table name (not just the pre suffix), so as to realize',
  workbench_Notice_yuanBiaoShuJu: 'Source table data',
  workbench_Notice_xieRu: 'write in',
  workbench_Notice_zhiDingMuBiaoBiao: 'Specify target table',
  workbench_Notice_tongGuoXiuGaiMu: 'By modifying the target table name to the same table name, the',
  workbench_Notice_duoGeJieGouXiang: 'Multiple source tables with the same structure',
  workbench_Notice_tongYiMuBiaoBiao: 'Same target table',
  workbench_Notice_tAPDA4:
    'Tapdata cloud 2.1.2 is coming: big wave details are ready! Field types can be modified in batch, support wechat code scanning login, and add Vika as the goal',
  workbench_Notice_xuQiuChiXuGeng2:
    'Requirements are constantly updated and optimized all the time - tapdata cloud version 2.1.2 is coming!',
  workbench_Notice_zuiXinFaBuDe2:
    'In the latest release, Vika is supportedAs the goal, in order to quickly import data, we use wig table to realize zero code cooperation system and build a "bridge". At the same time, we will continue to adhere to the iterative orientation of giving priority to user experience, open support wechat code scanning registration and login, focus on details and focus on improvementThe ease of use of tapdata cloud at the practical level.',
  workbench_Notice_xinZengZhiChiV: 'New support for Vika',
  workbench_Notice_daTongYuXinYi:
    ': open up the real-time data channel with "new generation team data collaboration + project management artifact", and help further improve the efficiency of business transformation and collaboration;',
  workbench_Notice_ziDuanLeiXingKe: 'Field types can be modified in batch',
  workbench_Notice_ziDuanYingSheGuo:
    ': the ability to batch modify new types in the field mapping process. When modifying types, you can choose to apply them to all tables of the current task;',
  workbench_Notice_saoMaDengLuGong: 'Code scanning login function online',
  workbench_Notice_zhiChiWeiXinSao:
    ': it supports wechat code scanning registration and login. One click operation makes it faster to scan and use;',
  workbench_Notice_gengDuoXiJieYou: 'More details optimization',
  workbench_Notice_duanXinTongZhiCe:
    '✔ Optimize the SMS notification strategy. The SMS notification is turned off by default and can be turned on as needed',
  workbench_Notice_chuangJianLianJieShi:
    '✔️ When creating a connection, you can quickly search and locate the data source and target through the connection type and connection name',
  workbench_Notice_kaiShiZhiChiV: 'Start supporting Vika as a goal',
  workbench_Notice_shuJuLianJieYou: 'Data connection adds new members',
  workbench_Notice_qingLiangQingLiangGeng: 'Light weight + light weight = easier to use',
  workbench_Notice_benCiGengXinZhong:
    'The new data target Vika in this updateVig table integrates the underlying visual database, spreadsheet, real-time network collaboration and low code development technology, making data management lightweight. When the lightweight heterogeneous data real-time synchronization tool meets the lightweight data management tool, it will be created in the new era of digitization1 + 1 > 2. Users with tapdata cloudIt can quickly import business system and other data into wig table, and provide a stable and reliable digital basis for more agile use of wig table for team data collaboration and project management. So far, tapdataCloud data connection sites expanded to',
  workbench_Notice_lingFuCaoZuoYan: 'An operation demonstration is attached. Click to see how to',
  workbench_Notice_jiangXueShengChengJi: 'Import student grades into Vika',
  workbench_Notice_2: '：',
  workbench_Notice_caoZuoYanShiJiang: 'Operation demonstration: import student scores into Vika',
  workbench_Notice_zhiChiZiDuanLei: 'Batch modification of field types is supported',
  workbench_Notice_ziDuanLeiXingZhuan:
    'What should I do if the field type conversion exception causes an error in the task? Now you can modify it manually!',
  workbench_Notice_tAPDA3:
    'Tapdata Cloud 2.1.2Aiming at the problem of task errors caused by abnormal field type conversion during data migration in the historical version, it began to support batch modification of field types (you can choose to apply to all tables of the current task during modification), providing users with the ability to manually modify the field type conversion mapping relationship.',
  workbench_Notice_shiXianSaoMaZhu: 'Realize code scanning registration and login',
  workbench_Notice_jiSaoJiYongKuai: 'Scan and use quickly',
  workbench_Notice_zhangHaoMiMaRong:
    'Account and password are easy to mix, and SMS verification has to wait. What if you want to log in quickly?',
  workbench_Notice_congXianZaiKaiShi:
    '📣 From now on, after scanning wechat, you can start your trip of real-time synchronization of heterogeneous data in tapdata cloud - the new version of tapdata cloudSupport new users to quickly register and log in with one click through wechat scanning code, making the first step of the journey more convenient; At the same time, it also supports old users to bind their existing accounts through wechat to optimize their login experience.',
  workbench_Notice_chuCiSaoMaDeng:
    'The first time you scan the code and log in, you can synchronously follow the tapdata official account, get first-hand information such as first-line case analysis and the new version of the operation guide at the first time, and master all the popular information.',
  workbench_Notice_weiXiaoDanTieXin: 'Small but intimate, and the use experience is constantly upgraded',
  workbench_Notice_yongHuDaoXiangXi:
    'User oriented, detail oriented - this time, we optimized the SMS notification strategy and the connection creation process.',
  workbench_Notice_ziZhuKaiGuanDuan: 'Self service switch SMS notification permission',
  workbench_Notice_aGENT:
    "Agent offline prompt, agent operation notification, task exception alarm - don't want to be frequently disturbed by unnecessary SMS reminders?",
  workbench_Notice_xinBanBenDeDuan:
    'The new version of SMS notification strategy has been optimized. The SMS notification of new users will be turned off by default (the settings of old users remain unchanged). You can choose to turn it on or turn it off in the notification settings according to your actual needs.',
  workbench_Notice_gengKuaiDingWeiLian: 'Locate connection types faster',
  workbench_Notice_suoWeiBanTuZhi:
    'The so-called territory is too big to fit on one screen. With the development of tapdata cloudThe types of data connections supported are expanding, and the need to quickly locate data sources and targets in the process of creating connections has also been put on the agenda.',
  workbench_Notice_xinBanBenZhiChi:
    'The new version supports quick search and location of data sources and targets through connection type filtering and fuzzy query of connection name when creating connections - all changes are for easier use.',
  workbench_Notice_tAPDA2:
    'Tapdata 2.1.3 is coming: Apache Doris is added as the target, and the task query is faster!',
  workbench_Notice_xuQiuChiXuGeng: 'Requirements are constantly updated and optimized - tapdata cloud 2.1.3 is coming!',
  workbench_Notice_zuiXinFaBuDe:
    'In the newly released version, in addition to supporting Apache Doris, the query of task log is also more humanized.',
  workbench_Notice_xinZengZhiChiA: 'New support for Apache Doris',
  workbench_Notice_qianShouGengDuoYou:
    ': join hands with more excellent domestic databases to explore more possibilities of a new generation of data architecture;',
  workbench_Notice_renWuRiZhiCha: 'Task log query path optimization',
  workbench_Notice_kaiShiZhiChiZai:
    ': start to support the direct export of logs on the task operation monitoring page, making the query faster;',
  workbench_Notice_kaiShiZhiChiD: 'Start supporting Doris as the goal',
  workbench_Notice_qiangQiangLianShouGong: 'Join hands to build the next generation data architecture',
  workbench_Notice_suiZheXinXingGuo:
    'With the continuous emergence of emerging domestic databases, tapdata cloud continues to work with more high-quality domestic databases. The new data target Apache in this updateDoris, also launched recently',
  workbench_Notice_tAPDA: 'Tapdata PDK ecological co construction plan',
  workbench_Notice_deShouPiGongJian:
    'One of the first co construction partners will work with tapdataJoin hands to break the data island, build a next-generation data architecture, and provide users with an efficient and unified data application and analysis platform.',
  workbench_Notice_zhiCiTAP: 'So far, tapdata cloud',
  workbench_Notice_shuJuLianJieJu: 'Number of data connection sites expanded to',
  workbench_Notice_xiaoYouHuaGengTie: 'Small optimization, more intimate',
  workbench_Notice_congZheYiBanKai:
    "📣 From this version, when you need to query the task log, you don't need to go back to the agent to pull it!",
  workbench_Notice_xinBanBenXiaDang:
    "In the new version, when there is a problem with the user's task and you need to view the log to locate the problem, you can directly export the log on the operation monitoring page (you can select [time range]) without returningAgent deployment server finds log files. The operation is more humanized!",
  workbench_Workbench_tAPDA5: 'Tapdata cloud version 2.1.3 has been released!',
  workbench_Workbench_tAPDA4: 'Tapdata cloud version 2.1.2 has been released!',
  workbench_Workbench_tAPDA3: 'Tapdata cloud version 2.1.1 has been released!',
  workbench_Workbench_tAPDA2: 'Tapdata cloud version 2.1.0 has been released!',
  workbench_Workbench_tAPDA: 'Tapdata cloud version 2.0.1 has been released!',
  workbench_Notice_tAPDA1:
    'Tapdata 2.1.4 is coming: the data connection is new again. Polardb MySQL and light flow start to access, which can automatically mark unsupported field types',
  workbench_Notice_xuQiuChiXuGeng1:
    'Requirements are constantly updated and optimized - tapdata cloud 2.1.4 is coming!',
  workbench_Notice_zuiXinFaBuDe1:
    'In the latest released version, the default flag does not support synchronized field types when adding data connections, so as to avoid affecting the normal operation of tasks.',
  workbench_Notice_shuJuLianJieShang1: 'New data connection',
  workbench_Notice_xinZengZhiChiA1:
    ': Alibaba cloud polardb MySQL is supportedAs the source and target, the new platform "light flow" supporting codeless system is added as the target;',
  workbench_Notice_ziDongBiaoJiBu: 'Unsupported field types are automatically marked',
  workbench_Notice_duiYuYiJingMing:
    ': for the field type that does not support synchronization, it is marked as not supported by default during field mapping. Quickly locate and delete to ensure the normal operation of the task.',
  workbench_Notice_shuJuLianJieZai: 'Add new members to data connection',
  workbench_Notice_chiXuDaZaoDe: 'Continue to create a user experience of 1 + 1 > 2',
  workbench_Notice_zuoWeiGuoNeiShou1:
    'As the first heterogeneous database real-time synchronization cloud platform in China, tapdata cloudContinuously expand the data connection layout that can be supported, strive to meet the diversified data sources and target needs of users, and truly realize the "comprehensive breaking wall" of real-time data synchronization. 2.1.4New partners have joined the version:',
  workbench_Notice_xinZengZhiChiP: 'Polardb MySQL is added as the source and target',
  workbench_Notice_suiZheXinXingGuo1:
    'With the continuous emergence of emerging domestic databases, tapdata cloud continues to work with more high-quality domestic databases. The latest access in this update',
  workbench_Notice_aLiYunPO: 'Alibaba cloud polardb MySQL',
  workbench_Notice_tongShiYeShiJin: 'It was also launched recently',
  workbench_Notice_deShouPiGongJian1:
    'One of the first co construction partners will work with tapdata to provide users with a better data as a service (DAAS) experience,Jointly prosper the cloud native distributed database ecosystem.',
  workbench_Notice_xinZengZhiChiQing: 'Added support for "light flow" as the target',
  workbench_Notice_mianDuiJinJiZhong:
    'In the face of the SaaS wave under attack and aiming at the diversified target needs of users, tapdata cloud plans steadily and continues to work together. The new version starts to support high quality',
  workbench_Notice_sAASFu: 'SaaS service tool "light flow"',
  workbench_Notice_weiShuJuMuBiao:
    'For data targets. As a codeless system building platform, light flow supports 0 code and quickly builds business systems, which can effectively improve work efficiency and reduce management costs. When the lightweight heterogeneous data real-time synchronization tool meets the lightweight digital management tool, the ease of use of the two can be doubled. User assistanceTapdata cloud quickly imports business data into light flow, providing stable and reliable data support for more agile use of light flow for digital management.',
  workbench_Notice_ziDongBiaoJi: 'Automatic marking',
  workbench_Notice_buZhiChiDeZi: 'Unsupported field type',
  workbench_Notice_kuaiSuDingWeiShan: 'Quickly locate and delete, and the task runs unimpeded',
  workbench_Notice_zhenDuiLiShiBan1:
    'In the historical version, errors are reported because the special field types in some databases do not support synchronization, which affects the normal operation of the task. The new version gives a solution:',
  workbench_Notice_gaiBanBenXiaDui:
    'In this version, for field types that explicitly do not support synchronization, they will be marked as not supported by default during field mapping. These fields will be automatically deleted when entering the field mapping page, and there is no need to locate them manually（',
  workbench_Notice_huaZhongDian: '*Focus',
  workbench_Notice_yongHuKeYiZai:
    ': the user can clearly see in the task interface that the corresponding field is deleted because [not supported], and the [deleted] field does not support recovery',
  workbench_Notice_congErBaoZhengRen:
    "）So as to ensure the normal operation of the task and avoid frequent errors caused by users' unclear which fields are not supported.",
  workbench_Workbench_tAPDA1: 'Tapdata cloud version 2.1.4 has been released!',
  field_mapping_field_mapping_dialog_buZhiChi: "I won't support it",
  components_MqQueueOrTopic_zhuTi: 'theme',
  components_MqQueueOrTopic_duiLie: 'queue',
  components_MqQueueOrTopic_zhuTiHeDuiLie: 'Only one subject and queue can be selected for configuration',
  components_ErrorLogDialog_cuoWuRiZhiCha: 'Error log view',
  components_ErrorLogDialog_qingQianWangAG: 'Please go to the agent deployment directory to view the log',
  components_ErrorLogDialog_zhaKanGengDuoRi: 'View more logs',
  views_Lang_pingBiGuoJiHua: 'Shielding internationalization - Rules',
  views_Lang_wenAnBaoHanDe: 'Values contained in the document, list: A, B, C',
  views_Lang_wenAnDengYuDe: 'Copy equals the value of, list: A, B, C',
  views_Lang_qingShuRuJiaoZheng: 'Please enter correction copy',
  copy_result: 'Copied to clipboard',
  views_Lang_shangChuanChengGongShua:
    'If the upload is successful, refresh the page to take effect and merge it into the existing copy. If the existing copy needs to be used, please export it first.',
  workbench_Notice_tAPDA1213:
    'Tapdata cloud 2.1.5 is coming: Amazon RDS database is newly supported, error log query is more convenient, and agent deployment details are optimized',
  workbench_Notice_xuQiuChiXuGeng12:
    'Requirements are constantly updated and optimized - tapdata cloud 2.1.5 is coming!',
  workbench_Notice_zuiXinFaBuDe12:
    'In the latest released version, the data connection is updated again, and a quick query entry of task error related information is added, which starts to support the custom setting of JVM parameters.',
  workbench_Notice_shuJuLianJieShang12: 'New data connection',
  workbench_Notice_chiXuQianShouYun:
    ': continue to join hands with Alibaba cloud database and add support for Alibaba cloud polardbPostgreSQL and Amazon RDS for MySQL as the source and target;',
  workbench_Notice_xinZengCuoWuRi2: 'New error log quick query entry',
  workbench_Notice_renWuYunXingChu:
    ': when the task runs in error, you can preview the error information directly through the pop-up window. At the same time, you can get the complete log query entry at the bottom of the pop-up window, and you can quickly reach the log display page with one click;',
  workbench_Notice_aGENT2: 'Agent deployment configuration optimization',
  workbench_Notice_kaiShiZhiChiZi:
    'Avoid supporting custom adjustment of JVM configuration at the beginning, and effectively:Memory overflow caused by agent startup.',
  workbench_Notice_shuJuLianJieZai1: 'Add new members to data connection',
  workbench_Notice_pOLAR: 'Polardb, PostgreSQL and Amazon RDS for MySQL are connected',
  workbench_Notice_zuoWeiGuoNeiShou12:
    'As the first heterogeneous database real-time synchronization cloud platform in China, tapdata cloudContinuously expand the data connection layout that can be supported, strive to meet the diversified data sources and target needs of users, and truly realize the "comprehensive breaking wall" of real-time data synchronization.',
  workbench_Notice_jiBanBenShouCi1:
    'Following the first cloud database access in version 2.1.0, tapdata cloud continues to make efforts, and new partners are added in this update: Alibaba cloud polardb is newly supportedPostgreSQL and Amazon RDS for MySQL are the source and target. So far, the number of tapdata cloud data connection sites has expanded to',
  workbench_Notice_fangDaJiuKanT1:
    '。 Zoom in to see the latest achievements of tapdata cloud\'s "wall breaking operation" 👇：',
  workbench_Notice_xinZengCuoWuRi: 'New error log',
  workbench_Notice_kuaiSuChaXunRu: 'Quick query entry',
  workbench_Notice_tanChuangYuLanYi: 'Pop up preview, one click direct',
  workbench_Notice_renWuBaoCuoXiang:
    'If the task reports an error, what should I do if I want to query the error log faster?',
  workbench_Notice_congZheYiBanBen:
    "📣 Starting from this version, log query will be faster! When a task runs in error, you don't need to go back to the operation monitoring page to export the error log. You can preview the error information directly through the pop-up window. At the same time, you can get the complete log query entry at the bottom of the pop-up window. You can click directly to the log display page for quick viewing and quick positioning, which is more convenient to use!",
  workbench_Notice_renWuBaoCuoDian: 'The task reports an error. Click to view the error log',
  workbench_Notice_aGENT1: 'Agent deployment details optimization',
  workbench_Notice_zhiChiJVM: 'Support JVM custom configuration',
  workbench_Notice_qiDongGengFangXin: 'Start more assured',
  workbench_Notice_zhenDuiLiShiBan12:
    'In view of the memory overflow problem that may be caused by the small default allocated memory during the agent installation of the historical version, the new version gives an optimization scheme:',
  workbench_Notice_xianJiangJVM:
    'Now the JVM parameter setting permission is open, and users can customize and adjust according to their own server configuration. AgentWhen starting, it will automatically prompt the memory usage. The user can adjust and restart it in the configuration file according to the actual needs.',
  workbench_Notice_peiZhiWenJianKai: "JVM parameter name opened by configuration file: tapdatajavaopts: '- xmx2362m'",
  workbench_Notice_beiZhuMoRenQi:
    '*Note: by default, startup occupies 3 / 5 of the system configuration memory. If 3 / 5 of the system memory exceeds 8g, it only occupies 8g at most.',
  workbench_Workbench_tAPDA12: 'Tapdata cloud version 2.1.5 has been released!',

  // web-core
  tap_login: 'Tapdata-Login',
  tap_registry: 'Tapdata-register',
  tap_verificationEmail: 'Tapdata-Email verification',
  tap_passwordReset: 'Tapdata-Modify Password',
  tap_connection: 'Tapdata-Connection ',
  tap_connectionEdtion: 'Tapdata-ConnectionEdtion',
  tap_jobFlow: 'Tapdata-JobFlow',
  tap_jsFuncs: 'Tapdata-JsFuncs',
  tap_dataCatalog: 'Tapdata-DataCatalog',
  tap_metadata: 'Tapdata-MetadataManagement',
  tap_metadataInstances: 'Tapdata-MetadataInstances',
  tap_dataQuality: 'Tapdata-DataQuality',
  tap_TimeToLive: 'Tapdata-TimeToLive',
  tap_dataLineage: 'Tapdata-DataLineage',
  tap_dataRules: 'Tapdata-DataRules ',
  tap_apiManagement: 'Tapdata-APIManagement ',
  tap_apiEdition: 'Tapdata-APIEdition',
  tap_dataExplor: 'Tapdata-DataExplor',
  tap_docTest: 'Tapdata-Doc&Test',
  tap_apiStats: 'Tapdata-API Stats',
  tap_apiClients: 'Tapdata-APIClients ',
  tap_apiSever: 'Tapdata-APISever',
  tap_dictionary: 'Tapdata-Dictionary',
  tap_topology: 'Tapdata-Topology',
  tap_serversOversee: 'Tapdata-ServersOversee',
  tap_journal: 'Tapdata-Journal',
  tap_apiInfo: 'Tapdata-APIInfo',
  tap_taskHistories: 'Tapdata-Scheduling History',
  tap_agentdownload: 'Tapdata-Agentdownload',
  tap_dataCollect: 'Tapdata-DataCollect',
  tap_upload: 'Tapdata-Upload',
  tap_jobSchedule: 'Tapdata-JobSchedule',
  tap_clusterManagement: 'Tapdata-ClusterManagement ',
  tap_agentManagement: 'Tapdata-AgentManagement ',
  tap_userManagement: 'Tapdata-UserManagement ',
  tap_userEdition: 'Tapdata-UserEdition',
  tap_roleManagement: 'Tapdata-RoleManagement',
  tap_roleEdition: 'Tapdata-RoleEdition ',
  tap_systemSettings: 'Tapdata-SystemSettings',
  tap_account: 'Tapdata-Account',
  tap_settingCenter: 'Tapdata-Setting Center',
  tap_sharedMining: 'Tapdata-shared mining',
  errorCode_networkUnconnected: 'Network unconnected',
  errorCode_serverAbnormal: 'Server abnormal',
  errorCode_requested: 'The resource you requested not existed',
  errorCode_unauthorized: 'Unauthorized',
  errorCode_parameters: 'Incorrect input parameters',
  errorCode_timeout: 'Request time out',
  app_document: 'Documentation',
  app_qa: 'Customer Service',
  app_account: 'Account',
  app_version: 'Version',
  app_home: 'Home',
  app_signOut: 'Sign out',
  app_signOutMsg: 'Are you sure to sign out?',
  app_save: 'Save',
  app_customerService_technicalSupport: 'User Support',
  app_customerService_technicalSupportText: 'Any question, please submit to',
  app_customerService_technicalSupportText1:
    'The account and password of Support Forum is same as cloud.tapdata.net.We will response you as soon as possible.',
  app_customerService_userSupport: 'Support Forum',
  app_customerService_otherDmands: 'Other Requirements',
  app_customerService_otherDmandsText: 'Any requirement, please contact us by scanning WeChat QR below.',
  app_signIn_slogan: 'Use your data, as easy as water from tap',
  app_signIn_signIn: 'Sign in',
  app_signIn_keepSignIn: 'Keep signed in',
  app_signIn_email_placeholder: 'Enter your email',
  app_signIn_inviteCode_placeholder: 'invite code',
  app_signIn_password_placeholder: 'Enter your password',
  app_signIn_email_require: 'E-mail is required.',
  app_signIn_inviteCode_require: 'invite code is required.',
  app_signIn_inviteCode_invalid: 'invite code must be valid.',
  app_signIn_email_invalid: 'E-mail must be valid.',
  app_signIn_password_invalid: 'Password at least 5 characters.',
  app_signIn_account_waiting_approve: 'Your account is waiting administrator to approve.',
  app_signIn_account_disabled: 'Your account is disabled by administrator.',
  app_signIn_permission_denied: 'Permission denied.',
  app_signIn_signInFail: "The email and password didn't work.",
  app_signIn_watingApprove: 'This account is not approved, please wait for contact email.',
  app_signIn_accountDisabled:
    'Your account has been frozen, if you have any questions, please contact customer service. ',
  app_signIn_hasVerified: 'The email has not been verified',
  app_signIn_registry: 'Registration',
  app_signIn_registry_tip: 'I agree with',
  app_signIn_userPplicy: ' user policy',
  app_signIn_nextStep: 'Next',
  app_signIn_haveAccpunt: 'Remember account?',
  app_signIn_backLogin: 'Back to login',
  app_signIn_email_existed: 'Email address has been registered',
  app_signIn_userPplicy_message: 'Please tick "agree with user policy"',
  app_signIn_modifyPassword: 'Reset password',
  app_signIn_newPasswordTip:
    'Enter your registered mailbox and new password, and we will send you confirmation email and click link to reset password',
  app_signIn_newpassword_placeholder: 'Please set a new password',
  app_signIn_rememberPasswords: 'Remember passwords?',
  app_signIn_Registration: 'Register an account',
  app_signIn_forgetPassword: 'Forget password?',
  app_signIn_confirmationEmail: 'Registration confirmation email has been sent to',
  app_signIn_mailbox: 'Please log in to the mailbox and click the link to confirm~',
  app_signIn_receiveEmail: "Didn't receive email? Click",
  app_signIn_resend: 'Resend',
  app_signIn_orClick: 'or click',
  app_signIn_account: 'Account',
  app_signIn_accountSuccess: 'has been successfully registered~',
  app_signIn_clickBtn: 'Click the button below to enjoy the journey of data transmission',
  app_signIn_resetClickBtn: 'Click the button below to log in',
  app_signIn_goLogin: 'Go login',
  app_signIn_connectionFailed: 'registration confirmation link is invalid',
  app_signIn_resetConnectionFailed: 'reset password confirmation link is invalid',
  app_signIn_clickText: 'Click',
  app_signIn_confirmEmail: 'Please re',
  app_signIn_registered: ' Registered',
  app_signIn_resetAccountSuccess: 'The password has been reset successfully~',
  app_signIn_passwordResetText: 'Reset password email has been sent to',
  app_signIn_notMailbox: 'oops~This mailbox has not been registered yet',
  app_signIn_hasMailbox: 'oops~This mailbox has already been registered',
  app_signIn_disableSignup: 'oops~Disable Signup',
  app_signIn_getCode: 'Get InviteCode',
  app_signIn_qrCodeText: 'Scan wechat QR Code to get invite code',
  app_menu_dashboard: 'Dashboard',
  app_menu_connections: 'Data Source',
  app_menu_dataSync: 'Data synchronization',
  app_menu_dataTransmission: 'Data Transmission',
  app_menu_dataFlows: 'Data Collect',
  app_menu_dataFlowsAll: 'All tasks',
  app_menu_dataFlowsRunning: 'Running',
  app_menu_dataFlowsError: 'Error',
  app_menu_dataFlowsPaused: 'Paused',
  app_menu_dataFlowsDraft: 'Draft',
  app_menu_dataGovernance: 'Data Governance',
  app_menu_metadataDefinition: 'Metadata management',
  app_menu_metadata: 'Data Catalog',
  app_menu_metadataSearch: 'Data Search',
  app_menu_dataQuality: 'Data Quality',
  app_menu_timeToLive: 'Time To Live',
  app_menu_dataMap: 'Data Lineage',
  app_menu_dataRules: 'Data Rules',
  app_menu_dictionary: 'Dictionary model',
  app_menu_dataPublish: 'Data Publish',
  app_menu_modules: 'API Management',
  app_menu_dataExplorer: 'API Data Explorer',
  app_menu_apiDocAndTest: 'API Doc&Test',
  app_menu_apiAnalysis: 'API Stats',
  app_menu_applications: 'API Clients',
  app_menu_apiServers: 'API Server',
  app_menu_dataCollect: 'Data Collect(Old)',
  app_menu_system: 'System',
  app_menu_tasks: 'Schedule Tasks',
  app_menu_taskHistories: 'Scheduling History',
  app_menu_agentdownload: 'Agent Download',
  app_menu_clusterManagement: 'Cluster management',
  app_menu_agentManagement: 'Agent management',
  app_menu_agents: 'Agents',
  app_menu_serversOversee: 'Servers Oversee',
  app_menu_users: 'User Management',
  app_menu_journal: 'User action log',
  app_menu_roles: 'Role Management',
  app_menu_settings: 'System settings',
  app_menu_favorite: 'Favorite',
  app_menu_dataVerification: 'Data Verification',
  app_menu_delFavMenu: 'Delete Favorite',
  app_menu_license: 'License manage',
  app_menu_licenseBefore: 'Info: License remaining ',
  app_menu_licenseAfter: ' days',
  app_menu_licenseDate: 'License expiration time',
  app_menu_licenseAfterOneDay: ' day',
  app_menu_dataFlowsClusterClone: 'Database Migration',
  app_menu_dataFlowsCustom: 'Data Sync',
  app_menu_topology: 'Topology',
  app_menu_sharedMining: 'Shared Mining',
  app_menu_function: 'function management',
  app_Home_all: 'All',
  app_Home_syncJobsOverview: 'Sync Jobs Overview',
  app_Home_migrationJobsOverview: 'Migration Jobs Overview',
  app_Home_allTask: 'All tasks',
  app_Home_transmissionOverview: 'Transmission Overview',
  app_Home_transferTask: 'Transfer Task',
  app_Home_wrongTask: 'Wrong Task',
  app_Home_taskRanking: 'Task Transfer Ranking',
  app_Home_serverProcess: 'Server and Process',
  app_Home_syncJobsStatus: 'Sync Jobs Status',
  app_Home_migrationJobsStatus: 'Migration Jobs Status',
  app_Home_dataValidationTitle: 'Data Validation',
  app_Home_before: 'Front',
  app_Home_pcs: 'bar',
  app_Home_server: 'Server',
  app_Home_managementSide: 'Management Side',
  app_Home_taskTransfer: 'Task Transfer',
  app_Home_apiService: 'API Service',
  app_Home_totalOutput: 'Total Output',
  app_Home_totalInput: 'Total Input',
  app_Home_bar: 'PCS',
  app_Home_starting: 'Starting',
  app_Home_running: 'Running',
  app_Home_stopping: 'Closed',
  app_Home_stopped: 'closed',
  app_Home_initialization: 'Initializing',
  app_Home_loadingFinished: 'Initialization completed',
  app_Home_incremental: 'CDC',
  app_Home_incrementalLag: 'CDC Lag',
  app_Home_allValid: 'All verification tasks',
  message_noPermission: 'This operation lacks the appropriate permissions',
  message_api_get_error: 'Load data failed.',
  message_api_get_loading: 'Loading data...',
  message_verifyConfirm: 'Are you sure to delete JS verify logic',
  message_comfirm: 'Are you sure you want to ',
  message_operationSuccuess: 'Operation succuess.',
  message_modifyName: 'Modify name',
  message_ok: 'OK',
  message_nullName: 'Field name can not be empty',
  message_search: 'search',
  message_sourchName: 'Name',
  message_serverName: 'Server name',
  message_agentSetting: 'Agent server settings',
  message_iPDisplay: 'IP display',
  message_ipTip:
    'Switching the network card only changes the display of IP under the server of cluster management page, does not affect any function.',
  message_delTittle: 'Delete Agent server',
  message_delMessage: 'Are you sure to delete the server ',
  message_filter: 'Filter',
  message_addServerMon: 'Add server monitoring',
  message_startUp: 'Start up',
  message_close: 'Close',
  message_manageSys: 'Manage system',
  message_restart: 'restart',
  message_update: 'Update',
  message_syncGover: 'Syn gover',
  message_screen: 'Screen',
  message_delete: 'Delete',
  message_test: 'Test',
  message_copy: 'Copy',
  message_reload: 'Reload schema',
  message_preview: 'Detail',
  message_save: 'Save',
  message_deleteOrNot: 'Delete or not',
  message_placeholderMonServer: 'Please enter the monitored service name',
  message_placeholderCommand: 'Please enter command',
  message_nullContent: 'Can not be empty',
  message_saveOK: 'Saved successfully',
  message_saveFail: 'Save failed',
  message_copyFail: 'Copy failed',
  message_stopFail: 'stop failed',
  message_copySuccess: 'Copy successfully',
  message_deleteFail: 'Failed to delete',
  message_deleting: 'Deleting',
  message_taskStart: 'Job is getting started',
  message_selectTime: 'Select time',
  message_selectDate: 'Select date',
  message_server: 'Server',
  message_serviceType: 'Service type',
  message_level: 'Level',
  message_time: 'Time',
  message_hostName: 'Host name',
  message_ipAddress: 'IP address',
  message_uniqueEncode: 'Unique encoding',
  message_logs: 'Log',
  message_startupAfter_delete: 'Please delete after startup',
  message_startupAfter_add: 'Please add after startup',
  message_noData: 'NO DATA ',
  message_prompt: 'Prompt',
  message_resetMessage: 'This will cause the job to be rerun from the beginning, continue?',
  message_deteleMessage: 'This will permanently delete the job',
  message_deteleJobMessage: 'This will permanently delete the choosed jobs ?',
  message_forceStoppingMessage: 'This will interrupt the data transfer immediately, continue?',
  message_stopInitial_syncMessage:
    'Pausing job while it is in the initial sync stage may cause it to run from the beginning, are you sure you want to pause?',
  message_stopMessage: 'Are you sure to pause the mission?',
  message_stopAggregation_message:
    'Job XXX includes aggregation processor node, job will be reset when excutes restart，still excute pause?',
  message_startAggregation_message:
    'Job XXX includes aggregation processor node, job will be reset when excutes start job，still excute start?',
  message_cancelReset: 'cancel reset',
  message_resetOk: 'Reset success',
  message_resetFailed: 'Reset Failed',
  message_notRest: 'Please select the correct data to reset',
  message_operator: 'Operator',
  message_edit: 'Edit',
  message_clickRelatedTasks: 'Click to view related tasks',
  message_currentTaskOpen: 'The current task has been opened',
  message_noRelatedTask: 'No related tasks',
  message_loadingSchema: 'Schema of source database has not finished loading yet, please wait',
  message_reloadSchemaSuccess: 'Model update successfully',
  message_reloadSchemaError: 'Model update failed',
  cluster_cancel: 'Cancel',
  cluster_confirm: 'Confirm',
  cluster_confirmText: 'Confirm ',
  cluster_closeSever: ' Close service ',
  cluster_restartServer: ' Restart service ',
  cluster_startServer: ' Start service ',
  cluster_deleteOrNot: 'Delete or not',
  cluster_serviceCluMange: 'Service cluster management',
  cluster_update: 'Update',
  cluster_start: 'Start up',
  cluster_close: 'Close',
  cluster_restart: 'Restart',
  cluster_syncGover: 'Syn gover',
  cluster_delete: 'Delete',
  cluster_edit: 'Edit',
  cluster_reduction: 'Restore',
  cluster_time: 'Test',
  cluster_saveOK: 'Saved successfully',
  cluster_saveFail: 'Save failed',
  cluster_deleteOK: 'Successfully deleted',
  cluster_deleteFail: 'Failed to delete',
  cluster_selectTime: 'Select time',
  cluster_selectDate: 'Select date',
  cluster_placeholderSelect: 'Please select',
  cluster_statusLog: 'Status log',
  cluster_placeholderServer: 'Please enter a server name',
  cluster_manageSys: 'Manage system',
  cluster_addServerMon: 'Add server monitoring',
  cluster_agentSetting: 'Agent server settings',
  cluster_serverName: 'Server name',
  cluster_placeholderMonServer: 'Please enter the monitored service name',
  cluster_iPDisplay: 'IP display',
  cluster_ipTip:
    'Switching the network card only changes the display of IP under the server of cluster management page, does not affect any function.',
  cluster_delTittle: 'Delete Agent server',
  cluster_delMessage: 're you sure to delete the server ',
  cluster_startupAfter_delete: 'Please delete after startup',
  cluster_startupAfter_add: 'Please add after startup',
  cluster_noneText: ' is required.',
  cluster_hostName: 'Host name',
  cluster_ipAddress: 'IP address',
  cluster_uniqueEncode: 'Unique encoding',
  cluster_logs: 'Log',
  cluster_serviceType: 'Service type',
  cluster_level: 'Level',
  cluster_cpuUsage: 'CPU Usage',
  cluster_heapMemoryUsage: 'Heap memory usage',
  button_refresh: 'Refresh',
  button_rename: 'Rename',
  button_more: 'More',
  button_query: 'Query',
  button_all: 'All',
  dataFlow_leave: 'Leave',
  dataFlow_backlistText: 'Back to sync job list page',
  dataFlow_saveReminder:
    'This jobhas not been saved yet, If you leave this page, the job configuration will be lost. Are you sure to leave ?',
  dataFlow_saveFail:
    'Failed to save the task, please check the configuration and ensure that the data source status is valid.',
  dataFlow_aggregateNotDataNode: 'The first target data node of aggregation node can only be COLLECTION',
  dataFlow_batchSortOperation: 'Batch sort operation',
  dataFlow_selectRowdata: 'Please select row data',
  dataFlow_clusterClone: 'Database Migration',
  dataFlow_custom: 'Data Sync',
  dataFlow_searchNode: 'Search Node',
  dataFlow_updateModel: 'Reload Model',
  dataFlow_loadingText: 'Loading...',
  dataFlow_databseProcessingHead: 'Data Processing & Sync',
  dataFlow_databseMigrationHead: 'Database Migration',
  dataFlow_dataMigrationHead: 'Data Sync',
  dataFlow_databseFreedomHead: 'Custom Data Sync',
  dataFlow_createNew: 'Create New',
  dataFlow_DissedNoAction: 'oops~ The banned node/Connecting line can not be deleted and connected',
  dataFlow_notCopy: 'The banned node cannot be copied ',
  dataFlow_guidingMode: 'Guiding mode',
  dataFlow_advancedMode: 'Standard mode',
  dataFlow_freedomMode: 'Standard mode',
  dataFlow_advanceSetting: 'More advanced setting',
  dataFlow_closeSetting: 'Fold up',
  dataFlow_openPanel: 'Open',
  dataFlow_execution: 'Execution',
  dataFlow_previous: 'Previous',
  dataFlow_next: 'Next',
  dataFlow_sourceSetting: 'Source setting',
  dataFlow_targetSetting: 'Target setting',
  dataFlow_advancedetting: 'Advanced settings',
  dataFlow_simpleSceneTitle: 'Create a database replication task',
  dataFlow_sourceLibrarySetting: 'Source library structure and object settings',
  dataFlow_databseMigration:
    'With the guided mode to help understanding the operation method of databases migration which can quickly realize structure , inital, and CDC migration between databases.',
  dataFlow_databseProcessing:
    'With the  guided mode to help novice users to quickly understand the table level data processing and SYNC. This function can not only realize table level INITAL and CDC transmission, but also focus on various processors (JS processing, field filtering, aggregation processing, row level filtering, etc.) for complex logical processing demands.',
  dataFlow_databseFreedom:
    'Database migration can help users  to achieve structure,  inital, and CDC migration of multiple homogeneous or heterogeneous databases in one job. ',
  dataFlow_dataFreedom:
    'Data sync focuses on data processing (such as table merging, data splitting, joint mapping, field processing, content filtering, aggregation processing, JS processing ,etc )and sync of table-level real-time data sync.',
  dataFlow_moreFeatures: 'More Features',
  dataFlow_creatSource: 'Create data source',
  dataFlow_creatApi: 'Create API',
  dataFlow_dataValidation: 'Data Verification',
  dataFlow_sourceDescription:
    'The data source is the premise of creating the transmission job, the data source includes Database, File, GridFS, Rest API, View, Custom connection, etc.',
  dataFlow_apiDescription:
    'API, aka data publication API, you can create a new API which includes the paths of Post, Get, Patch, Delete.',
  dataFlow_datavaliDescription:
    'Data verification has the function of count verify, content verify, and joint field value verify which can verify the consistency of source and target.',
  dataFlow_multiError_allSelectionError: 'The status of selected job does not allow this operation.',
  dataFlow_multiError_notFound: 'This job does not existed.',
  dataFlow_multiError_statusError: 'Job status does not allow to do this operation.',
  dataFlow_multiError_otherError: 'Operation failed, please try it again.',
  dataFlow_changeName: 'Rename',
  dataFlow_Enable: 'Enable',
  dataFlow_Disable: 'Disable',
  dataFlow_draftNotStart: 'Configuration is not complete,  cannot be started',
  dataFlow_systemHint: 'System prompt',
  dataFlow_systemText: 'The system detected that the following tasks were not saved， keep editing?',
  dataFlow_stystemOpen: 'Open',
  dataFlow_stystemOpenAll: 'Open all',
  dataFlow_stystemDeleteAll: 'Delete all',
  dataFlow_stystemLgnoreAll: 'Ignore all',
  dataFlow_newTaksName: 'The_new_task',
  dataFlow_selectNode: 'Please select a node',
  dataFlow_submitExecute: 'Submit and execute',
  dataFlow_submitOnly: 'Submit only',
  dataFlow_implementationModalities: 'Execution method',
  dataFlow_submitConfirmation: 'Submit Confirmation',
  dataFlow_SyncPoint: 'CDC start timepoint',
  dataFlow_cdcLabel: 'Data source:',
  dataFlow_syncType: ' Type',
  dataFlow_belongAgent: 'Agent',
  dataFlow_SyncInfo_localTZ: 'Local Timezone CDC Time: custom a point of  CDC time，in local time zone',
  dataFlow_SyncInfo_current: 'Current Time：Current DB Time',
  dataFlow_SyncInfo_connTZ: 'DB Timezone CDC Time: custom a point of  CDC time，in the time zone of a specific server',
  dataFlow_Current: 'Current Time',
  dataFlow_SyncTime: 'Sync Time',
  dataFlow_batchDelete: 'Batch Delete',
  dataFlow_batchRest: 'Batch reset',
  dataFlow_bulkExport: 'Bulk Export',
  dataFlow_bulkImport: 'Bulk Import',
  dataFlow_bulkScheuled: 'Batch Start',
  dataFlow_bulkStopping: 'Bulk Stop',
  dataFlow_taskBulkFx: 'Function',
  dataFlow_taskBulkOperation: 'Bulk Operation',
  dataFlow_taskBulkTag: 'Bulk Tag',
  dataFlow_upload: 'Click to upload',
  dataFlow_chooseFile: 'Select a document',
  dataFlow_import: 'Task Import',
  dataFlow_uploadOK: 'Upload successful',
  dataFlow_uploadError: 'Upload failed',
  dataFlow_uploadInfo: 'Click to view details',
  dataFlow_view: 'View',
  dataFlow_dataFlowExport: 'Export',
  dataFlow_addTag: 'Add tag',
  dataFlow_overWrite: 'Overwrite existing data',
  dataFlow_skipData: 'Skip existing data',
  dataFlow_loadingError: 'Loading failed, please',
  dataFlow_loadLogTip: 'Run log is trying to load, it may take 5 ~ 10 seconds, please wait ...',
  dataFlow_noLogTip: 'No data',
  dataFlow_clickLoadTxt: 'Click to load',
  dataFlow_average: 'Average',
  dataFlow_allNode: 'All Nodes',
  dataFlow_taskName: 'Flow Name',
  dataFlow_creatdor: 'Creator',
  dataFlow_ownedUser: 'Owned User',
  dataFlow_ownedLibrary: 'Owned Library',
  dataFlow_creationTime: 'Start Time',
  dataFlow_state: 'State',
  dataFlow_executionTime: 'Lapsed Time',
  dataFlow_finishTime: 'finish Time',
  dataFlow_sourceLibrary: 'Source',
  dataFlow_targetLibrary: 'Target',
  dataFlow_inputNumber: 'Input Total',
  dataFlow_outputNumber: 'Output Total',
  dataFlow_rowCount: 'Row',
  dataFlow_timePoint: 'CDC timepoint',
  dataFlow_taskDetail: 'Task Details',
  dataFlow_nodeDetail: 'Node Information',
  dataFlow_unit: 'Unit',
  dataFlow_article: 'pcs',
  dataFlow_secondUnit: 'second',
  dataFlow_category: 'Category',
  dataFlow_status_running: 'Running',
  dataFlow_status_paused: 'Paused',
  dataFlow_status_draft: 'Editting',
  dataFlow_status_scheduled: 'Scheduled',
  dataFlow_status_stopping: 'Stopping',
  dataFlow_status_error: 'Error',
  dataFlow_status_force_stopping: 'Force Stopping',
  dataFlow_status_prepare: 'Prepare',
  dataFlow_status_cdc: 'CDC',
  dataFlow_status_initializing: 'Initializing',
  dataFlow_status_initialized: 'Initialized',
  dataFlow_status_Lag: 'Lag',
  dataFlow_status_all: 'All',
  dataFlow_lag: 'lag',
  dataFlow_executionStatus: 'Execution status',
  dataFlow_searchPlaceholder: 'Task name / Node name / DB name',
  dataFlow_searchAgent: 'Agent name',
  dataFlow_dataRange: 'Date range',
  dataFlow_startTime: 'Start time',
  dataFlow_endTime: 'End time',
  dataFlow_separator: 'to',
  dataFlow_dataPlaceholder: 'Select time range',
  dataFlow_taskStatus: 'Status',
  dataFlow_maxLagTime: 'Max lag time',
  dataFlow_taskStatusPlaceholder: 'Select task status',
  dataFlow_taskSettingPlaceholder: 'Select Sync type',
  dataFlow_updateTime: 'Update time',
  dataFlow_runningSpeed: 'Running speed',
  dataFlow_taskSwitch: 'Switch',
  dataFlow_operate: 'Operation',
  dataFlow_dataMap: 'Data Map',
  dataFlow_edit: 'Edit',
  dataFlow_copy: 'Copy',
  dataFlow_reset: ' Reset ',
  dataFlow_schedule: 'Schedule',
  dataFlow_run: 'Run',
  dataFlow_stop: 'Stop',
  dataFlow_cut: 'Cut',
  dataFlow_paste: 'Paste',
  dataFlow_undo: 'Undo',
  dataFlow_redo: 'Redo',
  dataFlow_selectAll: 'Select all',
  dataFlow_amplification: 'Zoom in',
  dataFlow_zoomOut: 'Zoom out',
  dataFlow_down: 'Down',
  dataFlow_up: 'Up',
  dataFlow_selectMultipleNode: 'Multiple selection',
  dataFlow_mouseDrag: 'Drag',
  dataFlow_runningMonitor: 'Monitor',
  dataFlow_select_source_connection: 'Source-side connection',
  dataFlow_select_sync_mode: 'Sync Mode',
  dataFlow_mapping: 'Association',
  dataFlow_select_target_connection: 'Target connection',
  dataFlow_sync_mode: 'Sync Mode',
  dataFlow_sync_type: 'Sync type',
  dataFlow_initial_sync: 'INITIAL SYNC',
  dataFlow_cdc: ' CDC ',
  dataFlow_send_email: 'Send Email',
  dataFlow_stopped: 'task stopped',
  dataFlow_error: 'task error',
  dataFlow_edited: 'task edited',
  dataFlow_started: 'task started',
  dataFlow_sharecdcmode: 'shared incremental read mode',
  dataFlow_streaming: 'streaming read',
  dataFlow_polling: 'polling read',
  dataFlow_drop_target_before_start: 'Whether the target table is deleted before starting the task',
  dataFlow_run_custom_sql: 'Repeat custom SQL',
  dataFlow_stop_on_error: 'Stop when error',
  dataFlow_need_to_create_Index: 'Auto-create index',
  dataFlow_transformModelVersion: 'Transform model version',
  dataFlow_noPrimaryKey: 'Supported no primary key',
  dataFlow_is_schedule: 'Regular job schedul',
  dataFlow_cron_expression: 'Scheduling cron expression',
  dataFlow_data_quality_tag: 'Add data quality tag',
  dataFlow_notification_lag: 'Notification',
  dataFlow_isOpenAutoDDL: 'Auto-DDL operation',
  dataFlow_ddlTip: 'Warn: Automatic DDL does not support JS processor and field processor',
  dataFlow_transformerConcurrency: 'Transformer Concurrency',
  dataFlow_processorConcurrency: 'Processor Concurrency',
  dataFlow_cdcEngineFilter: 'Enable Engine Filtering',
  dataFlow_cdcFetchSize: 'Number CDC batch reads',
  dataFlow_cdcFetchSizeTip: 'Number of data read by system each time.',
  dataFlow_cdcFetchSizeTip1:
    'The smaller the number entered means the higher the CDC real-time performance, but the processing speed is relatively slow.',
  dataFlow_cdcFetchSizeTip2:
    'The more the number entered means the lower the real-time performance, and the overall processing speed will be faster. ',
  dataFlow_send_email_when_replication: 'Resend in a few seconds',
  dataFlow_send_email_at_most_one_replication: 'Cancel sending in more than seconds',
  dataFlow_read_cdc_interval: ' CDC interval',
  dataFlow_cdc_concurrency: ' CDC concurrency',
  dataFlow_cdcShareFilterOnServer: 'Filter CDC shared log',
  dataFlow_read_batch_size: 'Read-amount/time',
  dataFlow_cdcDataProcess: 'CDC data process',
  dataFlow_batch: 'Batch process',
  dataFlow_onebyone: 'Row by row process',
  dataFlow_mission: 'Description',
  dataFlow_yes: 'yes',
  dataFlow_no: 'no',
  dataFlow_selectGrpupFiled: 'Please select a grouping field',
  dataFlow_selectTargetField: 'Please select the target field',
  dataFlow_aggName: 'Sub-process Name',
  dataFlow_nodeName: 'Node Name',
  dataFlow_nodeType: 'Node Type',
  dataFlow_aggFunction: 'Polymerization',
  dataFlow_aggExpression: 'Target',
  dataFlow_filterPredicate: 'Filter Predicate',
  dataFlow_groupByExpression: 'Group Field',
  dataFlow_keepAggreHistoryData: 'Keep aggregation historical data',
  dataFlow_aggregation: 'Aggregation',
  dataFlow_aggrCleanSecond: 'Time to clean up old version data',
  dataFlow_aggrFullSyncSecond: 'Full synchronization time',
  dataFlow_enterFilterTable: 'Please enter the filter table content',
  dataFlow_lagTime: 'incremental lag time setting',
  dataFlow_lagTimeTip:
    'when the incremental task delay is greater than this value, the incremental task delay is considered, and the default value is 0',
  dataFlow_aggregatePrompt: 'Warn：Using the aggregation processor node, the job will be reset when excutes restart',
  dataFlow_nameTip:
    'Script editing of subsequent nodes needs to refer to the name of this sub-process for the specified data processing, so different sub-process names cannot be repeated. ',
  dataFlow_button_submit: 'Submit',
  dataFlow_button_viewConfig: 'Node Config',
  dataFlow_button_viewMonitoring: 'Data Monitoring',
  dataFlow_button_setting: 'Setting',
  dataFlow_button_logs: 'Logs',
  dataFlow_button_preview: 'Preview',
  dataFlow_button_capture: 'Data Trace',
  dataFlow_button_stop_capture: 'Stop Trace',
  dataFlow_button_start: 'Start',
  dataFlow_button_stop: 'Stop',
  dataFlow_button_force_stop: 'Force Stop',
  dataFlow_button_reset: 'Reset',
  dataFlow_button_save: 'Save',
  dataFlow_button_saveDraft: 'Save Draft',
  dataFlow_button_saveing: 'Saving',
  dataFlow_button_reloadSchema: 'Reload Schema',
  dataFlow_button_debug: 'debug test',
  dataFlow_button_quantitative: 'Quantitative',
  dataFlow_button_increment: 'Increment',
  dataFlow_save_before_running: 'Please save the task before running',
  dataFlow_reset_job_msg: 'Reset Job?',
  dataFlow_reset_job_tip: 'Tip',
  dataFlow_stop_job_msg: 'Stop jobs?',
  dataFlow_stop_job_force_stop_msg: 'Force Stop jobs?',
  dataFlow_stop_job_tip: 'Tip',
  dataFlow_file_preview_fields_file_name: 'File Name',
  dataFlow_file_preview_fields_file_size_ondisk: 'File Size(Byte)',
  dataFlow_file_preview_fields_file_modify_time_ondisk: 'File Modify Time',
  dataFlow_file_preview_fields_file_create_time_ondisk: 'File Create Time',
  dataFlow_file_preview_fields_file_path: 'File Path',
  dataFlow_delete_confirm_Title: 'Delete the task? ',
  dataFlow_delete_confirm_Message: 'After deleting task XXX, this task cannot be restored',
  dataFlow_bulk_delete_confirm_Title: 'Delete tasks in batch? ',
  dataFlow_bulk_delete_confirm_Message: 'After deleting tasks in batch, tasks cannot be restored',
  dataFlow_stop_confirm_title: 'Do you want to suspend this task? ',
  dataFlow_stop_confirm_message:
    'After the task xxx is suspended, when the table in the task that has not been fully synchronized is started again, the full synchronization will be performed again',
  dataFlow_bulk_stop_confirm_title: 'Do you want to pause tasks in bulk? ',
  dataFlow_bulk_stop_confirm_message:
    'After the task is paused in batch, when the table in the task that has not been fully synchronized is started again, the full synchronization will be performed again',
  dataFlow_force_stop_confirm_title: 'Do you want to force stop this task? ',
  dataFlow_force_stop_confirm_message:
    'Forcibly stop the task xxx will immediately interrupt the data transmission, force the task to stop quickly, and reset the task',
  dataFlow_bulk_force_stop_confirm_title: 'Do you want to force stop tasks in batches? ',
  dataFlow_bulk_force_stop_confirm_message:
    'The batch forced stop task will immediately interrupt the data transmission to force the task to stop quickly and reset the task',
  dataFlow_initialize_confirm_title: 'Do you want to reset this task? ',
  dataFlow_initialize_confirm_message:
    'Resetting task xxx will clear the task synchronization progress and the task will be executed again',
  dataFlow_bulk_initialize_confirm_title: 'Do you want to reset tasks in bulk? ',
  dataFlow_bulk_initialize_confirm_message:
    'Resetting the task in batches will clear the task synchronization progress, and the task will be executed again',
  dataFlow_modifyEditText: ' If you edited the',
  dataFlow_nodeLayoutProcess: ' node arrangement',
  dataFlow_nodeAttributes: 'node attribute',
  dataFlow_matchingRelationship: 'or matching attribute',
  dataFlow_afterSubmission: 'the job should be',
  dataFlow_runNomally: 'to make sure the job running correctly;',
  dataFlow_editLayerTip: 'otherwise the job will be abnormal, continue？',
  dataFlow_continueEditing: 'Still Edit',
  dataFlow_numberType: 'must be a number and cannot be less than 0',
  dataFlow_setting_distinctWriteType: 'De-rewrite mode',
  dataFlow_setting_intellect: 'Intelligent de-rewrite',
  dataFlow_setting_compel: 'Force de-rewrite',
  dataFlow_setting_intellectTip:
    "Intelligent deduplication: intelligent detection of the target's existing data, deduplication can greatly improve transmission performance",
  dataFlow_setting_compelTip:
    "Forced deduplication: Perform mandatory deduplication detection on the target's existing data, strictly guarantee accuracy but low transmission performance",
  dataFlow_setting_batchTip: 'Batch:  Batch processing and transmission of CDC data with high performance.',
  dataFlow_setting_onebyoneTip: 'Row by row: Processing and transmission of CDC data row by row',
  dataFlow_setting_sync_type_tip:
    'Transmission type can be changed after disable aggregation settings of collection node: ',
  dataFlow_skipError_title: 'Skip Error Settings',
  dataFlow_skipError_skipErrorSettings: 'Data Processing Error Handling',
  dataFlow_skipError_tip:
    'There were data processing errors detected in the job, please make sure these errors have been addressed. If you would like to skip these errors, please check them and click the "Skip errors, continue to start" button.  ',
  dataFlow_skipError_attention: 'WARNING: If you chose to skip the errors, the relevant data may be discarded. ',
  dataFlow_skipError_startJob: 'Skip errors, continue to start',
  dataFlow_skipError_cancel: 'Cancel',
  dataFlow_skipError_taskName: 'Task name',
  dataFlow_skipError_errorTotal: 'Total XX, selected',
  dataFlow_skipError_strip: 'row',
  dataFlow_flowEngineVersion: 'Flow Engine Version',
  dataFlow_flowEngineV1: 'Flow Engine V1',
  dataFlow_jetFlowEngineV2: 'Jet Flow Engine V2',
  connection_dataBaseName: 'Connection name',
  connection_dataBaseHost: 'Database host',
  connection_dataBaseClassify: 'Category',
  connection_dataBaseType: 'Database type',
  connection_dataBaseStatus: 'Status',
  connection_dataBaseSearch: 'Search by connection name',
  connection_loadSchema: 'Reload schema periodically',
  connection_connectionType: 'Connection type',
  connection_connectionInfo: 'Connection info',
  connection_connectionSource: 'Connection source',
  connection_lastUpdateTime: 'Update time',
  connection_operate: 'Operation',
  connection_fuzzyQuery: 'Fuzzy query',
  connection_PreciseQuery: 'Precise query',
  connection_databaseTittle: 'Data connection management',
  connection_createNewDataSource: 'Create New Connection',
  connection_info: 'Database information',
  connection_copyMsg: 'copy successfully',
  connection_testMsg: 'test successfully',
  connection_creator: 'Creator',
  connection_editDataSource: 'Edit Connection',
  connection_reloadOK: 'reloading schema',
  connection_desc:
    'Source Connection includes database, files, RESTful API, custom API etc. You must create at least one data source before you can create migration or replication job. In addition to the standard configuration, you can also configure whether to automatic/manual reload database schema, time zone, and table filter settings. See more details click',
  connection_deteleDatabaseTittle: 'Do you want to delete the connection?',
  connection_deteleDatabaseMsg: 'After deleting connection xxx, this connection cannot be restored. ',
  connection_checkMsg: 'This data source is used by transmission job or API, cannot be deleted',
  connection_copyFailedMsg:
    'Copy failed, reason:  The setting item "Connections - create  duplicate source" need to be set to "false"',
  connection_change: 'Change',
  connection_testConnection: 'Test connection ',
  connection_status_all: 'All',
  connection_status_testing: 'testing',
  connection_status_invalid: 'invalid',
  connection_status_ready: 'ready',
  connection_preview_reloadName: 'Reload schema',
  connection_type_source: 'Source',
  connection_type_target: 'Target',
  connection_type_source_and_target: 'Source&Target',
  connection_cannot_delete_remind:
    'Connection is currently being used by one or more jobs and apis. Please delete the jobs or apis then try again.',
  connection_dfs_cannot_delete_remind:
    'Connection is currently being used by one or more jobs. Please delete the jobs then try again.',
  editor_nodeSettings: 'Node Settings',
  editor_choose: 'Select',
  editor_newTxt: 'New',
  editor_noResult: 'No search results found',
  editor_cell_validate_empty_name: 'Name is required.',
  editor_cell_validate_empty_message_field_name_and_type: 'Message body field name and type are required',
  editor_cell_validate_none_setting: 'Settings cannot be none.',
  editor_cell_validate_none_stage: 'Must have one stage.',
  editor_cell_validate_none_data_node: 'At least 2 data node in graph',
  editor_cell_validate_none_link_node: 'At least 1 link in graph',
  editor_cell_validate_start_with_data_node: 'Must start with a data node',
  editor_cell_validate_acyclic: 'The graph cannot have cyclic',
  editor_cell_data_node_hiveText: 'Hive Node',
  editor_cell_data_node_hbaseText: 'HBase Node',
  editor_cell_data_node_kuduText: 'KUDU Node',
  editor_cell_data_node_hbase_check: 'HBase only supports INITIAL SYNC tasks',
  editor_cell_data_node_greentplum_check: 'Greentplum as a source only supports full tasks',
  editor_cell_data_node_kafkaText: 'Kafka Node',
  editor_cell_data_node_kafkaName_isNull: 'kafka cannot be empty',
  editor_cell_data_node_mqTableType: 'New table type',
  editor_cell_data_node_mqTableTypeTip: 'Please select the table type topic or queue',
  editor_cell_data_node_tcpTip:
    'Important: TCP/IP data sources output JSON packets by default without additional packet conversion processing nodes ',
  editor_cell_data_node_database_name: 'Database',
  editor_cell_data_node_database_tip: 'Any Database',
  editor_cell_data_node_database_defaultText: 'Database',
  editor_cell_data_node_database_none_database: 'Database is required.',
  editor_cell_data_node_database_tableSuffix: 'Please enter table suffix',
  editor_cell_data_node_database_tablePrefix: 'Please enter table prefix',
  editor_cell_data_node_database_form_placeholder: 'Please select database',
  editor_cell_data_node_database_form_label: 'Database',
  editor_cell_data_node_database_remove: 'Remove',
  editor_cell_data_node_database_Undo: 'Undo',
  editor_cell_data_node_database_bulkRemoval: 'Bulk removal',
  editor_cell_data_node_database_bulkRevocation: 'Bulk revocation',
  editor_cell_data_node_database_queueCopied: 'Included Tables',
  editor_cell_data_node_database_tableRemoved: 'Excluded Tables',
  editor_cell_data_node_database_enterName: 'Please enter the name / field name to search',
  editor_cell_data_node_database_source: 'Data source',
  editor_cell_data_node_database_type: 'Database Type',
  editor_cell_data_node_database_databaseName: 'Database Name',
  editor_cell_data_node_database_account: 'Database Account',
  editor_cell_data_node_database_attributionAccount: 'Database Owner',
  editor_cell_data_node_database_includeTable: 'Include Table',
  editor_cell_data_node_collection_name: 'Collection',
  editor_cell_data_node_collection_tip: 'MongoDB Collection',
  editor_cell_data_node_collection_defaultText: 'Collection',
  editor_cell_data_node_collection_none_database: 'Database is required.',
  editor_cell_data_node_collection_none_collection: 'Collection is required.',
  editor_cell_data_node_collection_none_pk: 'Primary key is required.',
  editor_cell_data_node_collection_form_database_label: 'Database',
  editor_cell_data_node_collection_form_database_placeholder: 'Please select MongoDB database',
  editor_cell_data_node_collection_form_collection_label: 'Collection',
  editor_cell_data_node_collection_form_collection_placeholder: 'Please select collection',
  editor_cell_data_node_collection_form_pk_label: 'Primary Key',
  editor_cell_data_node_collection_form_pk_placeholder: 'Please enter primary key',
  editor_cell_data_node_collection_form_fieldFilterType_keepAllFields: 'Keep all fields',
  editor_cell_data_node_collection_form_fieldFilterType_retainedField: 'Retained field',
  editor_cell_data_node_collection_form_fieldFilterType_deleteField: 'Delete field',
  editor_cell_data_node_collection_form_fieldFilter_placeholderKeep: ' Select the fields to keep',
  editor_cell_data_node_collection_form_fieldFilter_placeholderDelete: ' Select the fields to delete',
  editor_cell_data_node_collection_form_fieldFilterTip_label: 'Field filter',
  editor_cell_data_node_collection_form_fieldFilterTip_keepAllFields:
    'Keep all fields: Keep all fields of this collection.',
  editor_cell_data_node_collection_form_fieldFilterTip_retainedField:
    'Retained field: the selected fields will be retained and all other fields will be discarded.',
  editor_cell_data_node_collection_form_fieldFilterTip_deleteField:
    'Delete field: the selected fields will be deleted and all other fields will be retained.',
  editor_cell_data_node_collection_form_dropTable_label: 'Existing data',
  editor_cell_data_node_collection_form_dropTable_placeholder: '',
  editor_cell_data_node_collection_form_dropTable_keep: 'Keep existing data',
  editor_cell_data_node_collection_form_dropTable_remove: 'Remove exists data at before sync',
  editor_cell_data_node_collection_form_initialSyncOrder_keep: 'Enable custom initial sync order',
  editor_cell_data_node_collection_form_initialSyncOrder_open: 'Open',
  editor_cell_data_node_collection_form_initialSyncOrder_close: 'Close',
  editor_cell_data_node_collection_form_filter_label: 'Filter conditions',
  editor_cell_data_node_collection_form_filter_invalidJSON: 'Invalid JSON',
  editor_cell_data_node_collection_form_filter_fiflterSetting: 'Filter settings',
  editor_cell_data_node_collection_form_filter_fieldFilter: 'Visual Mode',
  editor_cell_data_node_collection_form_filter_openFiflter: 'Enable filtering',
  editor_cell_data_node_collection_form_filter_closeFiflter: 'Close filtering',
  editor_cell_data_node_collection_form_filter_sqlFilter: 'SQL Filter',
  editor_cell_data_node_collection_form_filter_mqlFilter: 'MQL Filter',
  editor_cell_data_node_collection_form_filter_saveFields: 'Reserved fields',
  editor_cell_data_node_collection_form_filter_allField: 'All fields',
  editor_cell_data_node_collection_form_filter_deleteField: 'Delete field',
  editor_cell_data_node_collection_form_filter_rowLimit: 'Row limit',
  editor_cell_data_node_collection_form_filter_allRows: 'All rows',
  editor_cell_data_node_collection_form_filter_oneThousandRows: '1000 rows',
  editor_cell_data_node_collection_form_filter_tenThousandRows: '10000 rows',
  editor_cell_data_node_collection_form_filter_placeholder_savefield: 'Please select a reserved field',
  editor_cell_data_node_collection_form_filter_placeholder_delField: 'Please select',
  editor_cell_data_node_collection_form_filter_placeholder_selectField: 'Please select a field',
  editor_cell_data_node_collection_form_filter_placeholder_Operator: 'Operator',
  editor_cell_data_node_collection_form_filter_placeholder_enterContent: 'Please enter the content of the conditions',
  editor_cell_data_node_collection_form_filter_placeholder_placeholder:
    'Filter Condition (Mongo Query Filter Document)',
  editor_cell_data_node_collection_form_aggregation_aggregationText: 'Aggregation Settings',
  editor_cell_data_node_collection_form_aggregation_disabled: 'Disabled',
  editor_cell_data_node_collection_form_aggregation_enabled: 'Enabled',
  editor_cell_data_node_collection_form_aggregation_preview: 'Preview',
  editor_cell_data_node_collection_form_aggregation_previewSampleData: 'Preview of sample data',
  editor_cell_data_node_collection_form_aggregation_addTextTip: 'No preview sample data',
  editor_cell_data_node_collection_form_aggregation_addTextTip1:
    'Please enter the MongoDB aggregation code, and then click "Preview" to preview the sample data here',
  editor_cell_data_node_collection_form_aggregation_filterAggreTip:
    'Aggregation settings and filtering settings cannot be enabled at same time.',
  editor_cell_data_node_collection_form_aggregation_seetingAggreTip: 'This function only available under initial job',
  editor_cell_data_node_table_name: 'Table',
  editor_cell_data_node_table_tip: 'RDBMS Table',
  editor_cell_data_node_table_defaultText: 'Table',
  editor_cell_data_node_table_none_database: 'Database is required.',
  editor_cell_data_node_table_none_table: 'Table is required.',
  editor_cell_data_node_table_none_pk: 'Primary key is required.',
  editor_cell_data_node_table_form_database_label: 'Database',
  editor_cell_data_node_table_form_database_placeholder: 'Please select RDBMS database',
  editor_cell_data_node_table_form_table_label: 'Table',
  editor_cell_data_node_table_form_table_labelTips: '（If it is empty, create a new table）',
  editor_cell_data_node_table_form_table_placeholder: 'Please select table,Case sensitive',
  editor_cell_data_node_table_form_custom_sql_label: 'Custom SQL',
  editor_cell_data_node_table_form_custom_sql_placeholder: 'Please input you custom sql',
  editor_cell_data_node_table_form_custom_sql_mplaceholder: 'Please input you custom mql',
  editor_cell_data_node_table_form_initial_offset_label: 'Custom SQL Offset',
  editor_cell_data_node_table_form_initial_offset_placeholder: 'Please input you custom sql offset',
  editor_cell_data_node_table_form_maximum_transaction_label: 'Max Transaction Length',
  editor_cell_data_node_table_form_maximum_transaction_tip:
    'Time in hours to wait for commit for a transaction. Enter the longest period of time that you expect a transaction to require.Default is 12 hours',
  editor_cell_data_node_file_name: 'File',
  editor_cell_data_node_file_tip: 'File node',
  editor_cell_data_node_file_none_fileName: 'The file name cannot be empty',
  editor_cell_data_node_file_configurationFile: 'Configuration File',
  editor_cell_data_node_file_chooseFileName: 'Please select a file name',
  editor_cell_data_node_gridfs_name: 'GridFS',
  editor_cell_data_node_gridfs_tip: 'GridFS node',
  editor_cell_data_node_gridfs_chooseGridFsName: 'Please select GridFS',
  editor_cell_data_node_gridfs_none_collection: 'Collection is required.',
  editor_cell_data_node_gridfs_none_pk: 'Primary key is required.',
  editor_cell_data_node_gridfs_gridFs_isNull: 'GridFS cannot be empty',
  editor_cell_data_node_dummy_name: 'Dummy',
  editor_cell_data_node_dummy_tip: 'Dummy node',
  editor_cell_data_node_dummy_chooseDummyName: 'Please select Dummy',
  editor_cell_data_node_dummy_none_collection: 'Collection is required.',
  editor_cell_data_node_dummy_none_pk: 'Primary key is required.',
  editor_cell_data_node_dummy_dummy_isNull: 'Dummy cannot be empty',
  editor_cell_data_node_redis_name: 'Redis',
  editor_cell_data_node_redis_tip: 'Redis Node',
  editor_cell_data_node_redis_chooseRedisName: 'Please select Redis',
  editor_cell_data_node_redis_Redis_isNull: 'Redis cannot be empty',
  editor_cell_data_node_redis_prefixKey: 'Cache key prefix',
  editor_cell_data_node_redis_prefixKey_placeholder: 'Please enter the cache key prefix',
  editor_cell_data_node_redis_cacheKey: 'Select cache key',
  editor_cell_data_node_redis_cacheKey_placeholder: 'Select source table field as cache key',
  editor_cell_data_node_api_name: 'API',
  editor_cell_data_node_api_tip: 'api node',
  editor_cell_data_node_api_chooseApiName: 'Please select API',
  editor_cell_data_node_api_none_collection: 'Collection is required.',
  editor_cell_data_node_api_none_database: 'Database is required.',
  editor_cell_data_node_api_none_pk: 'Primary key is required.',
  editor_cell_data_node_api_api_isNull: 'API cannot be empty',
  editor_cell_data_node_api_dataApiName: 'Data publishing API name',
  editor_cell_data_node_api_description: 'Description',
  editor_cell_data_node_api_method: 'Method',
  editor_cell_data_node_api_fieldSettings: 'Field Settings',
  editor_cell_data_node_api_table_field: 'field',
  editor_cell_data_node_api_table_type: 'Type',
  editor_cell_data_node_api_table_setting: 'Settings',
  editor_cell_data_node_api_publishName: 'Publish API',
  editor_cell_data_node_api_enterPublishApiName: 'Please enter the name of the data publishing API',
  editor_cell_data_node_api_enterNewlyReleasedApi: 'Please enter a description of the newly released API',
  editor_cell_data_node_api_enterEndUrl: 'Please enter the URL end path name',
  editor_cell_data_node_api_required: 'Required',
  editor_cell_data_node_api_availableQueries: 'Query',
  editor_cell_data_node_api_publishApi_path: 'API path is not empty',
  editor_cell_data_node_api_variable_name:
    'Can only contain letters, numbers, underscores and dollar signs, and numbers cannot start',
  editor_cell_data_node_es_name: 'ES',
  editor_cell_data_node_es_tip: 'Elastic search node',
  editor_cell_data_node_es_configurationES: 'Configure Elastic search',
  editor_cell_data_node_es_chunkSize: 'Number of shards',
  editor_cell_data_node_es_index: 'Index',
  editor_cell_data_node_es_chooseChunkSize: 'Please enter the number of shards',
  editor_cell_data_node_es_chooseIndex: 'Please enter the index',
  editor_cell_data_node_es_chooseESName: 'Please select Elastic search',
  editor_cell_data_node_es_es_isNull: 'Elastic search cannot be empty',
  editor_cell_data_node_custom_tip: 'Custom node',
  editor_cell_data_node_custom_name: 'Custom',
  editor_cell_data_node_custom_none_fileName: 'Custom cannot be empty',
  editor_cell_data_node_custom_chooseCustomName: 'Please select Custom',
  editor_cell_data_node_memCache_tip: 'Memery Cache node',
  editor_cell_data_node_memCache_name: 'Mem Cache',
  editor_cell_data_node_memCache_applicationCode: 'Application code',
  editor_cell_data_node_memCache_form_cacheName_label: 'Cache name',
  editor_cell_data_node_memCache_form_cacheName_placeholder: 'Please enter cache name.',
  editor_cell_data_node_memCache_form_cacheName_none: 'Cache name is required.',
  editor_cell_data_node_memCache_form_cacheKeys_label: 'Cache key',
  editor_cell_data_node_memCache_form_cacheKeys_placeholder: 'Please select cache key.',
  editor_cell_data_node_memCache_form_cacheKeys_none: 'Cache key is required.',
  editor_cell_data_node_memCache_form_maxSize_label: 'Max capacity',
  editor_cell_data_node_memCache_form_maxSize_placeholder: 'Please enter maximum capacity of the cache.',
  editor_cell_data_node_memCache_form_maxSize_none: 'Max capacity is required.',
  editor_cell_data_node_memCache_form_maxSize_options_unlimited: 'Unlimit',
  editor_cell_data_node_memCache_form_maxSize_options_custom: 'Custom',
  editor_cell_data_node_memCache_form_maxRows_label: 'Max records',
  editor_cell_data_node_memCache_form_maxRows_placeholder: 'Please enter maximum records of the cache.',
  editor_cell_data_node_memCache_form_maxRows_none: 'Max records is required.',
  editor_cell_data_node_memCache_form_maxRows_unit: 'pcs',
  editor_cell_data_node_memCache_form_maxRows_options_unlimited: 'Unlimit',
  editor_cell_data_node_memCache_form_maxRows_options_custom: 'Custom',
  editor_cell_data_node_logminer_add: 'Add',
  editor_cell_data_node_logminer_day: 'day',
  editor_cell_data_node_logminer_name: 'Log mining',
  editor_cell_data_node_logminer_tip: 'Log Miner',
  editor_cell_data_node_logminer_miningLogTime: 'Mining log time',
  editor_cell_data_node_logminer_logSaveTime: 'Log save time',
  editor_cell_data_node_logminer_logSourceSetting: 'Log source setting',
  editor_cell_data_node_logminer_currentTimeZone: 'Current Time Zone',
  editor_cell_data_node_logminer_databaseTimeZone: 'Database Time Zone',
  editor_cell_data_node_logminer_allTables: 'All tables',
  editor_cell_data_node_logminer_reservationTable: 'Reservation Table',
  editor_cell_data_node_logminer_exclusionTable: 'Exclusion Table',
  editor_cell_data_node_logminer_nodeFunDes: 'Node function description',
  editor_cell_data_node_logminer_function: 'Function',
  editor_cell_data_node_logminer_functionContent:
    'This node is used to collect logs from specified source databases to save to target MongoDB database share log data, in order to avoid the action of repeatedly starting the logging process to greatly alleviate theoccupation and waste of source database resources. ',
  editor_cell_data_node_logminer_connectionTarget: 'Connection Target',
  editor_cell_data_node_logminer_connectionText: 'COLLECTION nodes',
  editor_cell_data_node_logminer_tableFilter_placeSletSource: 'Please select the source of the collected data',
  editor_cell_data_node_logminer_tableFilter_tableFilter: 'Please select the table to keep',
  editor_cell_data_node_logminer_tableFilter_placeholderDelete: 'Please select the table to exclude',
  editor_cell_data_node_logminer_validate_name: 'Node name cannot be empty',
  editor_cell_data_node_logminer_validate_source: 'Data source cannot be empty',
  editor_cell_data_node_logminer_validate_table: 'Data table cannot be empty',
  editor_cell_data_node_logminer_validate_sameConnection: 'Cannot choose the same connection',
  editor_cell_processor_customProcessor_name: 'Custom processor',
  editor_cell_processor_aggregate_name: 'Aggregate',
  editor_cell_processor_aggregate_tip: 'Aggregate processor',
  editor_cell_processor_aggregate_defaultText: 'Aggregate',
  editor_cell_processor_aggregate_none_function: 'Aggregate function is required.',
  editor_cell_processor_aggregate_none_group: 'Group expression is required.',
  editor_cell_processor_aggregate_none_name: 'Sub-process name is required',
  editor_cell_processor_aggregate_none_aggregation_expression: 'Target field is required.',
  editor_cell_processor_aggregate_new_aggregate: 'Add new aggregate',
  editor_cell_processor_aggregate_none_stage: 'Must have one aggregate',
  editor_cell_processor_aggregate_returnExample: 'Return example',
  editor_cell_processor_aggregate_school_name: 'school_name: "Dorset"',
  editor_cell_processor_aggregate_idComment:
    '// "students_sum" is the Sub-process name, and the names between sub-processes cannot be repeated',
  editor_cell_processor_aggregate_countComment:
    '// COUNT is the Polymerization function and 132 is the value; if the function is MAX, it will show MAX here',
  editor_cell_processor_aggregate_school_nameComment: '// Grouping summary field names, no display if dont filling out',
  editor_cell_processor_aggregate_aggregateSizeLabel: 'Number of cached aggregation result',
  editor_cell_processor_aggregate_aggregateSizeTips:
    'Put in the range of cached aggregation result, the excess data will be stored in target database.',
  editor_cell_processor_aggregate_allAggregateSize: 'All data write in cache',
  editor_cell_processor_aggregate_customAggregateSize: 'Custom the cache range',
  editor_cell_processor_aggregate_cleanSecondTimeLess3600:
    'The time to clean up old version data cannot be less than 3600',
  editor_cell_processor_aggregate_fullSyncSecondTimeLess3600: 'Full sync time cannot be less than 3600',
  editor_cell_processor_field_name: 'Field',
  editor_cell_processor_field_tip: 'Field processor',
  editor_cell_processor_field_defaultText: 'Field processor',
  editor_cell_processor_field_form_name_label: 'Node Name',
  editor_cell_processor_field_form_name_placeholder: 'Please input you node name',
  editor_cell_processor_field_form_description_label: 'Description',
  editor_cell_processor_field_form_description_placeholder: 'Please input you node description',
  editor_cell_processor_field_form_originalName: 'Original field name: ',
  editor_cell_processor_field_form_originalType: 'Original type: ',
  editor_cell_processor_field_form_fieldDesc: 'Comment: ',
  editor_cell_processor_field_form_errorUndefined:
    'The model of the source node has changed, so that the field processor does not work, please click the UPDATE MODEL button in the configuration panel of the upper node to handle this issue',
  editor_cell_processor_field_form_errorOperationSaveTip: 'The field processor node has conflict to be handled',
  editor_cell_processor_field_form_errorOperationTipBefore:
    'Conflict between field processing operation and source model',
  editor_cell_processor_field_form_errorOperationTipAfter: ' click to handle',
  editor_cell_processor_field_form_errorOperationDrop:
    'The following processing operation is detected to conflict with the source model. Please select the operation mode for the following fields. Drop / Keep: Drop / Keep the process of the field',
  editor_cell_processor_field_form_errorOperationDesc:
    'Click "Drop all" to select "Drop" operation for all fields; click "Bulk keep" to select "Keep" operation for all fields, the field without "Keep" operation will still be selected "Drop"',
  editor_cell_processor_field_form_errorOperationDelBtn: 'Drop all',
  editor_cell_processor_field_form_errorOperationKeepBtn: 'Bulk keep',
  editor_cell_processor_field_form_toUpperCase: 'Upper',
  editor_cell_processor_field_form_toLowerCase: 'Lower',
  editor_cell_processor_field_form_delete: 'Delete',
  editor_cell_processor_field_form_save: 'Save',
  editor_cell_processor_field_form_originalField: 'Original field (type) ',
  editor_cell_processor_field_form_process: 'Process action',
  editor_cell_processor_field_form_result: 'Result',
  editor_cell_processor_field_form_keep: 'Keep',
  editor_cell_processor_field_form_operation: 'Operation',
  editor_cell_processor_field_form_fieldName: 'Field name',
  editor_cell_processor_field_form_fieldType: 'Field type',
  editor_cell_processor_field_form_addField: 'Add Field',
  editor_cell_processor_field_form_addEmbedField: 'Add Embed Field',
  editor_cell_processor_field_form_scriptDialogTitle: 'Set Script',
  editor_cell_processor_field_form_expression: 'Please enter an expression',
  editor_cell_processor_field_form_example: 'Example',
  editor_cell_processor_field_form_exampleRow1:
    'var result = "a" + "b"  // String concatenation, the result of result is "ab"',
  editor_cell_processor_field_form_exampleRow2: 'var result = 1 + 2 // Digital calculation, the result of result is 3',
  editor_cell_processor_field_form_exampleRow3:
    'var result = fn("1") // Call function, the result is the return value of the fn function.',
  editor_cell_processor_field_form_exampleRow4:
    'var result = record.isTrue ? true : false // Ternary expression, The value of result is true or false based on the result of the judgment expression (record.isTrue)',
  editor_cell_processor_script_name: 'JavaScript',
  editor_cell_processor_script_tip: 'Script processor',
  editor_cell_processor_script_defaultText: 'Script processor',
  editor_cell_processor_script_none_script_type: 'Script type is required.',
  editor_cell_processor_script_none_script: 'Script is required.',
  editor_cell_processor_script_debug_button_label: 'Debug Script',
  editor_cell_processor_script_warning_for_not_save:
    'The current task has not been saved, unable to connect the test server, please save and try again',
  editor_cell_processor_script_connect_server_fail: 'Failed to connect to server',
  editor_cell_processor_script_debug_top_header: 'Debug Script',
  editor_cell_processor_script_debug_bottom_header: 'Debug Details',
  editor_cell_processor_script_debug_detail_parameter: 'Input',
  editor_cell_processor_script_debug_detail_return: 'Output',
  editor_cell_processor_script_debug_order: 'Order',
  editor_cell_processor_script_debug_status: 'Status',
  editor_cell_processor_script_debug_status_error: 'Error',
  editor_cell_processor_script_debug_status_success: 'Success',
  editor_cell_processor_script_debug_time: 'Time',
  editor_cell_processor_script_debug_log: 'Log',
  editor_cell_processor_script_form_name_label: 'Node Name',
  editor_cell_processor_script_form_name_placeholder: 'Please enter the node name',
  editor_cell_processor_script_form_type_label: 'Script Type',
  editor_cell_processor_script_form_type_placeholder: 'Please select script type',
  editor_cell_processor_script_form_script_label: 'Script',
  editor_cell_processor_script_form_script_placeholder: 'Please input script',
  editor_cell_processor_dataFilter_name: 'Row Filter',
  editor_cell_processor_dataFilter_tip: 'Row Data Filter',
  editor_cell_processor_dataFilter_validate_none_expression: 'Conditional expression cannot be empty',
  editor_cell_processor_dataFilter_validate_none_action: 'The execution action cannot be empty',
  editor_cell_processor_dataFilter_form_name_label: 'Node Name',
  editor_cell_processor_dataFilter_form_name_placeholder: 'Please enter the node name',
  editor_cell_processor_dataFilter_form_expression_label: 'Conditional expression',
  editor_cell_processor_dataFilter_form_expression_placeholder: 'Please enter an expression',
  editor_cell_processor_dataFilter_form_expression_labelTip:
    'Expressions can use comparison and calculation operators in JavaScript',
  editor_cell_processor_dataFilter_form_action_label: 'Execute action',
  editor_cell_processor_dataFilter_form_action_discard: 'Discard',
  editor_cell_processor_dataFilter_form_action_retain: 'Retain',
  editor_cell_processor_dataFilter_form_expressionExample_label: 'Example expression',
  editor_cell_processor_dataFilter_form_expressionExample_labelTip:
    'Expressions can use comparison and calculation operators in JavaScript',
  editor_cell_processor_dataFilter_form_expressionExample_tip:
    'Select men over 50 years old or people over 30 years old with income below 10,000, the expression is as follows:',
  editor_cell_processor_dataFilter_form_symbol_label: 'Supported symbols',
  editor_cell_processor_dataFilter_form_symbol_gtLt: 'Greater than, less than',
  editor_cell_processor_dataFilter_form_symbol_geLe: 'Greater than and equal to, less than and equal to',
  editor_cell_processor_dataFilter_form_symbol_eq: 'equal to',
  editor_cell_processor_dataFilter_form_symbol_not: 'NO',
  editor_cell_processor_dataFilter_form_symbol_and: 'And',
  editor_cell_processor_dataFilter_form_symbol_or: 'Or',
  editor_cell_processor_dataFilter_form_symbol_regexp: 'Regular expression',
  editor_cell_processor_dataFilter_form_symbol_group: 'Conditional grouping',
  editor_cell_processor_jointCache_name: 'Cache Lookup',
  editor_cell_processor_jointCache_tip: 'Cache Lookup Node',
  editor_cell_processor_jointCache_form_name_label: 'Node Name',
  editor_cell_processor_jointCache_form_name_placeholder: 'Please input node name.',
  editor_cell_processor_jointCache_form_name_none: 'Node name is required.',
  editor_cell_processor_jointCache_form_cacheId_label: 'Cache lookup node',
  editor_cell_processor_jointCache_form_cacheId_placeholder: 'Choose MEMORY CACHE node in this job.',
  editor_cell_processor_jointCache_form_cacheId_none: 'Choose MEMORY CACHE node in this job.',
  editor_cell_processor_jointCache_form_joinSettings_label: 'Lookup joint setting',
  editor_cell_processor_jointCache_form_joinSettings_cacheKey: 'Memory cache primary key',
  editor_cell_processor_jointCache_form_joinSettings_sourceKey_label: 'Source table joint field',
  editor_cell_processor_jointCache_form_joinSettings_sourceKey_placeholder: 'Choose cache joint field.',
  editor_cell_processor_jointCache_form_joinSettings_none: 'Choose cache joint field.',
  editor_cell_processor_jointCache_form_joinKey_label: 'Target path',
  editor_cell_processor_jointCache_form_joinKey_placeholder: 'Enter or choose target path field.',
  editor_cell_processor_transform_name: 'Transform',
  editor_cell_processor_transform_tip: 'Transform Node',
  editor_cell_link_none_join_type: 'JoinType is required',
  editor_cell_link_none_join_key: 'JoinKeys is required',
  editor_cell_link_none_join_path: 'JoinPath is required',
  editor_cell_link_none_array_unique_key: 'Array unique key is required',
  editor_cell_link_repeatId_title: 'Field _id conflict',
  editor_cell_link_repeatId_message:
    '"_id" field exists in target model, and system will remove the duplicated field “_id”, if you wanna keep it, please use the field processor to rename the "_id" field before continue.',
  editor_cell_link_pcb_Label: 'protocol type',
  editor_cell_link_pcb_Placeholder: 'please select a protocol type',
  editor_cell_link_pcb_Fieldsselected: 'field to be selected',
  editor_cell_link_pcb_Selectedfield: 'selected field',
  editor_cell_link_pcb_Moveup: 'move up',
  editor_cell_link_pcb_Movedown: 'move down',
  editor_cell_link_pcb_Notmoveuptip: 'there is no room to move up',
  editor_cell_link_pcb_Notmovedowntip: 'there is no room to move down',
  editor_cell_link_pcb_Onlyonepiece: 'only one piece of data can be selected to move up and down',
  editor_cell_link_form_label_label: 'Label',
  editor_cell_link_form_label_placeholder: 'Please input label',
  editor_cell_link_form_joinMethod_label: 'Mismatched data insert model',
  editor_cell_link_form_joinMethod_placeholder: 'Please select the data insertion method',
  editor_cell_link_form_joinType_label: 'Data write model',
  editor_cell_link_form_joinType_placeholder: 'Please select Data Write model',
  editor_cell_link_form_joinPath_label: 'Target path',
  editor_cell_link_form_joinPath_placeholder: 'Please input target path',
  editor_cell_link_form_joinPath_copyLabel: 'Copy target path',
  editor_cell_link_form_joinKeys_label: 'Association condition',
  editor_cell_link_form_joinKeys_tips:
    'Reminder: The current association condition setting will cause the data deletion operation to fail to be synchronized. Please add an intermediate mongodb node to complete the synchronization setting.',
  editor_cell_link_form_joinKeys_sourceField: 'Source Field',
  editor_cell_link_form_joinKeys_targetField: 'Target Field',
  editor_cell_link_form_arrayUniqueKey_label: 'Embedded array match key',
  editor_cell_link_form_arrayUniqueKey_placeholder: 'Please enter in embed array match key ',
  editor_cell_link_methodList_false: 'Discard',
  editor_cell_link_methodList_true: 'write',
  editor_cell_link_writeMode_append: 'Append into Target',
  editor_cell_link_writeMode_upsert: 'Match and Merge or Insert New',
  editor_cell_link_writeMode_update: 'Match and Merge',
  editor_cell_link_writeMode_merge_embed: 'Match then Embed as Array in target',
  editor_cell_link_existingSchema_label: 'When schema and/or data already exist in target database',
  editor_cell_link_existingSchema_keepSchema: 'Retain schema and data in target database',
  editor_cell_link_existingSchema_keepExistedData: 'Retain schema, but remove data in target database',
  editor_cell_link_existingSchema_removeSchema: 'Drop schema and data in target database',
  editor_cell_link_migrationSetting: 'Tables to be copied selection',
  editor_cell_link_dataProcessing: 'Existing data processing',
  editor_cell_link_prefixAndSuffix: 'Add prefix and suffix',
  editor_cell_link_keepExistingData: 'Keep existing data',
  editor_cell_link_deleteExistingData: 'Delete existing data before running',
  editor_cell_link_reduction: 'Reduction',
  editor_cell_link_mappingRelations: 'Mapping Relations',
  editor_cell_link_addPrefix: 'Add prefix',
  editor_cell_link_addSuffix: 'Add suffix',
  editor_cell_link_prefixPlaceholder: 'Please enter the prefix',
  editor_cell_link_suffixPlaceholder: 'Please enter the suffix',
  editor_cell_link_batchRename: 'Batch rename settings',
  editor_cell_link_tableNameExample: 'Table name example',
  editor_cell_link_copySourceDatabase: 'Source database schema to be copied',
  editor_cell_link_tableTip: 'Table does not support foreign key copy',
  editor_cell_link_viewTip:
    'Copy view does not support table rename, if check this box rename function will be disabled',
  editor_cell_link_formTip: 'The function of copy view, function, procedure only support MySQL to MySQL',
  editor_cell_link_chooseATableTip: 'At least select one object to be copied',
  editor_ui_sidebar_setting: 'Data Flow Settings',
  editor_ui_sidebar_node_setting: 'Node Settings',
  editor_ui_sidebar_statistics: 'Statistics',
  editor_ui_sidebar_logs: 'Running Logs',
  editor_ui_sidebar_milestone: 'Task Milestone',
  editor_ui_sidebar_progress: 'Task Progress',
  editor_ui_sidebar_capture: 'Capture',
  editor_ui_sidebar_style: 'Style',
  editor_ui_sidebar_config: 'Config',
  editor_ui_sidebar_data_nodes: 'Data Nodes',
  editor_ui_sidebar_processor: 'Processor',
  editor_ui_sidebar_tableSelector: 'Fast Selection',
  editor_ui_toolbar_undo_tip: 'Undo',
  editor_ui_toolbar_redo_tip: 'Redo',
  editor_ui_toolbar_clear_paper_tip: 'Clear Paper',
  editor_ui_toolbar_export_svg_tip: 'Open as SVG in a pop-up',
  editor_ui_toolbar_export_png_tip: 'Open as SVG in a pop-up',
  editor_ui_toolbar_print_tip: 'Open a Print Dialog',
  editor_ui_toolbar_to_back_tip: 'Send Object to Back',
  editor_ui_toolbar_to_front_tip: 'Bring Object to Front',
  editor_ui_toolbar_layout_tip: 'Auto-layout Graph',
  editor_ui_toolbar_zoom_to_fit_tip: 'Zoom To Fit',
  editor_ui_toolbar_zoom_out_tip: 'Zoom Out',
  editor_ui_toolbar_zoom_in_tip: 'Zoom In',
  editor_ui_toolbar_grid_size_tip: 'Change Grid Size',
  editor_ui_toolbar_fullscreen_tip: 'Toggle Fullscreen Mode',
  editor_ui_nodeLoadSchemaDiaLog:
    'If the data source is updated, this operation will update the model of this node. Do you want to continue?',
  editor_ui_allNodeLoadSchemaDiaLog:
    'If the data source is updated, this operation will update the model of each node. Do you want to continue?',
  editor_preview_stage: 'Stage',
  editor_preview_table: 'Table',
  editor_fileFormBuilder_fileSource: 'Data source',
  editor_fileFormBuilder_fileSourcePlaceholder: 'Enter data source',
  editor_fileFormBuilder_includeFilename: 'Enter regular expression for include file',
  editor_fileFormBuilder_excludeFilename: 'Enter regular expression for discard file',
  editor_fileFormBuilder_fileSchema: 'Set model name',
  editor_fileFormBuilder_sperate: 'Model field separator',
  editor_fileFormBuilder_jsonType: 'Json type',
  editor_fileFormBuilder_excelPassword: 'Excel password',
  editor_fileFormBuilder_excelValue: 'Excel data settings',
  editor_fileFormBuilder_header_mapping_value: 'Cell content',
  editor_fileFormBuilder_header_mapping_index: 'Cell coordinate name',
  editor_fileFormBuilder_header_mapping: ' Field name getting',
  editor_fileFormBuilder_sheet_range: 'Range of sheets',
  editor_fileFormBuilder_sheet_start: 'Enter the number of starting sheet',
  editor_fileFormBuilder_sheet_end: 'Enter the number of ending sheet',
  editor_fileFormBuilder_excel_header_type: 'Field mapping range',
  editor_fileFormBuilder_excel_header_coordinate: 'According to the table coordinate',
  editor_fileFormBuilder_excel_header_range: 'Custom range',
  editor_fileFormBuilder_guideDocPrefix: 'Please select the ',
  editor_fileFormBuilder_guideDoc:
    'file under the data source of the FILE type. The system will load up the model and transfer it to the target collection. If the structures of selected files are different, the system will combine them into one model. For more information, please click the',
  editor_fileFormBuilder_header_type_custom_label: 'Multiple fields separated by commas',
  editor_fileFormBuilder_header_type_required: 'Header type is required',
  editor_fileFormBuilder_excel_header_start: 'Enter the starting coordinate',
  editor_fileFormBuilder_excel_header_end: 'Enter the ending coordinate',
  editor_fileFormBuilder_excel_value_type: 'Range of rows',
  editor_fileFormBuilder_excel_value_start: 'Enter the starting abscissa',
  editor_fileFormBuilder_excel_value_end: 'Enter the ending abscissa',
  editor_fileFormBuilder_excel_number: 'Sheet range should be number',
  editor_fileFormBuilder_excel_cell_point:
    'Enter the coordinates of Excel, "row 1 and column 1" can be entered as "A1"',
  editor_fileFormBuilder_excel_cell_tip: 'The field range must be uppercase letter + number',
  editor_fileFormBuilder_excel_value_end_gt_start:
    'The number of ending page must be greater than or equal to the number of starting page',
  editor_fileFormBuilder_excel_value_range:
    'Enter the abscissa range of Excel, "line 2 to line 100", can be entered as: "2" ~ "10"',
  editor_fileFormBuilder_fileFilter: 'File filter',
  editor_fileFormBuilder_include: 'Include file',
  editor_fileFormBuilder_exclude: 'Discard file',
  editor_fileFormBuilder_loadSchema: 'Load Schema',
  editor_fileFormBuilder_xpath: 'Select record data XPath',
  editor_fileFormBuilder_tableName: 'Model name',
  editor_fileFormBuilder_loadSchemaTip:
    'After configuring the above items, please click the Load Model" button to update the file model. If there is no model, sync transmission cannot be performed',
  dataVerify_row: 'Row verify',
  dataVerify_hash: 'Hash verify',
  dataVerify_advance: 'Advance verify',
  dataVerify_dataVerify: 'Data verify',
  dataVerify_dataWay: 'Verify mode',
  dataVerify_range: 'Sampling',
  dataVerify_source: 'Source table',
  dataVerify_target: 'Target table',
  dataVerify_sourceDatabase: 'Data source',
  dataVerify_targetDatabase: 'Target source',
  dataVerify_sourceText: 'Please select the source table',
  dataVerify_targetText: 'Please select the target table',
  dataVerify_sourceDatabaseText: 'Please select the data source',
  dataVerify_targetDatabaseText: 'Please select the target source',
  dataVerify_operate: 'Operate',
  dataVerify_dataVerifySetting: 'Data verify setting',
  dataVerify_confirm: 'Confirm',
  dataVerify_start: 'Start verify',
  dataVerify_back: 'Back',
  dataVerify_add: 'Add',
  dataVerify_refresh: 'Refresh',
  dataVerify_cancel: 'Cancel',
  dataVerify_overView: 'OverView',
  dataVerify_time: 'Operating time',
  dataVerify_duration: 'Duration',
  dataVerify_result: 'Error amount',
  dataVerify_linageDifference: 'linage difference',
  dataVerify_errorTotal: 'error Total',
  dataVerify_accuracyRate: 'Accuracy rate(%)',
  dataVerify_errorComparison: 'Error comparison',
  dataVerify_again: 'Check again',
  dataVerify_rows: 'By amount of rows',
  dataVerify_exampleJS: '请输入JS代码, 高级校验JS必须返回return值, 具体请查看示例',
  dataVerify_sampleRate: 'By percentage',
  dataVerify_condition: 'Sampling range',
  dataVerify_showResult: 'Show result',
  dataVerify_filter: 'filter',
  dataVerify_filterMQL: 'Please enter MQL query statement',
  dataVerify_filterSQL: 'Row Verify only supports select count(*) query statements',
  dataVerify_exampleSQL: 'e.g.: select count(*)  from tablename_1 where field__2 = A;',
  dataVerify_exampleMQL: 'e.g.: db.collection_1.count({ field_2:A })',
  dataVerify_exampleHashSQL:
    "Please enter SELECT query statement Hash verify only supports SELECT query statement, but doesn't support such as count/sum/avg/max,etc. e.g.: select field_1 from tablename_1 where field__2 = A;",
  dataVerify_exampleHashMQL:
    'Please enter MQL query statement. e.g.: db.collection_1.find ({ field_2:A },{ field_1:1 })',
  dataVerify_verifyRunningInfo: 'Keep verifying in background',
  dataVerify_verifyStatusWaiting: 'Verifying phase 1-3:  verification job queuing, please wait....   Click',
  dataVerify_verifyStatusDraft: 'Verifying phase 2-3:  verification job scheduling, please wait...   Click',
  dataVerify_verifyStatusValidating: 'Verifying phase 3-3:  verification job executing, please wait...   Click',
  dataVerify_verifyStatusInterrupted: 'Verification job being stopped，please wait...   Click',
  dataVerify_verifyStatusStop: 'Stop verification',
  dataVerify_verifyStatusCompleted: 'Verification result loading , please wait for a while',
  dataVerify_or: 'or',
  dataVerify_psc: 'pcs',
  dataVerify_all: 'All',
  dataVerify_setting_title: 'Verify default settings',
  dataVerify_setting_text:
    'The verification setting is the global verification setting, the priority of the advanced setting in the created verification task is higher than the setting here. ',
  dataVerify_setting_keepTimeLabel: 'Retention time of verification historical results and detailed information',
  dataVerify_setting_errorSaveSumLable: 'Check out the limit of the number of error messages saved for each table',
  dataVerify_setting_errorDifferenceResult:
    'The error tolerance of the difference data allowed by the verification result',
  dataVerify_setting_lineNumberFrequency: 'Line number verification interval frequency',
  dataVerify_setting_lineNumVerfyDuration: 'Line number verification duration',
  dataVerify_setting_intervalFrequency: 'Content verification interval frequency',
  dataVerify_setting_verifyDuration: 'Content verification duration',
  dataVerify_setting_verifyStartTime: 'Content verification start execution time',
  dataVerify_setting_verifySetting: 'Verify setting',
  dataMap_source: 'SOURCE',
  dataMap_tapdata: 'Tapdata',
  dataMap_API: 'API',
  dataMap_noneData: 'No data loaded',
  dataMap_classification: 'Data Model Classification',
  dataMap_topLevel: 'Top Level',
  dataMap_dbLevel: 'Database Level',
  dataMap_tableLevel: 'Table Level',
  dataMap_fieldLevel: 'Field Mapping',
  dataMap_infoSource: 'SOURCE',
  dataMap_infoDAAS: 'DAAS',
  dataMap_infoAPI: 'API',
  dataMap_dblclickDataModel: 'Please double-click the data model to open the field mapping',
  dataMap_properties_name: 'Name',
  dataMap_properties_type: 'Classification',
  dataMap_properties_path: 'Path',
  dataMap_properties_database_type: 'Database Type',
  dataMap_properties_database_host: 'Database IP',
  dataMap_properties_database_username: 'Database User',
  dataMap_properties_database_port: 'Database Port',
  dataMap_properties_database_uri: 'Database Connection URL',
  dataMap_properties_database_name: 'Database Name',
  dataMap_properties_original_name: 'Original Name',
  apiInfo_basicAttributes: 'Basic attributes',
  apiInfo_trquestMethod: 'Request method',
  apiInfo_status: 'Status',
  apiInfo_supportFormat: 'Support format',
  apiInfo_founder: 'Creator',
  apiInfo_interfaceClassification: 'Interface classification',
  apiInfo_modifyTime: 'Modify time',
  apiInfo_interface: 'Interface classification',
  apiInfo_version: 'Version',
  apiInfo_parameter: 'parameter',
  apiInfo_typesof: 'Type',
  apiInfo_is_required: 'Whether required',
  apiInfo_examples: 'Examples',
  apiInfo_requestParameters: 'Request parameters',
  apiInfo_responseParameters: 'Response parameters',
  apiInfo_requestExample: 'Request example',
  apiInfo_backExamples: 'Back to examples',
  apiInfo_announcing: 'Posting',
  apiInfo_apiTest: 'API documentation and testing',
  apiInfo_isPublishAPI: 'Are you sure to publish api?',
  apiInfo_unpublish_api: 'Are you sure you want to cancel publishing api?',
  apiInfo_apiPublishSuccess: 'Published',
  apiInfo_apiPublishError: 'API publishing failed',
  apiInfo_apiUnpublishSuccess: 'Unpublished',
  dataForm_title: 'Create Database',
  dataForm_saveSuccess: 'Test and save success.',
  dataForm_saveFail: 'Save failed.',
  dataForm_primaryTest: 'Starting connection test service, please wait for a while ...',
  dataForm_testing: 'Testing, please wait for a while ...',
  dataForm_submit: 'Submit',
  dataForm_cancel: 'Cancel',
  dataForm_backDetection: 'backstage testing',
  dataForm_test_testResultFail: 'Connection test failed',
  dataForm_test_testResultSuccess: 'Connection test successful',
  dataForm_test_testResult: 'Test connection result: ',
  dataForm_test_success: 'Pass',
  dataForm_test_fail: 'Failed',
  dataForm_test_testing: 'Untest',
  dataForm_test_items: 'Test items',
  dataForm_test_result: 'Result',
  dataForm_test_unTest: 'Waiting ... ',
  dataForm_test_information: 'Information',
  dataForm_test_error: 'The test service request timed out, please close and try again.',
  dataForm_test_retryBtn: 'Retry',
  dataForm_test_retryTest: 'The connection test service failed to start, please click Retry',
  dataForm_form_databaseType: 'DB type',
  dataForm_form_kuduhost: 'IP:port;support multiple; separated by ,',
  dataForm_form_agentAddr: 'Agent address',
  dataForm_form_databaseSchema: 'Database Schema',
  dataForm_form_rootName: 'Root name',
  dataForm_form_nodeName: 'Catalog Node Name',
  dataForm_form_isUrl: 'Use URI',
  dataForm_form_thinType: 'Thin Type',
  dataForm_form_clusterName: 'Cluster Name',
  dataForm_form_databaseHostPlaceholder:
    'Database Host(127.0.0.1/Domain:{Port},Please use multiple addresses , separate)',
  dataForm_form_supportUpdatePk: 'Support Update Primary Key',
  dataForm_form_agentMsg: 'Agent current state exception cannot create connection, please check.',
  dataForm_form_agentConnectionMsg: 'Agent current state is abnormal, cannot to test connection, please check.',
  dataForm_form_multiTenant: 'Multi-tenant',
  dataForm_form_hiveType: 'Hive type',
  dataForm_form_uriTips_label: 'Example',
  dataForm_form_options_standardModeTips:
    'Configure MongoDB database according to Host/IP, port, account and password. Batch input is supported',
  dataForm_form_guide:
    'For data connection configuration, please refer to the guide documenton the right side. For more information about data connection settings, instructions or other information, please click',
  dataForm_form_guideDoc: 'guide document',
  dataForm_form_response_body_CHECK_REDO_LOG_PARSER: 'Check if the raw log parsing service is available',
  dataForm_form_response_body_DORIS_HTTP: 'HTTP connection available',
  dataForm_form_file_fileAddr: 'File Address',
  dataForm_form_file_filePort: 'File Port',
  dataForm_form_file_creatAccount: 'Creator account',
  dataForm_form_file_password: 'Password',
  dataForm_form_file_connectionMethod: 'Connection Method',
  dataForm_form_file_encodingFormat: 'Encoding Format',
  dataForm_form_file_connecitonTimeout: 'Connection timeout (seconds)',
  dataForm_form_file_transmissionTimeout: 'Transmission timeout (seconds)',
  dataForm_form_file_second: 'second',
  dataForm_form_file_fileUrl: 'File Path',
  dataForm_form_file_agreementType: 'Agreement Type',
  dataForm_form_file_agentLocationFile: 'Agent location file',
  dataForm_form_file_agentLocationFileTip: 'Add files at the server where Agent is located.',
  dataForm_form_file_ftpTip: 'Add files according to FTP such as address, port, account, password, etc. ',
  dataForm_form_file_shared: 'Shared folder',
  dataForm_form_file_sharedTip: 'Add files according to shared folders such as address, account, password, etc.',
  dataForm_form_file_activeConnectionMode: 'FTP port mode',
  dataForm_form_file_activeConnectionModeTip:
    'The server initiatively sends a request to establish a connection with high performance. If there is a firewall, the request may fail. ',
  dataForm_form_file_passiveConnectionMode: 'FTP passive mode',
  dataForm_form_file_passiveConnectionModeTip:
    'The connection and data connection are submitted by the client to the server, which can solve the problem that the request is filtered out by the firewall.',
  dataForm_form_file_input_number: 'Please enter a number',
  dataForm_form_file_greaterZero_less5256000: 'Must be greater than or equal to zero and less than or equal to 5256000',
  dataForm_form_file_path: 'Set path',
  dataForm_form_file_recursive: 'Recursive path',
  dataForm_form_file_include_filename: 'Keep file',
  dataForm_form_file_exclude_filename: 'Discard file',
  dataForm_form_file_viewExpression: 'Please enter the file name expression',
  dataForm_form_file_expression: 'Expression example',
  dataForm_form_file_includePlaceholder: 'Please enter regular expression for include file',
  dataForm_form_file_excludePlaceholder: 'Please enter regular expression for discard file',
  dataForm_form_file_pathPlaceholder: 'Please enter the file path',
  dataForm_form_file_addPath: 'Add Path',
  dataForm_form_file_fileNone: 'The file path cannot be empty',
  dataForm_form_file_versionManagement: 'Version Management',
  dataForm_form_file_file_upload_chunk_size: 'File upload file chunk size (bytes)',
  dataForm_form_file_file_upload_mode: 'File upload mode',
  dataForm_form_file_file_upload_stream: 'Streaming',
  dataForm_form_file_file_upload_memory: 'Memory read (risk of memory overflow)',
  dataForm_form_file_overwriteText: 'When a file with the same name exists',
  dataForm_form_file_overwrite: 'Overwrite',
  dataForm_form_file_discard: 'ignore',
  dataForm_form_file_extend_source_path: 'Inherit the directory structure',
  dataForm_form_file_file_output_path: 'File output absolute path',
  dataForm_form_file_csvFijlter: 'File Name Filter ',
  dataForm_form_kafka_chooseTheme: 'Choose a theme',
  dataForm_form_kafka_topicName: 'topic name',
  dataForm_form_kafka_requestTimeoutPeriod: 'Pull request timeout period',
  dataForm_form_kafka_readIsolationLevel: 'Message submission read isolation level',
  dataForm_form_kafka_maximumNumber: 'The maximum number of records returned in a single poll message',
  dataForm_form_kafka_blockingTimeoutTime: 'Single poll message blocking timeout time',
  dataForm_form_kafka_fetchMaximumNumber: 'The maximum number of bytes in a single fetch message',
  dataForm_form_kafka_fetchBlockTime: 'Single fetch message blocking timeout time',
  dataForm_form_kafka_lonoreFormatTip:
    'If it is turned on, it will ignore the message if it encounters a parsing exception, otherwise it will stop pulling the message',
  dataForm_form_kafka_directlyNameTip: 'Enter the subject name directly, separate multiple subjects with commas',
  dataForm_form_kafka_kafkaPatternTopicsTip:
    'Configure the MongoDB database according to Host, port, account, and password, and support batch input',
  dataForm_form_kafka_hostPlaceHolder: 'Enter IP/host:port, separate multiple addresses with commas',
  dataForm_form_kafka_requestTimeout: 'Push request timeout (ms)',
  dataForm_form_kafka_transactionMessage: 'Transaction Message',
  dataForm_form_kafka_kafkaRetries: 'Request retry times',
  dataForm_form_kafka_kafkaBatchSize: 'Partition message batch bytes',
  dataForm_form_kafka_kafkaLingerMS: 'Maximum waiting time for partition message batch (milliseconds)',
  dataForm_form_kafka_kafkaDeliveryTimeoutMS: 'Message transmission timeout time',
  dataForm_form_kafka_kafkaMaxRequestSize: 'Request maximum number of bytes',
  dataForm_form_kafka_kafkaBufferMemory: 'Buffer message bytes',
  dataForm_form_kafka_kafkaPartitionKey: 'Partition key field name',
  dataForm_form_kafka_kafkaPartitionKeyTip: 'Please separate multiple field names with commas',
  dataForm_form_kafka_pushErrorTip:
    'If it is enabled, ignore the message pushed this time (there is a message loss), otherwise stop pushing the message',
  dataForm_form_custom_connection_history_custom_code: 'History Data Javascript',
  dataForm_form_custom_connection_cdc_custom_code: 'Increamental Javascript',
  dataForm_form_custom_connection_on_data_code: 'On Data javascript',
  dataForm_form_custom_connection_sync_type: 'Sync Type',
  dataForm_form_custom_connection_history_data: 'History data',
  dataForm_form_custom_connection_unique_keys: 'Unique primary key',
  dataForm_form_custom_connection_unique_keys_label: 'Comma-delimited list of joint primary key',
  dataForm_form_custom_connection_increamental_data: 'Increamental data',
  dataForm_form_custom_connection_history_increamental_data: 'History and increamental data',
  dataForm_form_restApi_auth_type: 'Auth Type',
  dataForm_form_restApi_request_interval: 'Synchronization interval',
  dataForm_form_restApi_request_interval_tip: 'Synchronization interval (second)',
  dataForm_form_restApi_collection_name: 'Collection Name',
  dataForm_form_restApi_unique_keys: 'Unique primary key',
  dataForm_form_restApi_unique_keys_label: 'Comma-delimited list of joint primary key',
  dataForm_form_restApi_req_pre_process: 'Request preprocessing script',
  dataForm_form_restApi_resp_pre_process: 'Response preprocessing script',
  dataForm_form_restApi_data_sync_mode: 'Data synchronize mode',
  dataForm_form_restApi_url_info: 'Urls',
  dataForm_form_restApi_url_info_url_invalid: 'Invalid URL, url example: http://127.0.0.1:8080/api/xxx?param=value',
  dataForm_form_restApi_url_info_method: 'Method',
  dataForm_form_restApi_url_info_url_type: 'URL Type',
  dataForm_form_restApi_url_info_ONLY: 'Fetch Data URL',
  dataForm_form_restApi_url_info_INITIAL_SYNC: 'Synchronize historical data',
  dataForm_form_restApi_url_info_INCREMENTAL_SYNC: 'Synchronize real-time data',
  dataForm_form_restApi_url_info_INITIAL_INCREMENTAL_SYNC: 'Synchronize historical and real-time data',
  dataForm_form_restApi_url_info_GET_TOKEN: 'Authenticate URL',
  dataForm_form_restApi_url_info_header_name: 'Header name',
  dataForm_form_restApi_url_info_header_value: 'Header value',
  dataForm_form_restApi_url_info_parameter_name: 'Parameter name',
  dataForm_form_restApi_url_info_parameter_value: 'Parameter value',
  dataForm_form_restApi_url_info_offset_field: 'Incremental field',
  dataForm_form_restApi_url_info_initial_offset: 'Incremental start value',
  dataForm_form_restApi_url_info_content_type: 'Content Type',
  dataForm_form_gridfs_gridfs_prefix: 'Bucket Name',
  dataForm_form_gridfs_gridfs_prefixDir: 'Include Dir path',
  dataForm_form_gridfs_gridfs_tag_filter: 'Tag Filter',
  dataForm_form_gridfs_data_regex: 'Data regex',
  dataForm_form_gridfs_gridfs_mode: 'Read Mode',
  dataForm_form_gridfs_gridfs_data: 'Parse Into Data',
  dataForm_form_gridfs_gridfs_binary: 'Binary Transmission',
  dataForm_form_gridfs_include_filename: 'Include filename',
  dataForm_form_gridfs_exclude_filename: 'Exclude filename',
  dataForm_form_gridfs_file_schema: 'Target Collection',
  dataForm_form_gridfs_file_schema_tip: 'If files are of same type, please specify a common name.',
  dataForm_form_gridfs_file_type: 'File type',
  dataForm_form_gridfs_separator: 'Separator',
  dataForm_form_gridfs_json_type: 'Json type',
  dataForm_form_gridfs_xpath: 'Select record data XPath',
  dataForm_form_gridfs_gridfs_upload_chunk_size: 'Gridfs Upload Chunk Size(Byte)',
  dataForm_form_gridfs_file_upload_mode: 'File Upload Mode',
  dataForm_form_gridfs_file_upload_stream: 'Stream',
  dataForm_form_gridfs_file_upload_memory: 'Memory(May be cause OOM)(有内存溢出风险)',
  dataForm_form_mq_brokerURL: 'Broker URL',
  dataForm_form_mq_database_host: 'MQ Host',
  dataForm_form_mq_database_port: 'MQ Port',
  dataForm_form_mq_queueSetTip: 'Multiple queues are separated by commas',
  dataForm_form_mq_topicSetTip: 'Multiple topics separated by commas',
  dataForm_form_mq_brokerUrl: 'MQ connection string',
  dataForm_form_mq_brokerUrlTip: 'example tcp://127.0.0.1 : 61616, support TCP, NiO, UDP, SSL, HTTP (s) ',
  dataForm_form_tcp_agreementType: 'Protocol type ',
  dataForm_form_tcp_targetAddr: 'Target address',
  dataForm_form_transform_fieldName: 'Field name',
  dataForm_form_transform_messageBody: 'Message body',
  dataForm_form_transform_dragSort: 'Support drag sort',
  dataForm_form_transform_addField: 'Add Field',
  dataForm_form_transform_name: 'Name',
  dataForm_form_transform_existName: 'Name already exists.Redefine',
  dataForm_form_transform_type: 'Type',
  dataForm_form_transform_modifier: 'Modifier',
  dataForm_form_transform_add: 'Add',
  dataForm_form_transform_edit: 'Edit',
  dataForm_form_transform_delete: 'Delete',
  dataForm_form_transform_deleteFieldTip:
    'Are you sure you want to delete the field? After deletion, it cannot be restored',
  dataForm_form_transform_typePlaceholder: 'Please select type',
  dataForm_form_transform_empty: 'Cannot be empty',
  dataForm_form_transform_exist: 'Already exists',
  dataForm_form_transform_noSameNameandType: 'The name cannot be the same as the type',
  dataForm_form_transform_specialSymbols: 'Special symbols are not allowed',
  dataForm_form_transform_deleteFieldConfirm:
    'Are you sure you want to delete the field? Cannot recover after deletion',
  dataForm_error_connectionNameExist: 'Connection name already existed.',
  dataForm_error_connectionurl: 'Connection name already existed.',
  dataForm_error_duplicateSource: 'This data source already existed',
  dataForm_error_sourceNameExist: 'This data source already exists',
  dataForm_error_noCreate: ' , Cannot be created repeatedly',
  dataForm_error_kafkaNameRange: 'The topic name length is greater than 256',
  dataForm_createDatabase: 'Create New Connection',
  dataForm_copyDatabase: 'Copy name',
  dataForm_checkDatabase: 'Check property',
  dataForm_createTable: 'Create New Table',
  dataForm_copyTable: 'Copy name',
  dataForm_createCollection: 'Create new collection',
  dataForm_copyCollection: 'Copy name',
  dataForm_dialogTitle: 'Prompt',
  dataForm_close: 'Close',
  formBuilder_file_placeholder: 'Please select a file',
  formBuilder_file_button: 'Select',
  formBuilder_input_placeholderPrefix: 'Enter ',
  classification_title: 'Data Category',
  classification_userTitle: 'User Group',
  classification_creatUserGroup: 'Create user group',
  classification_creatDataClassification: 'Create data classification',
  classification_nameExist: 'Category name already existed.',
  classification_addNode: 'Add category at the same level',
  classification_addChildernNode: 'Add Child Category',
  classification_editNode: 'Edit',
  classification_nodeName: 'Please enter classification',
  classification_deteleMessage:
    'This operation will delete all subclasses existing in this category, whether to delete it',
  relations_blood: 'Table Tracing',
  relations_refresh: 'Refresh',
  relations_refreshStatus: 'Last Refresh',
  relations_lastTimeConsume: 'Last time consuming',
  relations_allProgress: 'Total number of parsing tasks',
  relations_refreshMsg:
    'All synchronous tasks will be analyzed and lineage graph will be generated. It may take a long time, click "YES" to confirm',
  relations_refreshTitle: 'Synchronous tasks analysis',
  relations_refreshStatusMsg: 'Syncing graphics data, graphics may be missing, please refresh later and try again',
  relations_second: ' Second',
  relations_minute: ' Minute',
  relations_hours: ' Hours',
  relations_day: ' Day',
  relations_customFields: 'Custom fields, please separate multiple fields with , ',
  relations_label: 'Field type/field name',
  relations_viewTaskInfo: 'Task details',
  relations_task: 'Task',
  relations_add: 'Add',
  relations_delete: 'Delete',
  relations_rename: 'Rename',
  relations_field: 'Fields',
  relations_attributes: 'Attributes',
  relations_changeType: 'Change type',
  relations_script: 'Script processing',
  relations_fieldScript: 'Field script',
  relations_count: 'COUNT',
  relations_sum: 'SUM',
  relations_average: 'AVERAGE',
  relations_min: 'MIN',
  relations_max: 'MAX',
  relations_group: 'Group by',
  relations_field_processor: 'Field processor',
  relations_js_processor: 'Script processor',
  relations_aggregation_processor: 'Aggregation processor',
  relations_name: 'Name',
  relations_database_host: 'Database host',
  relations_database_port: 'Database port',
  relations_database_username: 'Database username',
  relations_database_name: 'Database name',
  relations_database_owner: 'Database owner',
  relations_originalName: 'Original name',
  relations_qualified_name: 'Qualified name',
  relations_meta_type: 'Type',
  relations_create_source: 'Source',
  relations_createTime: 'Create time',
  relations_last_updated: 'Last updated',
  relations_last_user_name: 'Last user name',
  metadata_createNewModel: 'Create model',
  metadata_namePlaceholder: 'Please enter the table name/database name',
  metadata_typePlaceholder: 'Please select the type',
  metadata_databasePlaceholder: 'Please select a database',
  metadata_createModel: 'Create a model',
  metadata_header_name: 'Table name/owned database',
  metadata_header_meta_type: 'Meta type',
  metadata_header_last_user_name: 'Last update user',
  metadata_header_last_updated: 'Last update time',
  metadata_metaType_database: 'Database',
  metadata_metaType_api: 'API',
  metadata_metaType_job: 'Job',
  metadata_metaType_table: 'Table',
  metadata_metaType_collection: 'Collection',
  metadata_metaType_view: 'View',
  metadata_metaType_directory: 'Directory',
  metadata_metaType_dataflow: 'Data Flow',
  metadata_metaType_mongo_view: 'Mongodb View',
  metadata_metaType_ftp: 'FTP',
  metadata_metaType_apiendpoint: 'API End Point',
  metadata_form_type: 'Meta type',
  metadata_form_database: 'Database',
  metadata_form_tableName: 'Table name',
  metadata_form_none_table_name: 'The table name cannot be empty',
  metadata_details_model: 'Model',
  metadata_details_collection: 'Collection',
  metadata_details_collectionName: 'Collection name',
  metadata_details_createCollection: 'Create collection',
  metadata_details_dataDirectory: 'Data Directory',
  metadata_details_dataDetails: 'Data Details',
  metadata_details_basicAttributes: 'Basic Properties',
  metadata_details_businessAttributes: 'Custom Properties',
  metadata_details_clickAddDes: 'Click to add a description',
  metadata_details_propertyDetails: 'Property Details',
  metadata_details_name: 'Name',
  metadata_details_comment: 'Description',
  metadata_details_data_type: 'Field Type',
  metadata_details_precision: 'Precision',
  metadata_details_columnSize: 'Column size',
  metadata_details_scale: 'Scale',
  metadata_details_autoincrement: 'Autoincrement',
  metadata_details_primary_key_position: 'Primary key',
  metadata_details_foreign_key_position: 'Foreign key',
  metadata_details_is_nullable: 'Not Null',
  metadata_details_unique: 'Unique',
  metadata_details_originalTableName: 'Original name',
  metadata_details_typesOf: 'Type',
  metadata_details_owningConnection: 'Connection',
  metadata_details_primaryKey: 'PK',
  metadata_details_source: 'Source',
  metadata_details_creationTime: 'Create time',
  metadata_details_founder: 'Creater',
  metadata_details_changeTime: 'Edit time',
  metadata_details_Modifier: 'Editor',
  metadata_details_renamed: 'Renamed',
  metadata_details_edit: 'Edit',
  metadata_details_searchPlaceholder: 'Field name/alias/description',
  metadata_details_selsectSource: 'Select source',
  metadata_details_createFiled: 'Create field',
  metadata_details_editFild: 'Edit field',
  metadata_details_prohibitOverwriting: 'Batch overwriting is prohibited',
  metadata_details_batchCoverage: 'Batch coverage',
  metadata_details_refreshModel: 'Refresh model',
  metadata_details_filedName: 'Field name',
  metadata_details_alias: 'Alias',
  metadata_details_description: 'Description',
  metadata_details_fieldType: 'Field Type',
  metadata_details_allowOverwrite: 'Sync by DB',
  metadata_details_selfIncreasing: 'Autoincrement',
  metadata_details_fieldLength: 'Column size',
  metadata_details_accuracy: 'Precision',
  metadata_details_numberLength: 'Scale',
  metadata_details_dictionarySettings: 'Dictionary Settings',
  metadata_details_initialValue: 'Initial value',
  metadata_details_mappedValue: 'Mapping value',
  metadata_details_enterInitialValue: 'Enter initial value',
  metadata_details_enterMappedValue: 'Enter the mapped value',
  metadata_details_opera: 'Operation',
  metadata_details_newMapping: 'Create new',
  metadata_details_chooseTemplate: 'Choose template',
  metadata_details_foreignKeySetting: 'Foreign Key Set',
  metadata_details_associationTable: 'Associated table',
  metadata_details_associationField: 'Associated field',
  metadata_details_connectionRelation: 'Relation type',
  metadata_details_oneone: 'one to one',
  metadata_details_onemany: 'one to many',
  metadata_details_manyone: 'many to one',
  metadata_details_addRelatedTable: 'Create new',
  metadata_details_enter: 'Please enter',
  metadata_details_select: 'Please select',
  metadata_details_filedAliasName: 'Field name/Alias',
  metadata_details_Float: 'Floating point number',
  metadata_details_String: 'String',
  metadata_details_baseObject: 'Object',
  metadata_details_Array: 'Array',
  metadata_details_Map: 'Dictionary Object',
  metadata_details_Short: 'Short integer',
  metadata_details_Long: 'Long integer',
  metadata_details_Double: 'Double Precision',
  metadata_details_Byte: 'Byte',
  metadata_details_Bytes: 'Number of bytes',
  metadata_details_BigDecimal: 'Decimal',
  metadata_details_Boolean: 'Boolean value',
  metadata_details_Date: 'Date',
  metadata_details_Integer: 'Integer',
  metadata_details_dictionary_typeNo: 'This field type cannot add a dictionary template',
  metadata_details_fieldNameNo: 'The field name is empty',
  metadata_details_moreAttributes: 'More Properties',
  metadata_details_msgFiledName: 'Please enter the field name',
  metadata_details_success_Release: 'Save successfully, please republish manually',
  metadata_details_filedName_repeat: 'Field name cannot be the same name',
  metadata_details_filedDictionary: 'Field Dictionary',
  metadata_details_foreignKeyAssociation: 'Foreign key',
  metadata_details_tableLayering: 'Category',
  metadata_details_theme: 'Theme',
  metadata_details_taskReference: 'Task Reference',
  metadata_details_APIReference: 'API Reference',
  metadata_details_creat: 'New',
  metadata_details_businessAttrTitle: 'Business attribute',
  metadata_details_attrName: 'Property name',
  metadata_details_attrKey: 'Property value',
  metadata_details_editAliasNameTitle: 'Edit alias',
  metadata_details_editCommentTitle: 'Edit description',
  metadata_details_uniquelyIdentifies: 'Qualified Name',
  metadata_details_query: 'Query',
  metadata_details_version_version: 'Version',
  metadata_details_version_version_control: 'Version Control Mode',
  metadata_details_version_version_control_required: 'Version Control Mode is required',
  metadata_details_version_lastVersion:
    'This metadata is already the latest version, the historical version records saved in the past will be saved in the list below',
  metadata_details_version_versionNum: 'Version number',
  metadata_details_version_versionComparison: 'Version comparison',
  metadata_details_version_compared: 'Compared',
  metadata_details_version_currentVersion: 'Current version',
  metadata_details_version_updateTime: 'Update Time',
  metadata_details_version_operator: 'Operator',
  metadata_details_version_modifyDescription: 'Modify Description',
  metadata_details_Modify_property: 'Modify property',
  metadata_details_Modify_field: 'Modify field property',
  metadata_details_Add_property: 'Add property',
  metadata_details_Add_new_field: 'Add new field in schema',
  metadata_details_Remove_property: 'Remove property',
  metadata_details_Remove_field: 'Remove field from schema',
  metadata_details_index_title: 'Index',
  metadata_details_index_name: 'Index name',
  metadata_details_index_create: 'Create index',
  metadata_details_index_fields: 'Time fields',
  metadata_details_index_unique: 'Unique constraint',
  metadata_details_index_status: 'Status',
  metadata_details_index_create_by: 'Create user',
  metadata_details_index_background: 'Background',
  metadata_details_index_properties: 'Properties',
  metadata_details_index_definition: 'Field name',
  metadata_details_index_options: 'Options',
  metadata_details_index_build_in_background: 'Build index in the background',
  metadata_details_index_create_unique: 'Create unique index',
  metadata_details_index_create_ttl: 'Create TTL',
  metadata_details_index_name_exists: 'Index name must be unique',
  metadata_details_index_index_exists: 'Index already exists',
  metadata_details_index_create_by_user: 'Platform user',
  metadata_details_index_create_by_dba: 'Database Administrator',
  metadata_details_index_status_creating: 'Creating',
  metadata_details_index_status_created: 'Create complete',
  metadata_details_index_status_creation_failed: 'Creation failed',
  metadata_details_index_status_deleted: 'Deleted',
  metadata_details_index_drop_index: 'Deleting index',
  metadata_details_index_unique_true: 'Unique',
  metadata_details_index_unique_false: 'not unique',
  metadata_details_validation_title: 'Data verification',
  metadata_details_validation_field_name: 'Field name',
  metadata_details_validation_rule: 'Rule',
  metadata_details_validation_ruleTem: 'Rule Template',
  metadata_details_validation_select_rule: 'Selection rules',
  metadata_details_validation_ungrouped: 'Ungrouped',
  metadata_details_validation_create: 'Create data verification',
  metadata_details_preview_title: 'Data Preview',
  metadata_details_pipeline_title: 'Pipeline',
  metadata_details_pipeline_collection: 'Data table',
  metadata_details_pipeline_pipeline: 'MongoDB Pipeline',
  metadata_details_pipeline_viewStatus: 'View Status',
  metadata_details_pipeline_FailedMessage: 'Failed details',
  metadata_details_pipeline_penpinSave:
    'Click the save button below to only save to the system, click the update button to apply to the database where this data is located',
  metadata_details_pipeline_apply: 'Apply',
  metadata_details_pipeline_cnot_Empty: 'Cannot be empty',
  metadata_details_pipeline_view_tip:
    'The operation will overwrite the view with the same name, whether to create a view',
  metadata_details_pipeline_success: 'Apply successful',
  metadata_details_pipeline_failed: 'Application failed',
  metadata_metadataSearch_title: 'Metadata retrieval',
  metadata_metadataSearch_desc:
    'Metadata retrieval provides search functions for the names, aliases, descriptions of tables and fields, please select the search table/field first, then enter the content, and click the search button to search',
  metadata_metadataSearch_table: 'Search table',
  metadata_metadataSearch_column: 'Search field',
  metadata_metadataSearch_search: 'Search',
  metadata_metadataSearch_noSearch: 'Please press "Enter" to initiate a search',
  metadata_metadataSearch_noResult: 'No search results, please confirm the search keywords',
  metadata_metadataSearch_originalName: 'Original table name',
  metadata_metadataSearch_noMore: 'No more search results',
  metadata_metadataSearch_more: 'Click to load more',
  metadata_metadataSearch_placeholder: 'please enter keyword to search',
  notification_notice: 'Notice',
  notification_viewMore: 'View more',
  notification_setting: 'Notice settings',
  notification_allNotice: 'All notice',
  notification_unreadNotice: 'Unread notice',
  notification_maskRead: 'Mask read this page',
  notification_maskReadAll: 'Mask read all',
  notification_systemNotice: 'System notice',
  notification_userNotice: 'Account Operation',
  notification_noticeCenter: 'Setting center',
  notification_dataFlow: 'DataFlow',
  notification_sync: 'Sync job',
  notification_migration: 'Migration job',
  notification_manageSever: 'Management server',
  notification_inspect: 'Verify job',
  notification_noticeType: 'Choose notice type',
  notification_noticeLevel: 'Choose notice level',
  notification_started: 'started',
  notification_paused: 'paused',
  notification_edited: 'edited',
  notification_deleted: 'deleted',
  notification_abnormallyStopped: 'abnormally stopped',
  notification_stoppedByError: 'stopped by error',
  notification_startupFailed: 'startup failed',
  notification_stopFailed: 'stop failed',
  notification_encounterERRORSkipped: 'skip an ERROR',
  notification_CDCLag: 'CDC lag',
  notification_manageSeverRestartFailed: 'MANAGE SEVER restart failed',
  notification_APISeverRestartFailed: 'API SEVER restart failed',
  notification_SYNCSeverRestartFailed: 'SYNC SEVER restart failed\t',
  notification_connectionInterrupted: 'connection interrupted',
  notification_manageSeverStartFailed: 'MANAGE SEVER start failed',
  notification_APISeverStartFailed: 'API SEVER start failed',
  notification_SYNCSeverStartFailed: 'SYNC SEVER start failed',
  notification_manageSeverStopFailed: 'MANAGE SEVER stop failed',
  notification_APISeverStopFailed: 'API SEVER stop failed',
  notification_SYNCSeverStopFailed: 'SYNC SEVER stop failed',
  notification_APISeverAbnormallyStopped: 'API SEVER abnormally stopped',
  notification_SYNCSeverAbnormallyStopped: 'SYNC SEVER abnormally stopped',
  notification_manageSeverAbnormallyStopped: 'MANAGE SEVER abnormally stopped',
  notification_manageSeverStartedSuccessfully: 'MANAGE SEVER started successfully',
  notification_APISeverStartedSuccessfully: 'API SEVER started successfully',
  notification_SYNCSeverStartedSuccessfully: 'SYNC SEVER started successfully',
  notification_manageSeverStoppedSuccessfully: 'MANAGE SEVER stopped successfully',
  notification_APISeverStoppedSuccessfully: 'API SEVER stopped successfully',
  notification_SYNCSeverStoppedSuccessfully: 'SYNC SEVER stopped successfully',
  notification_manageSeverRestartedSuccessfully: 'MANAGE SEVER restarted successfully',
  notification_APISeverRestartedSuccessfully: 'API SEVER restarted successfully',
  notification_SYNCSeverRestartedSuccessfully: 'SYNC SEVER restarted successfully',
  notification_newSeverCreatedSuccessfully: 'NEW SEVER created successfully',
  notification_newSeverDeletedSuccessfully: 'NEW SEVER deleted successfully',
  notification_databaseDDLChanged: 'Database DDL changed',
  notification_inspectVerifyJobCount: 'count difference',
  notification_inspectVerifyJobValue: 'field value difference',
  notification_inspectVerifyJobDelete: 'was deleted',
  notification_inspectVerifyJobError: 'error',
  notification_approaching: 'remaining ',
  notification_day: ' day',
  notification_settingCenter: 'Setting center',
  notification_systemSetting: 'System setting',
  notification_noticeSetting: 'Notice setting',
  notification_tip:
    'The notice setting here is the system global notification setting. The priority of the notification setting of Data flow job page is higher than the global notification setting here',
  notification_jobOperationNotice: 'Job operation notice',
  notification_emailNotice: ' Email notice',
  notification_jobStarted: 'Job started',
  notification_jobPaused: 'Job paused',
  notification_jobDeleted: 'Job deleted',
  notification_jobEdited: 'Job edited',
  notification_jobStateError: 'Job state error',
  notification_jobEncounterError: 'Job encounter error',
  notification_noticeInterval: 'Notice interval',
  notification_CDCLagTime: 'CDC lag time',
  notification_lagTime: 'Lag-time',
  notification_DDL: 'Database DDL changes',
  notification_agentNotice: 'Agent notice',
  notification_serverDisconnected: 'Server disconnected',
  notification_agentAbnormallyStopped: 'Agent sever abnormally stopped',
  notification_agentStarted: 'Agent started',
  notification_agentStopped: 'Agent stopped',
  notification_agentFailed: 'Agent start failed',
  notification_agentStop: 'Agent stop failed',
  notification_agentCreated: 'Agent created',
  notification_agentDeleted: 'Agent deleted',
  notification_inspectCount: 'Verify job count difference',
  notification_inspectValue: ' Verify job field value difference',
  notification_inspectDelete: ' Verify job was deleted',
  notification_inspectError: 'Verify job error',
  notification_ddlDeal: 'DDL',
  notification_system: 'License expiration time',
  notification_sourceName: 'Source Name',
  notification_databaseName: 'Database Name',
  notification_schemaName: 'Schema Name',
  notification_placeholder_user: 'Choose operator',
  notification_placeholder_keyword: 'search by datasource/job name',
  notification_account: 'Account ',
  notification_operation_create: ' created ',
  notification_operation_update: ' updated ',
  notification_operation_delete: ' deleted ',
  notification_operation_start: ' started ',
  notification_operation_stop: ' stopped ',
  notification_operation_forceStop: ' force stopped ',
  notification_operation_reset: ' reset ',
  notification_operation_copy: ' copied ',
  notification_operation_upload: 'upload ',
  notification_operation_download: ' downloaded ',
  notification_operation_login: ' login ',
  notification_operation_logout: ' logout ',
  notification_modular_sync: 'Sync job',
  notification_modular_migration: 'Migration job',
  notification_modular_connection: ' connection ',
  notification_modular_dataflow: ' data flow job ',
  notification_modular_inspect: ' verity job ',
  notification_modular_ddlDeal: ' DDL',
  notification_modular_system: ' System ',
  dialog_createTable: 'Create New Table',
  dialog_placeholderTable:
    'Only supports English, numbers, underscores, minus signs, dots, and starts with English letter',
  dialog_createCollection: ' Create New Collection ',
  dialog_placeholderCollection:
    'Only support English, numbers, underscores, minus signs, dots, and starts with English letter, and cannot start with "system"',
  dialog_tableValidateTip:
    'Table name can contain only English letters, numbers, underscores, minus signs, dots, and starts with English letter',
  dialog_collectionValidateTip:
    'Collection name can contain only English letters, numbers, underscores, minus signs, dots, and starts with English letter, and cannot start with "system"',
  dialog_downAgent_headTitle: 'Agent download and installation',
  dialog_downAgent_headInterpretation:
    'Tapdata DFS Cloud have to install Agent at local server to ensure databases connection and transmission services normally',
  dialog_downAgent_downloadInstall: 'Download and install',
  dialog_downAgent_text:
    'First, a JAVA runtime environment is required in the installation environment. Then, download and start Agent by using the following command.',
  dialog_downAgent_copy: 'Copy command',
  dialog_downAgent_copied: 'copied',
  dialog_downAgent_refresh: 'Refresh',
  dialog_downAgent_downloadInstallInstructions: 'Download installation instructions',
  dialog_downAgent_linuxInstructionsText1:
    '· First, ensure that the JAVA runtime environment is installed in the installation target environment.',
  dialog_downAgent_linuxInstructionsText2:
    '· Execute the above command in install environment, Agent will download and start automatically ',
  dialog_downAgent_linuxInstructionsText3:
    '· You can start and stop Agent by executing the command "tapdata start/stop backend".',
  dialog_downAgent_waitingInstall: 'Waiting installation',
  dialog_downAgent_agentInstallation: 'Agent has been installed',
  dialog_downAgent_agentNum: 'Agents installed',
  dialog_downAgent_downLoadAgent: 'Download Agent',
  dialog_downAgent_windowsText:
    'First, a JAVA runtime environment is required in the installation environment. After download, you can install and start Agent by using the following command in the directory where the Agent Installation package stored.',
  dialog_downAgent_windowsInstructionsText1:
    '· First, ensure that the JAVA runtime environment is installed in the installation target environment.',
  dialog_downAgent_windowsInstructionsText2: '· Second, download the installation file and store it in a directory.',
  dialog_downAgent_windowsInstructionsText3:
    '· Third, enter the directory, and execute the command to install and start Agent automatically. ',
  dialog_downAgent_windowsInstructionsText4: '· Only one Agent can be installed under an account of Tapdata cloud.',
  dialog_downAgent_windowsInstructionsText5:
    '· You can start and stop Agent by executing the command "tapdata start/stop backend".',
  dialog_downAgent_dockerText:
    'First, a Docker runtime environment is required in the installation environment. Then, download and start Agent by using the following command.',
  dialog_downAgent_dockerText1:
    '· First, ensure that the Docker runtime environment is installed in the installation target environment.',
  dialog_downAgent_dockerText2: '· After executing the command, the Agent will be automatically installed and started.',
  dialog_downAgent_important: 'Important: ',
  dialog_downAgent_noAgent: 'You have not installed Agent yet, and cannot execute the transmission jobs. Please ',
  dialog_downAgent_clickDownLoad: ' click to download and install',
  dialog_downAgent_dfsSuccessText: 'DFS Agent installed successfully,',
  dialog_downAgent_dfsSuccessText1: 'Or click',
  dialog_downAgent_dfsSuccessText2:
    'Create a data transfer task and experience the Tapdata DFS rapid data transfer function',
  dialog_downAgent_dfsSuccessText3: 'DFS Agent installed successfully, job',
  dialog_downAgent_dfsSuccessText4: 'is running',
  dialog_downAgent_creatTask: 'Create new',
  dialog_downAgent_clickView: 'Click view detail',
  dialog_downAgent_ok: 'OK',
  dialog_downAgent_agentRun: 'Agent installed ',
  dialog_library: 'The database',
  dialog_sameTable: 'has duplicate name tables: ',
  dialog_repeatTip:
    'click database name above to process the tables on the data catalog page to ensure the uniqueness of the table name under this database',
  dialog_jobSchedule_jobSecheduleSetting: 'Job schedule settings',
  dialog_jobSchedule_job: 'Job:',
  dialog_jobSchedule_sync: 'Sync:',
  dialog_jobSchedule_expression: 'Expression:',
  dialog_jobSchedule_expressionPlaceholder: 'Please enter cron expression',
  dialog_jobSchedule_second: 'second',
  dialog_jobSchedule_minute: 'minute',
  dialog_jobSchedule_hour: 'hour',
  dialog_jobSchedule_day: 'day',
  dialog_jobSchedule_month: 'month',
  dialog_jobSchedule_week: 'week',
  dialog_jobSchedule_year: 'year',
  dialog_jobSchedule_jobSchedule: 'Job schedule settings',
  dialog_jobSchedule_jobSchedule_tip: 'Job schedule settings - available only for initial job',
  dataVerification_verifyDetail: 'Verify Detail',
  dataVerification_sourceTable: 'Source Table',
  dataVerification_targetTable: 'Target Table',
  dataVerification_sourceRows: 'Source Table Rows',
  dataVerification_verifyResult: 'Verify Result',
  dataVerification_rowConsistent: 'Count diff',
  dataVerification_contConsistent: 'Value diff',
  dataVerification_jointVerify: 'Joint field value verify',
  dataVerification_verifyHistory: 'Verify History',
  dataVerification_tableDetail: ' Table detail',
  dataVerification_configuration: 'Configuration',
  dataVerification_verifyName: 'Verify name',
  dataVerification_sourceTotalRows: 'Verfify Rows',
  dataVerification_targetTotalRows: 'Target Rows',
  dataVerification_verifyStatus: 'Verify Status',
  dataVerification_verifystatus: 'Verify status',
  dataVerification_result: 'Verification result',
  dataVerification_completeTime: 'Completion time',
  dataVerification_verifyTime: 'Verify Time',
  dataVerification_operation: 'Operation',
  dataVerification_rowVerify: 'Row verify',
  dataVerification_advanceVerify: 'Advanced verification',
  dataVerification_JSVerifyLogic: 'JS verify logic',
  dataVerification_addJS: 'Add JS',
  dataVerification_returnMsg: 'Returned message',
  dataVerification_returnedData: 'Returned data ',
  dataVerification_sourceTableData: 'Source table data',
  dataVerification_contentVerify: 'Content verify',
  dataVerification_singleVerify: 'Single verify',
  dataVerification_repeatingVerify: 'Repeating verify',
  dataVerification_inconsistent: 'Inconsistent',
  dataVerification_consistent: 'Consistent',
  dataVerification_toBeVerified: 'To be verified',
  dataVerification_verifying: 'Verifying',
  dataVerification_verifyFinished: 'Verify finished',
  dataVerification_verifyJobExpired: 'Verify job expired',
  dataVerification_executeVerifyInstantly: 'Execute verify instantly',
  dataVerification_deleteVerifyJob: 'Delete verify job',
  dataVerification_verifySetting: 'Verify Setting',
  dataVerification_batchVerify: 'Batch Verify',
  dataVerification_verifyJobName: 'Verify Job Name',
  dataVerification_verifyjobname: 'Verify job name',
  dataVerification_verifyType: 'Verify Type',
  dataVerification_verifytype: 'Verify type',
  dataVerification_singleRepeatingVerify: 'Single/repeating verify',
  dataVerification_rowAndContConsistent: 'Row-and-Cont-consistent',
  dataVerification_sourceFieldName: 'Source Field Name',
  dataVerification_targetFieldName: 'Target Field Name',
  dataVerification_Value: 'value',
  dataVerification_inconsistentType: 'Inconsistent Type',
  dataVerification_success:
    'Congratulations~~~~  The field contents of the source table and the target table are identical, no error record here',
  dataVerification_chooseJob: 'Choose job',
  dataVerification_frequency: 'Frequency',
  dataVerification_startTime: ' Start time',
  dataVerification_LastTime: 'Stop time',
  dataVerification_startAndStopTime: 'Start and stop time',
  dataVerification_verifyInterval: 'Verify interval',
  dataVerification_inconsistentCount: 'Inconsistent data to be saved',
  dataVerification_table: 'Table',
  dataVerification_addTable: 'Add table',
  dataVerification_automaticallyAdd: 'Automatically add',
  dataVerification_enable: 'Enable',
  dataVerification_disable: 'Disable',
  dataVerification_isEnabled: 'Is Enabled',
  dataVerification_newVerify: 'New Verify',
  dataVerification_edit: 'Edit',
  dataVerification_clickVerified: 'Click the bottons below to add tables to be verified',
  dataVerification_ChoosePKField: 'Choose index /PK field',
  dataVerification_indexField: 'Index field',
  dataVerification_BasicSettings: 'Basic Settings',
  dataVerification_verifyCondition: 'Verify Conditions',
  dataVerification_clear: 'Clear',
  dataVerification_fastCountTip:
    'Fast count mode which only verify the number of rows of source and target tables has a extremely fast speed but does not show the differential field values.',
  dataVerification_contentVerifyTip:
    'Table field value verify mode which will verify all fields of source and target tables row by row can find out the differences of all fields, but has a slow speed.',
  dataVerification_jointFieldTip:
    'Joint fields value verify mode only compares the joint field value of source and target tables，faster than table field value verify mode .',
  dataVerification_waiting: 'To be verified',
  dataVerification_scheduling: 'Scheduling',
  dataVerification_error: 'Error',
  dataVerification_done: 'Verify finished',
  dataVerification_running: 'Running',
  dataVerification_verifyProgress: 'Verify Progress',
  dataVerification_tasksTime: 'please set start and stop time',
  dataVerification_tasksDataFlow: 'Please choose data flow job',
  dataVerification_tasksJobName: 'please enter verify job name',
  dataVerification_tasksVerifyCondition: 'Please set verify condition',
  dataVerification_tasksVerifyInterval: 'Please choose data verify interval',
  dataVerification_lackSource: 'Lack source or target table in verify condition',
  dataVerification_lackIndex: 'Lack index field of source or target table in verify condition',
  dataVerification_tasksAmount:
    'The amount of index field of source table does not equal to target table in verify condition',
  dataVerification_uniqueField: 'Unique field inconsistent ',
  dataVerification_otherField: 'Other field inconsistent',
  dataVerification_back: 'Back',
  dataVerification_startVerify: 'Executing verify',
  dataVerification_deleteMessage: 'This will permanently delete the choosed verify job',
  dataVerification_executeVerifyTip: 'Execute verify',
  dataVerification_addVerifyTip: 'Create new verify job ',
  dataVerification_historyTip: 'History',
  dataVerification_detailTip: 'Detail',
  dataVerification_configurationTip: 'Configuration',
  dataVerification_deleteTip: 'Delete',
  dataVerification_checkStatusPre: 'The job status is ',
  dataVerification_checkStatusSuffix: ' , cannot modify configuration',
  dataVerification_backConfirmMessage:
    'This operation will lose the verification task currently being created (edited)',
  dataVerification_backConfirmTitle: 'Would you give up creating (editing) verification tasks? ',
  queryBuilder_addCond: 'field Cond',
  tableFlow_task_view: 'Data Flow View',
  tableFlow_table_view: 'Table View',
  tableFlow_source_target_table: 'Source/Target Table',
  tableFlow_task_execution_time: 'Job/Execution Time',
  tableFlow_status_text: 'Status',
  tableFlow_stage: 'Stage',
  tableFlow_output_input: 'Output/Input (rows)',
  tableFlow_speed: 'Speed (QPS)',
  tableFlow_rows: 'Rows',
  tableFlow_opear: 'Operation',
  tableFlow_output: 'Output',
  tableFlow_input: 'Input',
  tableFlow_row_count_check: 'Rows Count',
  tableFlow_batch_verification: 'Batch verification',
  account_accountSettings: 'Account settings',
  account_setCenter: 'Settings Center',
  account_systemSetting: 'System Settings',
  account_noticeSetting: 'Notice Settings',
  account_email: 'Email',
  account_userName: 'User name',
  account_password: 'Password',
  account_accessCode: 'Access Code',
  account_changePassword: ' Change Password',
  account_currentPassword: 'Please enter the current password',
  account_newPassword: 'Please enter the new password',
  account_confirmPassword: 'Confirm password again',
  account_changeEmail: 'Change Email',
  account_enterMailbox: 'Please enter mailbox',
  account_enterNewMailbox: 'Please enter the new mailbox',
  account_changeUsername: 'Change User name',
  account_newUsername: 'Please enter a new username',
  account_sendEmail: 'Sent verify email',
  account_samePawTip: 'The new password cannot be the same as the original password!',
  account_newPawInconsistent: 'Inconsistent with the new password!',
  account_pawSaveSuccess: 'Password saved successfully',
  account_currerPawErrorTip: 'The current password is incorrect, please enter the correct password',
  account_nameModifySuccess: 'Name modified successfully',
  account_passwordNotCN: 'Only alphanumeric characters and hyphens are allowed in password',
  account_user_null: "That username's been taken",
  account_has_username: 'Username already exists',
  account_editFail: 'User name modification failed',
  role_allData: 'All role data',
  role_functionDataPermission: 'Function and data permissions',
  role_module: 'Module',
  role_choosePermissionTip:
    'Please select the functions and data permissions available for this role (checking all role data means you can browse or operate the data of all roles, unchecking means you can only browse or operate your own data )',
  role_funcPermission: 'Function permission settings',
  role_currentRole: 'Current role',
  role_pageVisible: 'Page permission settings',
  role_pageShowTip:
    'Checked means navigation and page are visible to the current character, unchecked will not display',
  role_choosePage: 'Select Page permission',
  role_bulkOperate: 'Select all',
  role_allCheck: 'Select all',
  role_chooseAllFunction: 'Select all functions',
  role_chooseAllRole: 'All role data',
  role_settingTitle: 'Set Up Permission',
  role_createRole: 'Create role',
  role_editroleTitle: 'Role Edit',
  role_roleName: 'Role Name',
  role_roleDesc: 'Role description',
  role_defaultRole: 'Default Role',
  role_rolePermission: 'role permission',
  role_alreadyExists: 'Duplicate role name',
  role_page_Dashboard_menu: 'Dashboard (Home)',
  role_page_datasource_menu: 'Datasource',
  role_page_Data_SYNC_menu: 'Migration & Data Synchronization',
  role_page_Data_verify_menu: 'Data verify',
  role_page_data_catalog_menu: 'Data Catalog',
  role_page_data_quality_menu: 'Data quality',
  role_page_data_rules_menu: 'Data rules',
  role_page_time_to_live_menu: 'Data time to live',
  role_page_data_lineage_menu: 'Data lineage',
  role_page_API_management_menu: 'API management',
  role_page_API_data_explorer_menu: 'API data explorer',
  role_page_API_doc_test_menu: 'API doc & test',
  role_page_API_stats_menu: 'API stats',
  role_page_API_clients_menu: 'API clients',
  role_page_API_server_menu: 'API server',
  role_page_data_collect_menu: 'Data collection (old)',
  role_page_schedule_jobs_menu: 'Scheduled jobs',
  role_page_Cluster_management_menu: 'Cluster Management',
  role_page_agents_menu: 'Agents',
  role_page_user_management_menu: 'User management',
  role_page_role_management_menu: 'Role management',
  role_page_system_settings_menu: 'System Settings',
  role_page_dictionary_menu: 'Dictionary',
  role_page_Topology_menu: 'Topolog',
  role_page_servers_oversee_menu: 'Servers oversee',
  role_moduleMeun_Dashboard: 'Datasource',
  role_moduleMeun_datasource: 'Datasource',
  role_moduleMeun_Data_SYNC: 'Migration & Data Synchronization',
  role_moduleMeun_SYNC_Function_management: 'Function management',
  role_moduleMeun_Data_verify: 'Data verify',
  role_moduleMeun_data_government: 'Data governance',
  role_moduleMeun_data_catalog: 'Data catalog',
  role_moduleMeun_data_quality: 'Data quality',
  role_moduleMeun_data_rules: 'Data rules',
  role_moduleMeun_time_to_live: 'Data time to live',
  role_moduleMeun_data_lineage: 'API lineage',
  role_moduleMeun_API_management: 'API management',
  role_moduleMeun_API_data_explorer: 'API data explorer',
  role_moduleMeun_API_doc_test: 'API doc & test',
  role_moduleMeun_API_stats: 'API stats',
  role_moduleMeun_API_clients: 'API clients',
  role_moduleMeun_API_server: 'API server',
  role_moduleMeun_data_collect: 'Data collection (old)',
  role_moduleMeun_schedule_jobs: 'Scheduled jobs',
  role_moduleMeun_Cluster_management: 'Cluster Management',
  role_moduleMeun_agents: 'Agents',
  role_moduleMeun_user_management: 'User Management',
  role_moduleMeun_role_management: 'Role Management',
  role_moduleMeun_system_settings: 'System Settings',
  role_roleNavName_Dashboard: 'Dashboard (Home)',
  role_roleNavName_system_notice: 'system notice',
  role_roleNavName_notice_settings: 'notice settings',
  role_roleNavName_account_operation_history: 'account operation history',
  role_roleNavName_datasource: 'View datasource',
  role_roleNavName_datasource_category_management: 'datasource category management',
  role_roleNavName_datasource_category_application: 'datasource category application',
  role_roleNavName_datasource_creation: 'datasource creation',
  role_roleNavName_datasource_delete: 'datasource deleting',
  role_roleNavName_datasource_edition: 'datasource editing',
  role_roleNavName_data_transmission: 'data transmission ',
  role_roleNavName_Data_SYNC: 'View dataflow',
  role_roleNavName_SYNC_category_management: 'category management',
  role_roleNavName_SYNC_category_application: 'category application',
  role_roleNavName_SYNC_job_creation: 'Job creation',
  role_roleNavName_SYNC_job_delete: 'Job deleting',
  role_roleNavName_SYNC_job_edition: 'Job editing',
  role_roleNavName_SYNC_job_operation: 'Job operation',
  role_roleNavName_SYNC_job_import: 'Job import ',
  role_roleNavName_SYNC_job_export: 'Job export ',
  role_roleNavName_SYNC_Function_management: 'View function management',
  role_roleNavName_Data_verify: 'View data verify',
  role_roleNavName_verify_job_creation: 'verify job creation',
  role_roleNavName_verify_job_edition: 'verify job editing & execution',
  role_roleNavName_verify_job_delete: 'verify job deleting',
  role_roleNavName_data_government: 'data government',
  role_roleNavName_data_catalog: 'View data catalog ',
  role_roleNavName_data_catalog_category_management: 'data catalog category management',
  role_roleNavName_data_catalog_category_application: 'data catalog category application',
  role_roleNavName_data_catalog_edition: 'data catalog editing',
  role_roleNavName_new_model_creation: 'new model creation',
  role_roleNavName_data_quality: 'View data quality',
  role_roleNavName_data_quality_edition: 'data quality editing',
  role_roleNavName_data_rules: 'View data rules',
  role_roleNavName_data_rule_management: 'data rule management',
  role_roleNavName_time_to_live: 'View time to live',
  role_roleNavName_time_to_live_management: 'time to live management',
  role_roleNavName_data_lineage: 'View data lineage',
  role_roleNavName_data_publish: 'View data publish',
  role_roleNavName_API_management: 'View API management',
  role_roleNavName_API_category_application: 'API category application',
  role_roleNavName_API_category_management: 'API category management',
  role_roleNavName_API_creation: 'API creation',
  role_roleNavName_API_delete: 'API deleting',
  role_roleNavName_API_edition: 'API editing',
  role_roleNavName_API_publish: 'API publish',
  role_roleNavName_API_import: 'API import',
  role_roleNavName_API_export: 'API export',
  role_roleNavName_API_data_explorer: 'View API data explorer',
  role_roleNavName_API_data_explorer_export: 'API data explorer export',
  role_roleNavName_API_doc_test: 'View API doc & test',
  role_roleNavName_API_stats: 'View API stats',
  role_roleNavName_API_clients: 'View API clients',
  role_roleNavName_API_clients_amangement: 'API clients amangement',
  role_roleNavName_API_server: 'View API server',
  role_roleNavName_API_server_management: 'API server management',
  role_roleNavName_data_collect: 'View data collect(old)',
  role_roleNavName_system_management: 'View system management',
  role_roleNavName_schedule_jobs: 'View schedule jobs',
  role_roleNavName_schedule_jobs_management: 'schedule jobs management',
  role_roleNavName_Cluster_management: 'View Cluster management',
  role_roleNavName_Cluster_operation: 'Cluster operation',
  role_roleNavName_status_log: 'status log',
  role_roleNavName_agents: 'View agents',
  role_roleNavName_user_management: 'View user management',
  role_roleNavName_user_creation: 'user creation',
  role_roleNavName_user_edition: 'user editing',
  role_roleNavName_user_delete: 'user deleting',
  role_roleNavName_user_category_management: 'user category management',
  role_roleNavName_user_category_application: 'user category application',
  role_roleNavName_role_management: 'View role management',
  role_roleNavName_role_creation: 'role creation',
  role_roleNavName_role_edition: 'role editing',
  role_roleNavName_role_delete: 'role deleting',
  role_roleNavName_system_settings: 'View system settings',
  role_roleNavName_system_settings_modification: 'system settings modification',
  role_roleNavName_servers_oversee: 'View servers oversee',
  role_roleNavName_dictionary: 'View dictionary',
  role_roleNavName_Topology: 'View Topology',
  role_roleNavName_meta_data_deleting: 'Metadata delete',
  role_roleNavName_API_data_explorer_deleting: 'API data explorer deleting',
  role_roleNavName_API_data_explorer_tagging: 'API data explorer tagging',
  role_roleNavName_API_data_time_zone_editing: 'API data time zone editing',
  role_roleNavName_API_data_creation: 'API data creation',
  role_roleNavName_API_data_download: 'API data download',
  role_roleManagement: 'Role Management',
  role_preciseMatching: 'precise matching',
  role_fuzzyMatching: 'Fuzzy matching',
  role_selectRoleName: 'Please enter the role name',
  role_selectDesc: 'Please enter a role description',
  role_selectUser: 'Please select a user name',
  role_description: 'Role Description',
  role_associatUsers: 'Associate user',
  role_edit: 'Edit',
  role_founder: 'Founder',
  role_operate: 'Operation',
  role_create: 'New',
  role_settingPermissions: 'Set permission',
  role_delete: 'Delete',
  role_yes: 'Yes',
  role_no: 'No',
  role_delete_remind: 'Confirm to delete role',
  role_delete_success: 'Delete role successfully',
  role_delete_error: 'Failed to delete role',
  role_connected: 'Associated',
  role_role_null: 'The role name cannot be empty',
  milestone_INIT_DATAFLOW: '【Preparation】Analyze the DAG and create sub job(s)',
  milestone_CONNECT_TO_SOURCE: '【Preparation】Connecto to source',
  milestone_CONNECT_TO_TARGET: '【Preparation】Connect to target',
  milestone_INIT_CONNECTOR: '【Preparation】Scan source information and initialize the source collector',
  milestone_INIT_TRANSFORMER: '【Preparation】Scan target information and initialize the target handler',
  milestone_READ_SOURCE_DDL: '【Preparation】Read source DDL information(Database Migration)',
  milestone_DROP_TARGET_SCHEMA: '【Preparation】Drop target schema',
  milestone_CLEAR_TARGET_DATA: '【Preparation】Empty the target data',
  milestone_CREATE_TARGET_TABLE: '【Preparation】Automatically create target table',
  milestone_CREATE_TARGET_INDEX: '【Preparation】Automatically create target index',
  milestone_CREATE_TARGET_VIEW: '【Preparation】Automatically create target view',
  milestone_CREATE_TARGET_FUNCTION: '【Preparation】Automatically create target function',
  milestone_CREATE_TARGET_PROCEDURE: '【Preparation】Automatically create target procedure',
  milestone_READ_SNAPSHOT: '【Data transfer】Read the source snapshot',
  milestone_WRITE_SNAPSHOT: '【Data transfer】Write the snapshot into target',
  milestone_READ_CDC_EVENT: '【Data transfer】Source enters incremental read mode',
  milestone_WRITE_CDC_EVENT: '【Data transfer】Target enters incremental write mode',
  milestone_emptyText: 'The job has not been started or has been reset, so there is no running milestone data.',
  milestone_status_paused: 'paused',
  milestone_status_waiting: 'Waiting',
  milestone_status_running: 'Running',
  milestone_status_error: 'Error',
  milestone_status_finish: 'Finish',
  guide_guide_title: 'New user guide',
  guide_step_1: 'Agent download and installation',
  guide_step_2: 'Set data source',
  guide_step_3: 'Set goal',
  guide_step_4: 'Select the task type and start the data transmission journey',
  guide_step_1_title: 'Agent download and installation',
  guide_step_1_desc:
    'Tapdata DFS Cloud Edition needs to install the agent locally to ensure the normal operation of the connection database and data transmission service. You can select the corresponding type below to download and install according to the type of server to be installed.',
  guide_step_2_title: 'Create a data source connection',
  guide_step_2_desc:
    'Data source connection refers to the data connection of the database that can be used as the source. The data source must be created before the migration or synchronization task can be created.',
  guide_step_2_btn_label: 'Create a new source connection',
  guide_step_3_title: 'Create target connection',
  guide_step_3_desc:
    'The target connection refers to the data connection of the database that can be used as data transmission targets. The target connection must be created before the migration or synchronization task can be created.',
  guide_step_3_btn_label: 'Create a new target connection',
  guide_step_4_title: 'Select task type',
  guide_step_4_desc:
    'Please select the type of task to be performed according to the prompts below, the system will open the corresponding task editing panel according to your choice, if you choose a wrong task, you can cancel the task and select again.',
  guide_task_type_clone: 'Database migration',
  guide_task_type_clone_tips:
    'Database migration function takes the library as the unit user to easily realize the structure migration, initial migration, or incremental migration between multiple homogeneous or heterogeneous databases (libraries, table mapping) within a task, suitable for data Database migration to the cloud, database migration between instances, database migration to the cloud, database disaster recovery and other scenarios. ',
  guide_task_type_custom: 'Data synchronization',
  guide_task_type_custom_tips:
    "Data synchronization focuses on table-level data processing and transmission, to meet the needs of users to achieve multi-table (data set), multi-table integration between multi-level data, data splitting, association mapping, field increase and decrease merge, content filtering, Real-time data synchronization is realized at the same time in the case of aggregate processing JS processing and other functions. Without affecting the user's business, it meets the user's needs for various business scenarios such as remote or local data disaster recovery, cross-instance data synchronization, query and report distribution, and real-time data warehouse management. ",
  guide_agent_not_install:
    'The system detects that the Agent is not installed, please download and install and try again',
  guide_btn_save: 'Save,',
  guide_btn_to_dataflow: 'Start editing task',
  guide_btn_to_dashboard: "Don't edit the task for now, go shopping first",
  guide_not_source: 'Please choose a source connection',
  guide_not_target: 'Please choose a target connection',
  guide_agentServiceTitle: 'Agent service status is abnormal',
  guide_abnormalText: 'abnormal reason',
  guide_abnormal: 'The environment where the Agnet process is located is disconnected',
  guide_abnormal1: 'Agnet service process was killed',
  guide_solutionText: 'Solution',
  guide_windowsSolution: 'WINDOWS: Start the server and execute commands',
  guide_windowsSolution1: 'WINDOWS: execute commands in the Agent environment',
  guide_linuxSolution: 'LINUX: Start the server and execute commands',
  guide_linuxSolution1: 'LINUX: execute commands in the Agent environment',
  guide_restartProcess: 'To restart the process',
  guide_clickText: 'The process has been restarted? Please click',
  user_des: 'The user management page provides functions to create, edit, delete, and status settings for users',
  user_all: 'All',
  user_inactivated: 'Not activated',
  user_unverified: 'Unverified',
  user_userNameEmail: 'Please enter your username/email',
  user_changeTime: 'Modification time',
  user_creatUser: 'Create user',
  user_editUser: 'Edit User',
  user_userName: 'Username',
  user_role: 'Role',
  user_source: 'Source',
  user_status: 'Status',
  user_opera: 'Operation',
  user_activation: 'Activation',
  user_freeze: 'Freeze',
  user_delete: 'Delete',
  user_check: 'Check',
  user_edit: 'Edit',
  user_bulkActivation: 'Bulk activation',
  user_bulkFreeze: 'Bulk Freeze',
  user_bulkCheck: 'Batch check',
  user_create: 'Create',
  user_registration: 'Register',
  user_notVerified: 'Not verified',
  user_notActivated: 'Not activated',
  user_activated: 'Activated',
  user_rejected: 'Rejected',
  user_passwordNull: 'Please enter a password, the length is 5 ~ 32 characters',
  user_pass_hint: 'Password length cannot be less than 5 and greater than 32',
  user_activationCode: 'Access Code',
  user_delUserTitle: 'Whether to delete this user ?',
  user_delUser: 'Delete user',
  user_deluserLast: ' after this user will not be able to recover',
  user_checkUserTitle: 'Whether to verify this user ?',
  user_checkUser: 'Pass the verification user',
  user_checkUserLast: ' after the mailbox, this user can be activated',
  user_activationUserTitle: 'Do you want to activate this user ? ',
  user_activetionUser: 'Activation User',
  user_activetionUserLast: ' after that, this user will be able to use the TAPDATA system',
  user_freezeUserTitle: 'Do you want to freeze this user ? ',
  user_freezeUser: 'Freeze user',
  user_freezeUserLast: ' after this user will not be able to use the TAPDATA system',
  user_startTime: 'Start Time',
  user_endTime: 'End Time',
  user_emailNull: 'Email cannot be empty',
  user_email_must_valid: 'Please enter a valid email address',
  user_activetionSuccess: 'Activation successful',
  user_activetionError: 'Activation failed',
  user_freezeSuccess: 'Freeze successful',
  user_freezeError: 'Freeze failed',
  user_checkSuccess: 'Pass verification',
  user_checkError: 'Verification failed',
  user_alreadyExists: 'User name cannot be repeated',
  process_name: 'Name/worker type',
  process_worker_ip: 'Address',
  process_version: 'Version',
  process_online: 'Online',
  process_all: 'All',
  process_state: 'State',
  process_job_ids: 'Detail',
  process_running_thread: 'Running thread',
  process_total_thread: 'Number of threads',
  process_worker_type: 'Worker type',
  process_ping_time: 'Ping time',
  process_start_time: 'Start time',
  process_process_id: 'Process ID',
  process_processState: 'Working process state',
  timeToLive_header_indexName: 'Index name',
  timeToLive_header_indexFields: 'Time Field',
  timeToLive_header_indexStatus: 'Status',
  timeToLive_header_indexCreate_by: 'Create user',
  timeToLive_header_operate: 'Operation',
  timeToLive_header_database: 'Database name',
  timeToLive_header_tableName: 'Data table name',
  timeToLive_header_expire: 'Expiration time',
  timeToLive_form_databaseTypes: 'Database Type',
  timeToLive_form_database: 'Database',
  timeToLive_form_tableName: 'table name',
  timeToLive_form_fieldName: 'Field name',
  timeToLive_form_expire: 'Expiration time',
  timeToLive_creatTtl: 'Create life cycle',
  timeToLive_searchtext: 'Database name/Data table name/Index name',
  timeToLive_Settinglife: 'Set life cycle',
  timeToLive_m: 'minute',
  timeToLive_h: 'hour',
  timeToLive_d: 'day',
  timeToLive_s: 'second',
  timeToLive_w: 'week',
  timeToLive_mo: 'month',
  timeToLive_y: 'year',
  timeToLive_failed: 'The current database table, no time field was found, and the life cycle could not be created',
  timeToLive_create_by_user: 'Platform user',
  timeToLive_create_by_dba: 'Database Administrator',
  timeToLive_status_creating: 'Creating',
  timeToLive_status_created: 'Create complete',
  timeToLive_status_creation_failed: 'Creation failed',
  timeToLive_status_deleted: 'Deleting',
  timeToLive_filedGetFailed:
    'The current database table, no time field was found, and the life cycle could not be created',
  timeToLive_index_exists: 'Index already exists',
  setting_email_template: 'Email template',
  setting_connect_and_test: 'Connection test',
  setting_saveSuccess: 'Save successfully, take effect in one minute',
  setting_nameserver: 'Server name',
  setting_Log: 'Log',
  setting_SMTP: 'SMTP',
  setting_Job: 'Task',
  setting_license: 'License Control',
  setting_expiredate: 'Expiration time',
  setting_import: 'Import',
  setting_apply: 'Apply for license',
  setting_license_expire_date: 'License expiration time',
  setting_Worker: 'Process',
  setting_Download: 'Download',
  setting_Log_level: 'Log level',
  setting_maxCpuUsage: 'Maximum CPU usage (value range 0.1 ~ 1)',
  setting_maxHeapMemoryUsage: 'Maximum heap memory usage (value range 0.1 ~ 1)',
  setting_switch_insert_mode_interval:
    'Interval time for switching to batch insert mode in incremental mode (unit: second)',
  setting_Email_Communication_Protocol: 'Encryption Method',
  setting_SMTP_Server_Port: 'SMTP service port',
  setting_SMTP_Server_User: 'SMTP service account',
  setting_SMTP_Server_password: 'SMTP service password',
  setting_Email_Receivers: 'Email receiving email address',
  setting_Email_Send_Address: 'Email sending email address',
  setting_SMTP_Server_Host: 'SMTP Service Host',
  setting_Send_Email_Title_Prefix: 'Send Email title prefix (optional)',
  setting_Email_Template_Running: 'Task start notification',
  setting_Email_Template_Paused: 'Task Paused Notification',
  setting_Email_Template_Error: 'Task error notification',
  setting_Email_Template_Draft: 'Notification of task being edited',
  setting_Email_Template_CDC: 'Task Incremental Delay Notification',
  setting_Email_Template_DDL: 'DDL error notification',
  setting_Clean_Message_Time: 'Clear message time',
  setting_Keep_Alive_Message: 'Keep online message',
  setting_Sample_Rate: 'Sampling rate',
  setting_task_load_threshold: 'Task load threshold (percentage)',
  setting_task_load_statistics_time: 'Task load statistics time (minute)',
  setting_ApiServer: 'API distribution settings',
  setting_Default_Limit: 'The number of rows returned by the default query',
  setting_Max_Limit: 'Maximum number of rows returned by the query',
  setting_Send_batch_size: 'Number of packed data',
  setting_hint_Send_batch_size: 'Number of packed data',
  setting_Mongodb_target_create_date: 'Whether to add the creation time to the target data set',
  setting_Mongodb_target_create_date_docs: 'Whether to add the creation time to the target data set',
  setting_System: 'System Resource Monitoring',
  setting_Collect_system_info_interval: 'System resource monitoring collection frequency (seconds)',
  setting_Interval_to_collect_system_info:
    'System resource information (CPU, memory, hard disk usage) monitoring collection frequency',
  setting_Job_Sync_Mode: 'Task synchronization mode',
  setting_Worker_Threshold: 'Process Threshold',
  setting_Worker_Heartbeat_Expire: 'Process heartbeat period time (seconds)',
  setting_License_Key: 'Certificate Key',
  setting_Enter_jobs_log_level__error_warn_info_debug_trace: 'Enter task log level: error/warn/info/debug/trace',
  setting_Email_Receivers_Multiple_separated_by_semicolons:
    'Mail recipients, you can enter multiple, separated by commas',
  setting_Keep_recent_n_hours_message_before_the_last_processed_message_s_time_: 'Keep the last n hours news',
  setting_Store_full_record_as_embedded_document_in_target_collection_for_update_operations:
    'Cache a copy of the current overall data and merge it into the target data set',
  setting_Store_before_field_as_embedded_document_in_target_collection_before_update_operation:
    'Cache a copy of the overall data before modification and merge it into the target data set',
  setting_Store_job_script_processor_log_to_cloud: 'Whether to transfer task logs to the cloud',
  setting_Validator_to_validate_data__s_sample_rate: 'Validation data sampling rate',
  setting_Process_message_mode__consistency_fast: 'Message processing mode consistency/fast',
  setting_Worker_can_execute_the_nums_of_Jobs: 'The process can perform multiple tasks',
  setting_Worker_heartbeat_expire_time: 'Process heartbeat period time',
  setting_Users: 'User',
  setting_Show_Page: 'Show download page',
  setting_User_Registery: 'User registration management',
  setting_hint_Show_Page: 'Show download page',
  setting_hint_User_Registery:
    'User registration type settings. The value is set to "disabled": registration is prohibited; the value is set to "self-signup" to enable user self-registration; the value is set to "manual-approval" to allow user registration, but requires administrator approval. ',
  setting_DR_Rehearsal: 'Disaster preparedness drill',
  setting_Mongod_path: 'Mongod path',
  setting_SSH_User: 'SSH username',
  setting_SSH_Port: 'SSH Port',
  setting_hint_Mongod_path: 'Mongod path',
  setting_hint_SSH_User: 'SSH username, used to connect to the host of Mongod',
  setting_hint_SSH_Port: 'SSH port, used to connect to the host of Mongod',
  setting_Enable_DR_Rehearsal: 'Allow disaster recovery exercises',
  setting_hint_Enable_DR_Rehearsal: 'Disaster recovery rehearsal switch, true means on, false means off',
  setting_Download_Agent_Page: 'Agent Download Page',
  setting_Background_Analytics: 'Background analysis',
  setting_Data_quality_analysis_frequency: 'Data quality analysis interval (seconds)',
  setting_Dashboard_data_analysis_frequency: 'Panel data analysis interval (seconds)',
  setting_dashboard_Analysis_Interval: 'Panel data analysis interval (seconds)',
  setting_quality_Analysis_Interval: 'Data quality analysis interval (seconds)',
  setting_Log_filter_interval: 'Log filtering interval (seconds)',
  setting_Filter_the_interval_between_duplicate_logs__seconds__:
    'The same log appears only once within a specified time (valid after 1 minute)',
  setting__DK36: 'File download',
  setting_File_Down_Base_Url: 'Address',
  setting_Set_the_average_number_of_events_per_second_to_allow:
    'Log settings allow the average number of events per second',
  setting_Log_Filter_Rate: 'Log output frequency (line/sec)',
  setting_Connections: 'Connection Settings',
  setting_Mongodb_Load_Schema_Sample_Size: 'Mongodb load model sample records (rows)',
  setting_hint_Mongodb_Load_Schema_Sample_Size:
    'When MongoDB connects to load the model, this configuration will be used for sampling and loading',
  setting_Enable_API_Stats_Batch_Report: 'Enable API Statistics',
  setting_Header: 'UDP header information',
  setting_hint_Header: 'UDP header information',
  setting_Size_Of_Trigger_API_Stats_Report: 'Maximum number of API request cache',
  setting_hint_Size_Of_Trigger_API_Stats_Report:
    'When the number of API request records reaches the specified number, batches are sent to the management end',
  setting_Time_Span_Of_Trigger_API_Stats_Report: 'API request report frequency (seconds)',
  setting_hint_Time_Span_Of_Trigger_API_Stats_Report:
    'The API request is cached and sent to the management end at the specified time',
  setting_save: 'Save successfully, take effect in one minute',
  setting_Logout_forward_to_this_url: 'Logout forwarding address',
  setting_Check_devices: 'Important device detection',
  setting_ops: 'Operation and maintenance display',
  setting_server_oversee_url: 'O&M operation control URL',
  setting_system: 'System global',
  setting_licenseNoticeDays: 'license expiration reminder',
  setting_flow_engine_version: 'Flow engine version',
  setting_tapdata_agent_version: 'tapdata agent version',
  setting_doc_base_url: 'Help document URL',
  setting_help: 'Help document',
  setting_Ip_addresses: 'Ipv4 addresses (separated by multiple commas)',
  setting_hint_Ip_addresses: 'The ipv4 address of the device to be detected, for example: 127.0.0.1, 192.168.0.1',
  setting_PingTimeout: 'Detection timeout (milliseconds)',
  setting_hint_PingTimeout: 'When this setting is exceeded, it is considered that the device cannot be connected',
  setting_Job_field_replacement: 'Illegal characters replaced with',
  setting_A_replacement_for_the_invalid_field_name:
    'Some databases have special requirements for field names, tapdata will automatically replace illegal characters during synchronization. MongoDB[Contains ".", "$" as the beginning]',
  setting_true__store_log_to_cloud__false__only_store_to_local_log_file_:
    'true: store log to cloud, false: only store to local log file.',
  setting_When_one_document_may_be_updated_frequently_within_very_short_period_a_few_updates_within_one_second__for_instance___the_change_stream_event_received_by_downstream_processor_may_return_the__fullDocument__that_is_inconsistent_with_the_actual_version_when_the_update_was_applied_to_that_document__To_avoid_this_inconsistency__enable_this_option_to_store_the_full_document_along_with_the_update_operation__This_will_at_the_expense_of_additional_storage_and_degraded_performance_:
    'When a document may be frequently updated in a very short time (for example, several updates within a second), the change stream event received by the downstream processor may return "fullDocument" that is inconsistent with the actual version ( Inconsistent with the actual version) the file. To avoid this inconsistency, please enable this option to store the complete document with the update operation. This will be at the expense of increased storage space and reduced performance. ',
  setting_the_before_field_contains_a_field_for_each_table_column_and_the_value_that_was_in_that_column_before_the_update_operation_:
    'the before field contains a field for each table column and the value that was in that column before the update operation.',
  setting_Job_heart_timeout: 'Synchronization task heartbeat timeout (milliseconds)',
  setting_job_cdc_share_mode: 'Incremental synchronization task sharing mode',
  setting_job_cdc_share_mode_doc:
    'In the incremental synchronization phase, the sharing mode will be automatically adopted according to whether the log collection task is available. Affected database: Oracle',
  setting_job_cdc_share_only: 'Incremental tasks are forced to use shared mode',
  setting_job_cdc_share_only_doc:
    'When the incremental synchronization task sharing mode is turned on and a sharable log cannot be found, the task will be stopped',
  setting_test_email_success: 'The test email has been sent, please log in to the receiving mailbox to check it',
  setting_test_email_countdown: 'The operation is too frequent, please try again later',
  setting_email_template_from: 'From',
  setting_email_template_to: 'Recipient',
  setting_email_template_subject: 'Subject',
  setting_job_cdc_record: 'Automatically save incremental events',
  setting_job_cdc_record_doc: 'Automatically save incremental events',
  setting_job_cdc_record_ttl: 'Incremental event save time (days)',
  setting_job_cdc_record_ttl_doc: 'Incremental event save time (days)',
  setting_lagTime: 'incremental lag decision time (seconds)',
  setting_connection_schema_update_hour: 'Data source schema update time',
  setting_connection_schema_update_interval: 'Data source schema update interval (days)',
  setting_creatDuplicateSource: 'Allow the creation of duplicate data sources',
  setting_requestFailed: 'Request processing failed',
  setting_Mongodb_will_use_this_sample_size_when_load_schema:
    'Mongodb will use this sample size when load schema When MongoDB connects to load the model, this configuration will be used for sample loading',
  setting_Switch_to_batch_insert_mode_interval__s__in_cdc_: 'Switch to batch insert mode interval in cdc. ',

  dictionary_creatDictionary: 'Create a dictionary template',
  dictionary_editDictionary: 'Edit dictionary template',
  dictionary_classification: 'Classification',
  dictionary_name: 'Name',
  dictionary_data_type: 'Data Type',
  dictionary_isdatatype: 'Dictionary template details',
  dictionary_baseFloating: 'Floating point number',
  dictionary_baseString: 'String',
  dictionary_baseBoolean: 'Boolean value',
  dictionary_template: 'Template',
  dictionary_pleaseSelect: 'Please select',
  dictionary_pleaseInput: 'Please input',
  dictionary_mapping: 'Mapping value',
  dictionary_initial: 'Initial value',
  dictionary_initialNum: 'Initial value can only enter numbers',
  dictionary_isMappedvalue: 'The mapped value cannot be empty',
  dictionary_isInitialvalue: 'Initial value cannot be empty',
  dictionary_titlenametips: 'The name cannot be repeated, please modify it again',
  dictionary_nameCheck: 'Name cannot be empty',
  dictionary_alreadyExists: 'Rule name already exists',
  dataRule_creatRule: 'Create rule',
  dataRule_editRule: 'Edit Rule',
  dataRule_classification: 'Classification',
  dataRule_name: 'Name',
  dataRule_pleaseSelect: 'Please select',
  dataRule_pleaseInput: 'Please input',
  dataRule_nameCheck: 'The name cannot be empty',
  dataRule_rule: 'Rule',
  dataRule_data_type: 'Field Type',
  dataRule_precision: 'Accuracy',
  dataRule_data_Nullable: 'Nullable',
  dataRule_scale: 'Number length',
  dataRule_data_Range: 'Range',
  dataRule_data_Enum: 'Enumeration',
  dataRule_data_Regex: 'Regex',
  dataRule_greater_that: 'greater than',
  dataRule_less_that: 'less than',
  dataRule_required: 'Cannot be empty',
  dataRule_enum_required: 'Enum value is required',
  dataRule_gt_lt_none: 'The range boundary cannot be none at the same time',
  dataRule_data_type_required: 'Data type is required',
  dataRule_data_regex_required: 'Data regex is required',
  dataRule_correct_rules: 'Please enter the correct rules',
  dataRule_pleaseNum: 'Please enter a number',
  dataRule_dataType_baseFloating: 'Float',
  dataRule_dataType_baseObject: 'Object',
  dataRule_dataType_baseBinarydata: 'Binarydata',
  dataRule_dataType_baseString: 'String',
  dataRule_dataType_baseArray: 'Array',
  dataRule_dataType_baseUndefined: 'Undefined',
  dataRule_dataType_baseBoolean: 'Booleanvalue',
  dataRule_dataType_basedate: 'Date',
  dataRule_dataType_baseNull: 'Null',
  dataRule_dataType_baseRegularexpression: 'Regularexpression',
  dataRule_dataType_baseShorttype: 'Shorttype',
  dataRule_dataType_baseTimestamp: 'Timestamp',
  dataRule_dataType_baseLonginteger: 'Longinteger',
  task_task_name: 'Task name',
  task_task_type: 'Task Type',
  task_statusText: 'Status',
  task_cron_expression: 'Cron expression',
  task_agent_id: 'Run Agent Id',
  task_last_updated: 'Last update time',
  task_task_result_code: 'Task Result Code',
  task_task_result: 'Task Result',
  task_task_duration: 'Task Duration(ms)',
  task_task_start_time: 'Task Start Time',
  task_ahistory: 'Scheduling History',
  task_apitest: 'API Documentation And Testing',
  task_ping_time: 'Ping time',
  task_start: 'Start',
  task_paused: 'Pause',
  task_status_done: 'done',
  task_status_waiting: 'Waiting',
  task_status_scheduling: 'Scheduling',
  dkDashboard_dataCount: 'Overview',
  dkDashboard_trendCount: 'Data increment trend statistics',
  dkDashboard_typeCount: 'Number of optional data types',
  dkDashboard_annulusTitle1: 'Published data (pieces)',
  dkDashboard_annulusTitle2: 'Published data size',
  dkDashboard_annulusTitle3: 'Data types available (number)',
  dkDashboard_annulusTitle4: 'Published data (number)',
  dkDashboard_trendData: 'Publish incremental trends in data',
  dkDashboard_spaceUsage: 'Take up the space(GB)',
  dkDashboard_topRelease: 'Top 10 distribution of released data (pieces)',
  dkDashboard_month: 'Nearly a month',
  dkDashboard_yesterday: 'Yesterday',
  dkDashboard_today: 'Today',
  dkDashboard_create: 'New (number)',
  dkDashboard_update: 'New (Modified)',
  dkDashboard_dataIncrement: 'The incremental data',
  dkDashboard_spaceUsage2: 'Take up the space(number)',
  dkDashboard_from: 'source',
  dkDashboard_unknown: 'unknown',
  dkDashboard_record: 'Historical records (number)',
  dkDashboard_dataSize: 'Data size',
  dkDashboard_outCount: 'Violations(number)',
  dkDashboard_outRate: 'Percent of Violations',
  dkDashboard_gather: 'Summary',
  dkDashboard_zhao: 'M',
  dkDashboard_yi: '*10000W',
  dkDashboard_wan: 'W',
  taskProgress_taskProgressOverview: 'Task progress overview',
  taskProgress_seeDetails: 'View Details',
  taskProgress_tip: '*Current task progress view only supports: MySQL, Oracle, SQL Server, PostgreSQL and MongoDB',
  taskProgress_fullSyuncProgress: 'Full synchronization progress',
  taskProgress_takeTime: 'It is estimated that it will take time to complete the full amount',
  taskProgress_takeCompleteTime: 'Full completion time',
  taskProgress_planMigrationTableNum: 'Number of planned migration tables',
  taskProgress_completedMigrationTableNum: 'Number of completed migration tables',
  taskProgress_planMigrateData: 'Planned migration data volume (rows)',
  taskProgress_completedMigrateData: 'The amount of data that has been migrated (rows)',
  taskProgress_taskStopped: 'Task has been stopped',
  taskProgress_progress: 'In progress',
  taskProgress_stopped: 'Stopped',
  taskProgress_m: 'minute',
  taskProgress_h: 'hour',
  taskProgress_d: 'day',
  taskProgress_fullyCompleted: 'Fully completed',
  taskProgress_currentMigration: 'Current migration status of each library',
  taskProgress_sourceLibraryeName: 'Source library name',
  taskProgress_sourceType: 'Source library type',
  taskProgress_tableNumber: 'Number of incremental tables',
  taskProgress_targetLibraryName: 'Target library name',
  taskProgress_targetType: 'Target library type',
  taskProgress_incrementalState: 'Incremental State',
  taskProgress_operate: 'Operation',
  taskProgress_sourceTableName: 'Source table name',
  taskProgress_targetTableName: 'Target table name',
  taskProgress_totalDataVolume: 'Total data volume (rows)',
  taskProgress_fullMigrationProgress: 'Full migration progress',
  taskProgress_progressScreening: 'Progress Screening',
  taskProgress_details: 'Details',
  taskProgress_done: 'Done',
  taskProgress_querySearch: 'Enter table name keyword query',
  taskProgress_progressInfo: 'Progress Details',
  connection_selector_desc1: 'The trial version is not currently supported',
  connection_selector_desc2: 'For more data sources, please use the official version',
  date_picker_start_time: 'Start time',
  date_picker_end_time: 'End time',
  button_back: 'Return',
  message_name_exist: 'Name already exists',
  schema_progress_status_success: 'Finished',
  schema_progress_status_error: 'Loading error',
  schema_progress_dialog_error_title: 'Schema loading error',
  schema_progress_load_time: 'Loaded time: {0}',
  verify_title_create: 'New verification',
  verify_title_edit: 'Edit Verification',
  verify_history_source_rows: 'Verfify Rows',
  verify_history_target_rows: 'Target Rows',
  verify_history_source_total_rows: 'Source Total Rows',
  verify_history_target_total_rows: 'Target Total Rows',
  verify_type_row_count: 'Quick count verification',
  verify_type_field: 'Check all field values ​​of the table',
  verify_type_joint_field: 'Associated field value verification',
  verify_tips_type_row_count:
    'Quick count only performs count verification on the number of rows in the source table and the target table. The speed is extremely fast, but the specific field content of the difference will not be displayed.',
  verify_tips_type_field:
    'Full table field value verification will verify all the fields of the source table and the target table row by row. It can detect the differences in all fields, but the speed is slow.',
  verify_tips_type_joint_field:
    'Associated key verification only compares and verifies the values ​​of the associated fields of the source table and the target table, which is faster than the full-table field value verification mode',
  verify_frequency_manual: 'Single verification',
  verify_frequency_cron: 'Repeat verification',
  verify_job_enable: 'Enabled',
  verify_job_disable: 'Disabled',
  verify_job_name: 'Verify job name',
  verify_form_label_select_job: 'Select task',
  verify_form_label_type: 'Verification Type',
  verify_form_label_frequency: 'Verify frequency',
  verify_form_label_start_and_end_time: 'Start and end time',
  verify_form_label_interval: 'Verification interval',
  verify_form_label_error_save_count: 'Number of saved errors',
  verify_form_label_index_field: 'Index field',
  verify_form_label_script: 'JS verification logic',
  verify_form_label_table: 'Table to be verified',
  verify_form_joint_table_header: 'Verification condition',
  verify_button_joint_table_clear: 'Clear',
  verify_button_add_table: 'Add table',
  verify_button_auto_add_table: 'Automatically add table',
  verify_button_add_script: 'Add logic',
  verify_switch_job_enable_or_not: 'Is it enabled?',
  verify_checkbox_advance: 'Advanced Checkbox',
  verify_validator_message_task: 'Please select a task',
  verify_validator_message_job_name: 'Please enter the verification job name',
  verify_validator_message_time: 'Please select the start and end time',
  verify_validator_message_frequency: 'Please enter the verification interval',
  verify_message_error_joint_table_not_set: 'Please add verification conditions',
  verify_message_error_joint_table_target_or_source_not_set:
    'The source table or the target table is not selected in the verification condition',
  verify_message_error_joint_table_field_not_set:
    'The index field of the source table or the target table in the verification condition is not selected',
  verify_message_error_joint_table_field_not_match:
    'The number of index fields of the source table and the target table in the verification condition are not equal',
  verify_message_confirm_delete_script: 'Are you sure you want to delete the custom JS verification logic',
  verify_message_confirm_back: 'This operation will lose the verification task currently being created (edited)',
  verify_message_title_confirm_back: 'Would you give up creating (editing) verification tasks? ',
  dag_task_error_tittle: 'Task start pre-check',
  dag_task_error_Text: 'During the model deduction, please wait patiently',
  dag_task_error_current_Progress: 'Current progress',
  dag_task_error_Completed: 'Model deduction completed',
  dag_task_filed_mapping_Text: 'Field mapping error, please correct',

  dfs_workbench_workbench_zhongyaobanbensheng:
    '[Important] Important announcement on version upgrade and service switching',
  dfs_workbench_workbench_xinzengzidingyi:
    '· Added support for custom operators, users can define their own operators through flexible JS capabilities',
  dfs_workbench_workbench_xinzengzidingyi2:
    '· Added custom functions. Users can import custom functions through jar packages for use',
  dfs_workbench_workbench_xinzenghebingsuan:
    '· Add merge operator and JOIN operator, support multi-table association merge operation',
  dfs_workbench_workbench_xinzengDdl:
    '· Added DDL support capability to synchronize common DDL operations of Oracle, MySQL, DB2, PG and other databases',
  dfs_workbench_workbench_xinzengdongtaixin:
    '· Added the function of dynamically adding new tables, which supports synchronizing new tables in the database to the target',
  dfs_workbench_workbench_shujutongbuneng: 'Enhanced data synchronization capability',
  dfs_workbench_workbench_renwugaojingneng:
    '· Task alarm capability, when an abnormal alarm occurs in a task, it is directly reflected on the task operation monitoring page, combined with the task DAG, all problems are intuitively visible',
  dfs_workbench_workbench_renwurizhike:
    '· Mission log observability capability, output key mission information through standardized mission logs, and quickly locate problems when they occur',
  dfs_workbench_workbench_renwuzhibiaoke:
    '· Task indicators can be observed, and the running status of tasks can be directly fed back through key indicators',
  dfs_workbench_workbench_renwukeguance: 'Task observability',
  dfs_workbench_workbench_jubeiduishuju:
    '· Has the ability to initiate re-verification on the difference results of data verification',
  dfs_workbench_workbench_jubeiduishuju2:
    '· Has the ability to verify the consistency of incremental data in real time for data replication tasks',
  dfs_workbench_workbench_jubeiduishuju3:
    '· Has the ability to verify the consistency of the full data of the data replication task',
  dfs_workbench_workbench_quanlianghezengliang:
    'Data consistency verification capability in full and incremental phases',
  dfs_workbench_workbench_xinkaifadeshu:
    '· The newly developed data source can be quickly connected to the platform through registration and can be used without restarting',
  dfs_workbench_workbench_yonghukeanzhao:
    '·Users can flexibly customize their own data sources according to PDK standards',
  dfs_workbench_workbench_jiyuPdk: '· Implement data source development based on PDK',
  dfs_workbench_workbench_jiyuPdk2: 'PDK-based data source registration mechanism',
  dfs_workbench_workbench_xiamianshixinban: 'The following are the features added in the new version:',
  dfs_workbench_workbench_dangranruguoyou:
    'Of course, if there are new tasks, we recommend that you create them in the new version for a better user experience. You are welcome to experience our new version functions and give your valuable suggestions at that time. ',
  dfs_workbench_workbench_youyuzengjiale:
    'Because of the addition of many useful functions, we were forced to abandon the existing version structure and redevelop, so the connections and tasks you created in the current V2 version will not be synchronized to the new version, but rest assured, you will still be You can continue to use the old version for your data operations, we guarantee that the V2 version and the V3 version will coexist for a long time,\n ',
  dfs_workbench_workbench_zainianyueriwo: 'On September 29, 2022, we will release a major upgrade V3.0. ',
  dfs_workbench_workbench_zunjingdeyonghu: 'Dear user, hello:',
  dfs_workbench_workbench_banbenshengjihe: 'Announcement of version upgrade and service switch',
  dfs_workbench_workbench_banbenshengjitong: 'version upgrade notice'
}
